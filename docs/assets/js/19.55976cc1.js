(window.webpackJsonp=window.webpackJsonp||[]).push([[19],{1636:function(e,a,s){"use strict";s.r(a);var t=s(7),r=Object(t.a)({},(function(){var e=this,a=e.$createElement,t=e._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h1",{attrs:{id:"design-kafka"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#design-kafka"}},[e._v("#")]),e._v(" Design Kafka")]),e._v(" "),t("h2",{attrs:{id:"overview"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#overview"}},[e._v("#")]),e._v(" Overview")]),e._v(" "),t("h3",{attrs:{id:"goal"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#goal"}},[e._v("#")]),e._v(" Goal")]),e._v(" "),t("p",[e._v("Design a distributed messaging system that can reliably transfer a high\nthroughput of messages between different entities.")]),e._v(" "),t("h3",{attrs:{id:"background"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#background"}},[e._v("#")]),e._v(" Background")]),e._v(" "),t("p",[e._v("One of the common challenges among distributed systems is handling a\ncontinuous influx of data from multiple sources. Imagine a log aggregation\nservice that is receiving hundreds of log entries per second from different\nsources. The function of this log aggregation service is to store these logs on\ndisk at a shared server and also build an index so that the logs can be\nsearched later. A few challenges of this service are:")]),e._v(" "),t("ol",[t("li",[e._v("How will the log aggregation service handle a spike of messages? If the\nservice can handle (or buffer) 500 messages per second, what will\nhappen if it starts receiving a higher number of messages per second? If\nwe decide to have multiple instances of the log aggregation service, how\ndo we divide the work among these instances?")]),e._v(" "),t("li",[e._v("How can we receive messages from different types of sources? The\nsources producing (or consuming) these logs need to decide upon a\ncommon protocol and data format to send log messages to the log\naggregation service. This leads us to a strongly coupled architecture\nbetween the producer and consumer of the log messages.")]),e._v(" "),t("li",[e._v("What will happen to the log messages if the log aggregation service is\ndown or unresponsive for some time?")])]),e._v(" "),t("p",[e._v("To efficiently manage such scenarios, distributed systems depend upon a\nmessaging system.")]),e._v(" "),t("h3",{attrs:{id:"what-is-a-messaging-system"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#what-is-a-messaging-system"}},[e._v("#")]),e._v(" What is a messaging system?")]),e._v(" "),t("p",[e._v("A "),t("strong",[e._v("messaging system")]),e._v(" is responsible for transferring data among services,\napplications, processes, or servers. Such a system helps "),t("strong",[e._v("decouple")]),e._v(" different\nparts of a distributed system by providing an "),t("strong",[e._v("asynchronous")]),e._v(" way of\ntransferring messaging between the sender and the receiver. Hence, all\nsenders (or producers) and receivers (or consumers) focus on the\ndata/message without worrying about the mechanism used to share the data.")]),e._v(" "),t("p",[t("img",{attrs:{src:s(953),alt:"Figure 1"}}),t("br"),e._v(" "),t("em",[e._v("Messaging system")])]),e._v(" "),t("p",[e._v("There are two common ways to handle messages: "),t("em",[e._v("Queuing")]),e._v(" and "),t("strong",[e._v("Publish-Subscribe")]),e._v(".")]),e._v(" "),t("h3",{attrs:{id:"queue"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#queue"}},[e._v("#")]),e._v(" Queue")]),e._v(" "),t("p",[e._v("In the queuing model, messages are stored sequentially in a queue.\nProducers push messages to the rear of the queue, and consumers extract\nthe messages from the front of the queue")]),e._v(" "),t("p",[t("img",{attrs:{src:s(954),alt:"Figure 2"}})]),e._v(" "),t("p",[e._v("A particular message can be consumed by a maximum of one consumer only.\nOnce a consumer grabs a message, it is removed from the queue such that\nthe next consumer will get the next message. This is a great model for\ndistributing message-processing among multiple consumers. But this also\nlimits the system as multiple consumers cannot read the same message from the queue.")]),e._v(" "),t("p",[t("img",{attrs:{src:s(955),alt:"Figure 3"}}),t("br"),e._v(" "),t("em",[e._v("Message consumption in a message queue")])]),e._v(" "),t("h3",{attrs:{id:"publish-subscribe-messaging-system"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#publish-subscribe-messaging-system"}},[e._v("#")]),e._v(" Publish-subscribe messaging system")]),e._v(" "),t("p",[e._v("In the pub-sub (short for publish-subscribe) model, messages are divided\ninto topics. A publisher (or a producer) sends a message to a topic that gets\nstored in the messaging system under that topic. Subscribers (or the\nconsumer) subscribe to a topic to receive every message published to that\ntopic. Unlike the Queuing model, the pub-sub model allows multiple\nconsumers to get the same message; if two consumers subscribe to the same\ntopic, they will receive all messages published to that topic.")]),e._v(" "),t("p",[t("img",{attrs:{src:s(956),alt:"Figure 4"}}),t("br"),e._v(" "),t("em",[e._v("Pub-sub messaging system")])]),e._v(" "),t("p",[e._v("The messaging system that stores and maintains the messages is commonly\nknown as the message "),t("strong",[e._v("broker")]),e._v(". It provides a loose coupling between\npublishers and subscribers, or producers and consumers of data.")]),e._v(" "),t("p",[t("img",{attrs:{src:s(957),alt:"Figure 5"}}),t("br"),e._v(" "),t("em",[e._v("Message broker")])]),e._v(" "),t("p",[e._v("The message broker stores published messages in a queue, and subscribers\nread them from the queue. Hence, subscribers and publishers do not have to\nbe synchronized. This "),t("strong",[e._v("loose coupling")]),e._v(" enables subscribers and publishers to\nread and write messages at different rates.")]),e._v(" "),t("p",[e._v("The messaging systemâ€™s ability to store messages provides "),t("strong",[e._v("fault-tolerance")]),e._v(",\nso messages do not get lost between the time they are produced and the time\nthey are consumed.")]),e._v(" "),t("p",[e._v("To summarize, a message system is deployed in an application stack for the\nfollowing reasons:")]),e._v(" "),t("ol",[t("li",[t("strong",[e._v("Messaging buffering")]),e._v(". To provide a buffering mechanism in front of\nprocessing (i.e., to deal with temporary incoming message spikes that\nare greater than what the processing app can deal with). This enables\nthe system to safely deal with spikes in workloads by temporarily\nstoring data until it is ready for processing.")]),e._v(" "),t("li",[t("strong",[e._v("Guarantee of message delivery")]),e._v(". Allows producers to publish messages\nwith assurance that the message will eventually be delivered if the\nconsuming application is unable to receive the message when it is\npublished.")]),e._v(" "),t("li",[t("strong",[e._v("Providing abstraction")]),e._v(". A messaging system provides an architectural\nseparation between the consumers of messages and the applications\nproducing the messages.")]),e._v(" "),t("li",[t("strong",[e._v("Enabling scale")]),e._v(". Provides a flexible and highly configurable architecture\nthat enables many producers to deliver messages to multiple\nconsumers.")])]),e._v(" "),t("h2",{attrs:{id:"kafka-introduction"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka-introduction"}},[e._v("#")]),e._v(" Kafka: Introduction")]),e._v(" "),t("p",[e._v("Apache Kafka is an open-source "),t("strong",[e._v("publish-subscribe")]),e._v("-based messaging system ("),t("em",[e._v("Kafka can work as a message queue too")]),e._v("). It is "),t("strong",[e._v("distributed")]),e._v(",\n"),t("strong",[e._v("durable")]),e._v(", "),t("strong",[e._v("fault-tolerant")]),e._v(", and "),t("strong",[e._v("highly scalable")]),e._v(" by design. Fundamentally, it is\na system that takes streams of messages from applications known as\nproducers, stores them reliably on a central cluster (containing a set of\nbrokers), and allows those messages to be received by applications (known\nas consumers) that process the messages.")]),e._v(" "),t("p",[t("img",{attrs:{src:s(958),alt:"Figure 6"}}),t("br"),e._v(" "),t("em",[e._v("A high-level view of Kafka")])]),e._v(" "),t("h3",{attrs:{id:"background-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#background-2"}},[e._v("#")]),e._v(" Background")]),e._v(" "),t("p",[e._v("Kafka was created at LinkedIn around 2010 to track various events, such as\npage views, messages from the messaging system, and logs from various\nservices. Later, it was made open-source and developed into a\ncomprehensive system which is used for:")]),e._v(" "),t("ol",[t("li",[e._v("Reliably storing a huge amount of data.")]),e._v(" "),t("li",[e._v("Enabling high throughput of message transfer between different entities.")]),e._v(" "),t("li",[e._v("Streaming real-time data.")])]),e._v(" "),t("p",[e._v("At a high level, we can call Kafka a distributed "),t("strong",[e._v("Commit Log")]),e._v(". A Commit Log\n("),t("em",[e._v("also known as a Write-Ahead log or a Transactions log")]),e._v(") is an "),t("strong",[e._v("append-only")]),e._v("\ndata structure that can persistently store a sequence of records. Records are always appended to the end of the log, and once added, records cannot be\ndeleted or modified. Reading from a commit log always happens from left to\nright (or old to new).")]),e._v(" "),t("p",[t("img",{attrs:{src:s(959),alt:"Figure 7"}}),t("br"),e._v(" "),t("em",[e._v("Kafka as a write-ahead log")])]),e._v(" "),t("p",[e._v("Kafka stores all of its messages on disk. Since all reads and writes happen in\nsequence, Kafka takes advantage of sequential disk reads")]),e._v(" "),t("h3",{attrs:{id:"kafka-use-cases"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka-use-cases"}},[e._v("#")]),e._v(" Kafka use cases")]),e._v(" "),t("p",[e._v("Kafka can be used for collecting big data and real-time analysis. Here are\nsome of its top use cases:")]),e._v(" "),t("ol",[t("li",[t("strong",[e._v("Metrics")]),e._v(": Kafka can be used to collect and aggregate monitoring data.\nDistributed services can push different operational metrics to Kafka\nservers. These metrics can then be pulled from Kafka to produce\naggregated statistics.")]),e._v(" "),t("li",[t("strong",[e._v("Log Aggregation")]),e._v(": Kafka can be used to collect logs from multiple\nsources and make them available in a standard format to multiple\nconsumers.")]),e._v(" "),t("li",[t("strong",[e._v("Stream processing")]),e._v(": Kafka is quite useful for use cases where the\ncollected data undergoes processing at multiple stages. For example, the raw data consumed from a topic is transformed, enriched, or aggregated\nand pushed to a new topic for further consumption. This way of data\nprocessing is known as stream processing.")]),e._v(" "),t("li",[t("strong",[e._v("Commit Log")]),e._v(": Kafka can be used as an external commit log for any\ndistributed system. Distributed services can log their transactions to\nKafka to keep track of what is happening. This transaction data can be\nused for replication between nodes and also becomes very useful for\ndisaster recovery, for example, to help failed nodes to recover their\nstates.")]),e._v(" "),t("li",[t("strong",[e._v("Website activity tracking")]),e._v(": One of Kafkaâ€™s original use cases was to\nbuild a user activity tracking pipeline. User activities like page clicks,\nsearches, etc., are published to Kafka into separate topics. These topics\nare available for subscription for a range of use cases, including realtime processing, real-time monitoring, or loading into "),t("a",{attrs:{href:"https://hadoop.apache.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Hadoop"),t("OutboundLink")],1),e._v(" or data warehousing systems for offline\nprocessing and reporting.")]),e._v(" "),t("li",[t("strong",[e._v("Product suggestions")]),e._v(": Imagine an online shopping site like "),t("a",{attrs:{href:"http://amazon.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("amazon.com"),t("OutboundLink")],1),e._v(", which offers a feature of â€˜similar productsâ€™ to\nsuggest lookalike products that a customer could be interested in\nbuying. To make this work, we can track every consumer action, like\nsearch queries, product clicks, time spent on any product, etc., and\nrecord these activities in Kafka. Then, a consumer application can read\nthese messages to find correlated products that can be shown to the\ncustomer in real-time. Alternatively, since all data is persistent in Kafka,\na batch job can run overnight on the â€˜similar productâ€™ information\ngathered by the system, generating an email for the customer with\nproduct suggestions.")])]),e._v(" "),t("h2",{attrs:{id:"high-level-architecture"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#high-level-architecture"}},[e._v("#")]),e._v(" High-level Architecture")]),e._v(" "),t("h3",{attrs:{id:"kafka-common-terms"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka-common-terms"}},[e._v("#")]),e._v(" Kafka common terms")]),e._v(" "),t("h4",{attrs:{id:"brokers"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#brokers"}},[e._v("#")]),e._v(" Brokers")]),e._v(" "),t("p",[e._v("A Kafka server is also called a broker. Brokers are responsible for reliably\nstoring data provided by the producers and making it available to the\nconsumers.")]),e._v(" "),t("h4",{attrs:{id:"records"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#records"}},[e._v("#")]),e._v(" Records")]),e._v(" "),t("p",[e._v("A record is a message or an event that gets stored in Kafka. Essentially, it is\nthe data that travels from producer to consumer through Kafka. A record\ncontains a key, a value, a timestamp, and optional metadata headers.")]),e._v(" "),t("p",[t("img",{attrs:{src:s(960),alt:"Figure 8"}}),t("br"),e._v(" "),t("em",[e._v("Kafka message")])]),e._v(" "),t("h4",{attrs:{id:"topics"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#topics"}},[e._v("#")]),e._v(" Topics")]),e._v(" "),t("p",[e._v("Kafka divides its messages into categories called Topics. In simple terms, a\ntopic is like a table in a database, and the messages are the rows in that table.")]),e._v(" "),t("ul",[t("li",[e._v("Each message that Kafka receives from a producer is associated with a\ntopic.")]),e._v(" "),t("li",[e._v("Consumers can subscribe to a topic to get notified when new messages\nare added to that topic.")]),e._v(" "),t("li",[e._v("A topic can have multiple subscribers that read messages from it.")]),e._v(" "),t("li",[e._v("In a Kafka cluster, a topic is identified by its name and must be unique.")])]),e._v(" "),t("p",[e._v("Messages in a topic can be read as often as needed â€” unlike traditional\nmessaging systems, messages are not deleted after consumption. Instead,\nKafka retains messages for a configurable amount of time or until a storage\nsize is exceeded. Kafkaâ€™s performance is effectively constant with respect to\ndata size, so storing data for a long time is perfectly fine.")]),e._v(" "),t("p",[t("img",{attrs:{src:s(961),alt:"Figure 9"}}),t("br"),e._v(" "),t("em",[e._v("Kafka topics")])]),e._v(" "),t("h4",{attrs:{id:"producers"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#producers"}},[e._v("#")]),e._v(" Producers")]),e._v(" "),t("p",[e._v("Producers are applications that publish (or write) records to Kafka.")]),e._v(" "),t("h4",{attrs:{id:"consumers"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#consumers"}},[e._v("#")]),e._v(" Consumers")]),e._v(" "),t("p",[e._v("Consumers are the applications that subscribe to (read and process) data\nfrom Kafka topics. Consumers subscribe to one or more topics and consume\npublished messages by pulling data from the brokers.")]),e._v(" "),t("p",[e._v("In Kafka, producers and consumers are fully decoupled and agnostic of each\nother, which is a key design element to achieve the high scalability that\nKafka is known for. For example, producers never need to wait for\nconsumers.")]),e._v(" "),t("h4",{attrs:{id:"high-level-architecture-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#high-level-architecture-2"}},[e._v("#")]),e._v(" High-level architecture")]),e._v(" "),t("p",[e._v("At a high level, applications (producers) send messages to a Kafka broker,\nand these messages are read by other applications called consumers.\nMessages get stored in a topic, and consumers subscribe to the topic to\nreceive new messages.")]),e._v(" "),t("h4",{attrs:{id:"kafka-cluster"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka-cluster"}},[e._v("#")]),e._v(" Kafka cluster")]),e._v(" "),t("p",[e._v("Kafka is run as a cluster of one or more servers, where each server is\nresponsible for running one Kafka broker.")]),e._v(" "),t("h4",{attrs:{id:"zookeeper"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#zookeeper"}},[e._v("#")]),e._v(" ZooKeeper")]),e._v(" "),t("p",[e._v("ZooKeeper is a distributed key-value store and is used for coordination and\nstoring configurations. It is highly optimized for reads. Kafka uses ZooKeeper\nto coordinate between Kafka brokers; ZooKeeper maintains metadata\ninformation about the Kafka cluster. We will be looking into this in detail\nlater.")]),e._v(" "),t("p",[t("img",{attrs:{src:s(427),alt:"Figure 10"}}),t("br"),e._v(" "),t("em",[e._v("High level architecture of Kafka")])]),e._v(" "),t("h2",{attrs:{id:"kafka-deep-dive"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka-deep-dive"}},[e._v("#")]),e._v(" Kafka: Deep Dive")]),e._v(" "),t("p",[e._v("Kafka is simply a "),t("strong",[e._v("collection of topics")]),e._v(". As topics can get quite big, they are\n"),t("strong",[e._v("split into partitions")]),e._v(" of a smaller size for better performance and scalability.")]),e._v(" "),t("h3",{attrs:{id:"topic-partitions"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#topic-partitions"}},[e._v("#")]),e._v(" Topic partitions")]),e._v(" "),t("p",[e._v("Kafka topics are partitioned, meaning a topic is spread over a number of\nâ€˜fragmentsâ€™. Each partition can be placed on a separate Kafka broker. When\na new message is published on a topic, it gets appended to one of the topicâ€™s\npartitions. The producer controls which partition it publishes messages to\nbased on the data. For example, a producer can decide that all messages\nrelated to a particular â€˜cityâ€™ go to the same partition.")]),e._v(" "),t("p",[e._v("Essentially, a partition is an ordered sequence of messages. Producers\ncontinually append new messages to partitions. Kafka guarantees that all\nmessages inside a partition are stored in the sequence they came in.")]),e._v(" "),t("p",[t("strong",[e._v("Ordering of messages is maintained at the partition level, not across the topic.")])]),e._v(" "),t("p",[t("img",{attrs:{src:s(962),alt:"Figure 11"}}),t("br"),e._v(" "),t("em",[e._v("A topic having three partitions residing on three brokers")])]),e._v(" "),t("ul",[t("li",[e._v("A unique sequence ID called an "),t("strong",[e._v("offset")]),e._v(" gets assigned to every message\nthat enters a partition. These numerical offsets are used to identify\nevery messageâ€™s sequential position within a topicâ€™s partition.")]),e._v(" "),t("li",[e._v("Offset sequences are unique only to each partition. This means, to locate\na specific message, we need to know the Topic, Partition, and Offset\nnumber.")]),e._v(" "),t("li",[e._v("Producers can choose to publish a message to any partition. If ordering\nwithin a partition is not needed, a "),t("strong",[t("em",[e._v("round-robin")])]),e._v(" partition strategy can be\nused, so records get distributed evenly across partitions.")]),e._v(" "),t("li",[e._v("Placing each partition on separate Kafka brokers enables multiple\nconsumers to read from a topic in parallel. That means, different\nconsumers can concurrently read different partitions present on\nseparate brokers.")]),e._v(" "),t("li",[e._v("Placing each partition of a topic on a separate broker also enables a\ntopic to hold more data than the capacity of one server.")]),e._v(" "),t("li",[e._v("Messages once written to partitions are "),t("strong",[e._v("immutable")]),e._v(" and cannot be\nupdated.")]),e._v(" "),t("li",[e._v("A producer can add a "),t("strong",[e._v("â€˜keyâ€™")]),e._v(" to any message it publishes. Kafka\nguarantees that messages with the same key are written to the same\npartition.")]),e._v(" "),t("li",[e._v("Each broker manages a set of partitions belonging to different topics")])]),e._v(" "),t("p",[e._v("Kafka follows the principle of a "),t("strong",[e._v("dumb broker")]),e._v(" and "),t("strong",[e._v("smart consumer")]),e._v(". This\nmeans that Kafka does not keep track of what records are read by the\nconsumer. Instead, consumers, themselves, poll Kafka for new messages and\nsay what records they want to read. This allows them to\nincrement/decrement the offset they are at as they wish, thus being able to\nreplay and reprocess messages. Consumers can read messages starting from\na specific offset and are allowed to read from any offset they choose. This\nalso enables consumers to join the cluster at any point in time.")]),e._v(" "),t("p",[e._v("Every topic can be replicated to multiple Kafka brokers to make the data\nfault-tolerant and highly available. Each topic partition has one leader\nbroker and multiple replica (follower) brokers.")]),e._v(" "),t("h3",{attrs:{id:"leader"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#leader"}},[e._v("#")]),e._v(" Leader")]),e._v(" "),t("p",[e._v("A leader is the node responsible for all reads and writes for the given\npartition. Every partition has one Kafka broker acting as a leader.")]),e._v(" "),t("h3",{attrs:{id:"follower"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#follower"}},[e._v("#")]),e._v(" Follower")]),e._v(" "),t("p",[e._v("To handle single point of failure, Kafka can replicate partitions and\ndistribute them across multiple broker servers called followers. Each\nfollowerâ€™s responsibility is to replicate the leaderâ€™s data to serve as a â€˜backupâ€™\npartition. This also means that any follower can take over the leadership if\nthe leader goes down.")]),e._v(" "),t("p",[e._v("In the following diagram, we have two partitions and four brokers. "),t("code",[e._v("Broker 1")]),e._v(" is the leader of "),t("code",[e._v("Partition 1")]),e._v(" and follower of "),t("code",[e._v("Partition 2")]),e._v(" . Consumers\nwork together in groups to process messages efficiently. More details on\nconsumer groups later.")]),e._v(" "),t("p",[t("img",{attrs:{src:s(963),alt:"Figure 12"}}),t("br"),e._v(" "),t("em",[e._v("Leader and followers of partitions")])]),e._v(" "),t("p",[e._v("Kafka stores the location of the leader of each partition in ZooKeeper. As all\nwrites/reads happen at/from the leader, producers and consumers directly\ntalk to ZooKeeper to find a partition leader.")]),e._v(" "),t("h3",{attrs:{id:"in-sync-replicas"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#in-sync-replicas"}},[e._v("#")]),e._v(" In-sync replicas")]),e._v(" "),t("p",[e._v("An in-sync replica (ISR) is a broker that has the latest data for a given\npartition. A leader is always an in-sync replica. A follower is an in-sync\nreplica only if it has fully caught up to the partition it is following. In other\nwords, ISRs cannot be behind on the latest records for a given partition.\n"),t("strong",[e._v("Only ISRs are eligible to become partition leaders")]),e._v(". Kafka can choose the\nminimum number of ISRs required before the data becomes available for\nconsumers to read.")]),e._v(" "),t("h3",{attrs:{id:"high-water-mark"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#high-water-mark"}},[e._v("#")]),e._v(" High-water mark")]),e._v(" "),t("p",[e._v("To ensure data consistency, the leader broker never returns (or exposes)\nmessages which have not been replicated to a minimum set of ISRs. For this,\nbrokers keep track of the high-water mark, which is the highest offset that all\nISRs of a particular partition share. The leader exposes data only up to the\nhigh-water mark offset and propagates the high-water mark offset to all\nfollowers. Letâ€™s understand this with an example.")]),e._v(" "),t("p",[e._v("In the figure below, the leader does not return messages greater than offset\nâ€˜4â€™, as it is the highest offset message that has been replicated to all follower\nbrokers.")]),e._v(" "),t("p",[t("img",{attrs:{src:s(964),alt:"Figure 13"}}),t("br"),e._v(" "),t("em",[e._v("High-water mark offset")])]),e._v(" "),t("p",[e._v("If a consumer reads the record with offset â€˜7â€™ from the leader (Broker 1), and\nlater, if the current leader fails, and one of the followers becomes the leader\nbefore the record is replicated to the followers, the consumer will not be able\nto find that message on the new leader. The client, in this case, will\nexperience a "),t("strong",[e._v("non-repeatable read")]),e._v(". Because of this possibility, Kafka brokers\nonly return records up to the high-water mark.")]),e._v(" "),t("h2",{attrs:{id:"consumer-groups"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#consumer-groups"}},[e._v("#")]),e._v(" Consumer Groups")]),e._v(" "),t("p",[e._v("A consumer group is basically a set of one or more consumers working\ntogether in parallel to consume messages from topic partitions. Messages are\nequally divided among all the consumers of a group, with no two consumers\nreceiving the same message.")]),e._v(" "),t("h3",{attrs:{id:"distributing-partitions-to-consumers-within-a-consumer-group"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#distributing-partitions-to-consumers-within-a-consumer-group"}},[e._v("#")]),e._v(" Distributing partitions to consumers within a consumer group")]),e._v(" "),t("p",[e._v("Kafka ensures that "),t("strong",[e._v("only a single consumer reads messages from any partition within a consumer group")]),e._v(". In other words, topic partitions are a\nunit of parallelism â€“ only one consumer can work on a partition in a\nconsumer group at a time. If a consumer stops, Kafka spreads partitions\nacross the remaining consumers in the same consumer group. Similarly,\nevery time a consumer is added to or removed from a group, the\nconsumption is rebalanced within the group.")]),e._v(" "),t("p",[t("img",{attrs:{src:s(965),alt:"Figure 14"}}),t("br"),e._v(" "),t("em",[e._v("How Kafka distributes partitions to consumers within a consumer group")])]),e._v(" "),t("p",[e._v("Consumers pull messages from topic partitions. Different consumers can be\nresponsible for different partitions. Kafka can support a large number of\nconsumers and retain large amounts of data with very little overhead. By\nusing consumer groups, consumers can be parallelized so that multiple\nconsumers can read from multiple partitions on a topic, allowing a very high\nmessage processing throughput. The number of partitions impacts\nconsumersâ€™ maximum parallelism, as there cannot be more consumers than\npartitions.")]),e._v(" "),t("p",[e._v("Kafka stores the current offset per consumer group per topic per partition,\nas it would for a single consumer. This means that unique messages are only\nsent to a single consumer in a consumer group, and the load is balanced\nacross consumers as equally as possible.")]),e._v(" "),t("p",[e._v("When the number of consumers exceeds the number of partitions in a topic,\nall new consumers wait in idle mode until an existing consumer\nunsubscribes from that partition. Similarly, as new consumers join a\nconsumer group, Kafka initiates a rebalancing if there are more consumers\nthan partitions. Kafka uses any unused consumers as failovers.")]),e._v(" "),t("p",[e._v("Here is a summary of how Kafka manages the distribution of partitions to\nconsumers within a consumer group:")]),e._v(" "),t("ul",[t("li",[t("strong",[e._v("Number of consumers in a group = number of partitions")]),e._v(": each\nconsumer consumes one partition.")]),e._v(" "),t("li",[t("strong",[e._v("Number of consumers in a group > number of partitions")]),e._v(": some\nconsumers will be idle.")]),e._v(" "),t("li",[t("strong",[e._v("Number of consumers in a group < number of partitions")]),e._v(": some\nconsumers will consume more partitions than others.")])]),e._v(" "),t("h2",{attrs:{id:"kafka-workow"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka-workow"}},[e._v("#")]),e._v(" Kafka Workow")]),e._v(" "),t("p",[e._v("Kafka provides both pub-sub and queue-based messaging systems in a fast,\nreliable, persisted, fault-tolerance, and zero downtime manner. In both\ncases, producers simply send the message to a topic, and consumers can\nchoose any one type of messaging system depending on their need. Let us\nfollow the steps in the next section, to understand how the consumer can\nchoose the messaging system of their choice.")]),e._v(" "),t("h3",{attrs:{id:"kafka-workflow-as-pub-sub-messaging"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka-workflow-as-pub-sub-messaging"}},[e._v("#")]),e._v(" Kafka workflow as pub-sub messaging")]),e._v(" "),t("p",[e._v("Following is the stepwise workflow of the Pub-Sub Messaging:")]),e._v(" "),t("ul",[t("li",[e._v("Producers publish messages on a topic.")]),e._v(" "),t("li",[e._v("Kafka broker stores messages in the partitions configured for that\nparticular topic. If the producer did not specify the partition in which\nthe message should be stored, the broker ensures that the messages are\nequally shared between partitions. If the producer sends two messages\nand there are two partitions, Kafka will store one message in the first\npartition and the second message in the second partition.")]),e._v(" "),t("li",[e._v("Consumer subscribes to a specific topic.")]),e._v(" "),t("li",[e._v("Once the consumer subscribes to a topic, Kafka will provide the current\noffset of the topic to the consumer and also saves that offset in the\nZooKeeper.")]),e._v(" "),t("li",[e._v("Consumer will request Kafka at regular intervals for new messages.")]),e._v(" "),t("li",[e._v("Once Kafka receives the messages from producers, it forwards these\nmessages to the consumer.")]),e._v(" "),t("li",[e._v("Consumer will receive the message and process it.")]),e._v(" "),t("li",[e._v("Once the messages are processed, the consumer will send an\nacknowledgment to the Kafka broker.")]),e._v(" "),t("li",[e._v("Upon receiving the acknowledgment, Kafka increments the offset and\nupdates it in the ZooKeeper. Since offsets are maintained in the")]),e._v(" "),t("li",[e._v("ZooKeeper, the consumer can read the next message correctly, even\nduring broker outages.")]),e._v(" "),t("li",[e._v("The above flow will repeat until the consumer stops sending the\nrequest.")]),e._v(" "),t("li",[e._v("Consumers can rewind/skip to the desired offset of a topic at any time\nand read all the subsequent messages.")])]),e._v(" "),t("h3",{attrs:{id:"kafka-workflow-for-consumer-group"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka-workflow-for-consumer-group"}},[e._v("#")]),e._v(" Kafka workflow for consumer group")]),e._v(" "),t("p",[e._v("Instead of a single consumer, a group of consumers from one consumer\ngroup subscribes to a topic, and the messages are shared among them. Let us\ncheck the workflow of this system:")]),e._v(" "),t("ul",[t("li",[e._v("Producers publish messages on a topic.")]),e._v(" "),t("li",[e._v("Kafka stores all messages in the partitions configured for that particular topic, similar to the earlier scenario.")]),e._v(" "),t("li",[e._v("A single consumer subscribes to a specific topic, assume "),t("code",[e._v("Topic-01")]),e._v(" with Group ID as "),t("code",[e._v("Group-1")])]),e._v(" "),t("li",[e._v("Kafka interacts with the consumer in the same way as pub-sub\nmessaging until a new consumer subscribes to the same topic, "),t("code",[e._v("Topic-01")]),e._v(" , with the same Group ID as "),t("code",[e._v("Group-1")])]),e._v(" "),t("li",[e._v("Once the new consumer arrives, Kafka switches its operation to share\nmode, such that each message is passed to only one of the subscribers of\nthe consumer group "),t("code",[e._v("Group-1")]),e._v(" . This message transfer is similar to queuebased messaging, as only one consumer of the group consumes a\nmessage. Contrary to queue-based messaging, messages are not\nremoved after consumption.")]),e._v(" "),t("li",[e._v("This message transfer can go on until the number of consumers reaches\nthe number of partitions configured for that particular topic.")]),e._v(" "),t("li",[e._v("Once the number of consumers exceeds the number of partitions, the\nnew consumer will not receive any message until an existing consumer\nunsubscribes. This scenario arises because each consumer in Kafka will\nbe assigned a minimum of one partition. Once all the partitions are\nassigned to the existing consumers, the new consumers will have to\nwait.")])]),e._v(" "),t("h2",{attrs:{id:"role-of-zookeeper"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#role-of-zookeeper"}},[e._v("#")]),e._v(" Role of ZooKeeper")]),e._v(" "),t("p",[e._v("A critical dependency of Apache Kafka is Apache ZooKeeper, which is a\ndistributed configuration and synchronization service. ZooKeeper serves as\nthe coordination interface between the Kafka brokers, producers, and\nconsumers. Kafka stores basic metadata in ZooKeeper, such as information\nabout brokers, topics, partitions, partition leader/followers, consumer\noffsets, etc.")]),e._v(" "),t("p",[t("img",{attrs:{src:s(427),alt:"Figure 15"}})]),e._v(" "),t("h3",{attrs:{id:"zookeeper-as-the-central-coordinator"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#zookeeper-as-the-central-coordinator"}},[e._v("#")]),e._v(" ZooKeeper as the central coordinator")]),e._v(" "),t("p",[e._v("As we know, Kafka brokers are stateless; they rely on ZooKeeper to maintain\nand coordinate brokers, such as notifying consumers and producers of the\narrival of a new broker or failure of an existing broker, as well as routing all\nrequests to partition leaders.")]),e._v(" "),t("p",[e._v("ZooKeeper is used for storing all sorts of metadata about the Kafka cluster:")]),e._v(" "),t("ul",[t("li",[e._v("It maintains the last offset position of each consumer group per\npartition, so that consumers can quickly recover from the last position\nin case of a failure (although modern clients store offsets in a separate\nKafka topic).")]),e._v(" "),t("li",[e._v("It tracks the topics, number of partitions assigned to those topics, and\nleadersâ€™/followersâ€™ location in each partition.")]),e._v(" "),t("li",[e._v("It also manages the access control lists (ACLs) to different topics in the\ncluster. ACLs are used to enforce access or authorization.")])]),e._v(" "),t("h4",{attrs:{id:"how-do-producers-or-consumers-find-out-who-the-leader-of-a-partition-is"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#how-do-producers-or-consumers-find-out-who-the-leader-of-a-partition-is"}},[e._v("#")]),e._v(" How do producers or consumers find out who the leader of a partition is?")]),e._v(" "),t("p",[e._v("In the older versions of Kafka, all clients (i.e., producers and consumers)\nused to directly talk to ZooKeeper to find the partition leader. Kafka has\nmoved away from this coupling, and in Kafkaâ€™s latest releases, clients fetch\nmetadata information from Kafka brokers directly; brokers talk to\nZooKeeper to get the latest metadata. In the diagram below, the producer\ngoes through the following steps before publishing a message:")]),e._v(" "),t("ol",[t("li",[e._v("The producer connects to any broker and asks for the leader of\nâ€˜"),t("code",[e._v("Partition 1")]),e._v("â€™.")]),e._v(" "),t("li",[e._v("The broker responds with the identification of the leader broker\nresponsible for â€˜"),t("code",[e._v("Partition 1")]),e._v("â€™.")]),e._v(" "),t("li",[e._v("The producer connects to the leader broker to publish the message.")])]),e._v(" "),t("p",[t("img",{attrs:{src:s(966),alt:"Figure 16"}}),t("br"),e._v(" "),t("em",[e._v("Role of ZooKeeper in Kafka")])]),e._v(" "),t("p",[e._v("All the critical information is stored in the ZooKeeper and ZooKeeper\nreplicates this data across its cluster, therefore, failure of Kafka broker (or\nZooKeeper itself) does not affect the state of the Kafka cluster. Upon\nZooKeeper failure, Kafka will always be able to restore the state once the ZooKeeper restarts after failure. Zookeeper is also responsible for\ncoordinating the partition leader election between the Kafka brokers in case\nof leader failure.")]),e._v(" "),t("h2",{attrs:{id:"controller-broker"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#controller-broker"}},[e._v("#")]),e._v(" Controller Broker")]),e._v(" "),t("p",[e._v("Within the Kafka cluster, one broker is elected as the Controller. This\nController broker is responsible for admin operations, such as\ncreating/deleting a topic, adding partitions, assigning leaders to partitions,\nmonitoring broker failures, etc. Furthermore, the Controller periodically\nchecks the health of other brokers in the system. In case it does not receive a\nresponse from a particular broker, it performs a failover to another broker.\nIt also communicates the result of the partition leader election to other\nbrokers in the system.")]),e._v(" "),t("h3",{attrs:{id:"split-brain"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#split-brain"}},[e._v("#")]),e._v(" Split brain")]),e._v(" "),t("p",[e._v("When a controller broker dies, Kafka elects a new controller. One of the\nproblems is that we cannot truly know if the leader has stopped for good and\nhas experienced an intermittent failure like a "),t("strong",[t("em",[e._v("stop-the-world GC pause")])]),e._v(" or a temporary network disruption. Nevertheless, the cluster has to move on and\npick a new controller. If the original Controller had an intermittent failure,\nthe cluster would end up having a so-called "),t("strong",[e._v("zombie controller")]),e._v(". A zombie\ncontroller can be defined as a controller node that had been previously\ndeemed dead by the cluster and has come back online. Another broker has\ntaken its place, but the zombie controller might not know that yet. This\ncommon scenario in distributed systems with two or more active controllers\n(or central servers) is called split-brain.")]),e._v(" "),t("p",[e._v("We will have two controllers under split-brain, which will be giving out\npotentially conflicting commands in parallel. If something like this happens\nin a cluster, it can result in major inconsistencies. How do we handle this\nsituation?")]),e._v(" "),t("h3",{attrs:{id:"generation-clock"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#generation-clock"}},[e._v("#")]),e._v(" Generation clock")]),e._v(" "),t("p",[e._v("Split-brain is commonly solved with a "),t("strong",[e._v("generation clock")]),e._v(", which is simply a\nmonotonically increasing number to indicate a serverâ€™s generation. In Kafka,\nthe generation clock is implemented through an epoch number. If the old\nleader had an epoch number of â€˜1â€™, the new one would have â€˜2â€™. This epoch is\nincluded in every request that is sent from the Controller to other brokers.\nThis way, brokers can now easily differentiate the real Controller by simply\ntrusting the Controller with the highest number. The Controller with the\nhighest number is undoubtedly the latest one, since the epoch number is\nalways increasing. This epoch number is stored in ZooKeeper.")]),e._v(" "),t("h2",{attrs:{id:"kafka-delivery-semantics"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka-delivery-semantics"}},[e._v("#")]),e._v(" Kafka Delivery Semantics")]),e._v(" "),t("h3",{attrs:{id:"producer-delivery-semantics"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#producer-delivery-semantics"}},[e._v("#")]),e._v(" Producer delivery semantics")]),e._v(" "),t("p",[e._v("As we know, a producer writes only to the leader broker, and the followers\nasynchronously replicate the data. How can a producer know that the data is\nsuccessfully stored at the leader or that the followers are keeping up with the\nleader? Kafka offers three options to denote the number of brokers that must\nreceive the record before the producer considers the write as successful:")]),e._v(" "),t("ul",[t("li",[t("strong",[e._v("Async")]),e._v(": Producer sends a message to Kafka and does not wait for\nacknowledgment from the server. This means that the write is\nconsidered successful the moment the request is sent out. This "),t("strong",[e._v("fire-and-forget")]),e._v(" approach gives the best performance as we can write data to\nKafka at network speed, but no guarantee can be made that the server\nhas received the record in this case.")]),e._v(" "),t("li",[t("strong",[e._v("Committed to Leader")]),e._v(": Producer waits for an acknowledgment from the\nleader. This ensures that the data is committed at the leader; it will be\nslower than the â€˜Asyncâ€™ option, as the data has to be written on disk on\nthe leader. Under this scenario, the leader will respond without waiting\nfor acknowledgments from the followers. In this case, the record will be lost if the leader crashes immediately after acknowledging the producer\nbut before the followers have replicated it.")]),e._v(" "),t("li",[t("strong",[e._v("Committed to Leader and Quorum")]),e._v(": Producer waits for an\nacknowledgment from the leader and the quorum. This means the\nleader will wait for the full set of in-sync replicas to acknowledge the\nrecord. This will be the slowest write but guarantees that the record will\nnot be lost as long as at least one in-sync replica remains alive. This is\nthe strongest available guarantee.")])]),e._v(" "),t("p",[e._v("As we can see, the above options enable us to configure our preferred tradeoff between durability and performance.")]),e._v(" "),t("ul",[t("li",[e._v("If we would like to be sure that our records are safely stored in Kafka,\nwe have to go with the last option â€“ Committed to Leader and Quorum.")]),e._v(" "),t("li",[e._v("If we value latency and throughput more than durability, we can choose\none of the first two options. These options will have a greater chance of\nlosing messages but will have better speed and throughput.")])]),e._v(" "),t("h3",{attrs:{id:"consumer-delivery-semantics"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#consumer-delivery-semantics"}},[e._v("#")]),e._v(" Consumer delivery semantics")]),e._v(" "),t("p",[e._v("A consumer can read only those messages that have been written to a set of\nin-sync replicas. There are three ways of providing consistency to the\nconsumer:")]),e._v(" "),t("ul",[t("li",[t("strong",[e._v("At-most-once")]),e._v(" (Messages may be lost but are never redelivered): In this\noption, a message is delivered a maximum of one time only. Under this\noption, the consumer upon receiving a message, commit (or increment)\nthe offset to the broker. Now, if the consumer crashes before fully\nconsuming the message, that message will be lost, as when the\nconsumer restarts, it will receive the next message from the last\ncommitted offset.")]),e._v(" "),t("li",[t("strong",[e._v("At-least-once")]),e._v(" (Messages are never lost but maybe redelivered): Under\nthis option, a message might be delivered more than once, but no\nmessage should be lost. This scenario occurs when the consumer\nreceives a message from Kafka, and it does not immediately commit the\noffset. Instead, it waits till it completes the processing. So, if the\nconsumer crashes after processing the message but before committing\nthe offset, it has to reread the message upon restart. Since, in this case,\nthe consumer never committed the offset to the broker, the broker will\nredeliver the same message. Thus, duplicate message delivery could\nhappen in such a scenario.")]),e._v(" "),t("li",[t("strong",[e._v("Exactly-once")]),e._v(" (each message is delivered once and only once): It is very\nhard to achieve this unless the consumer is working with a\ntransactional system. Under this option, the consumer puts the message\nprocessing and the offset increment in one transaction. This will ensure\nthat the offset increment will happen only if the whole transaction is\ncomplete. If the consumer crashes while processing, the transaction will\nbe rolled back, and the offset will not be incremented. When the\nconsumer restarts, it can reread the message as it failed to process it last\ntime. This option leads to no data duplication and no data loss but can\nlead to decreased throughput.")])]),e._v(" "),t("h2",{attrs:{id:"kafka-characteristics"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka-characteristics"}},[e._v("#")]),e._v(" Kafka Characteristics")]),e._v(" "),t("h3",{attrs:{id:"storing-messages-to-disks"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#storing-messages-to-disks"}},[e._v("#")]),e._v(" Storing messages to disks")]),e._v(" "),t("p",[e._v("Kafka writes its messages to the local disk and does not keep anything in\nRAM. Disks storage is important for durability so that the messages will not\ndisappear if the system dies and restarts. Disks are generally considered to\nbe slow. However, there is a huge difference in disk performance between\nrandom block access and sequential access. Random block access is slower\nbecause of numerous disk seeks, whereas the sequential nature of writing or\nreading, enables disk operations to be thousands of times faster than\nrandom access. Because all writes and reads happen sequentially, Kafka has\na very high throughput.")]),e._v(" "),t("p",[e._v("Writing or reading sequentially from disks are heavily optimized by the OS,\nvia "),t("strong",[e._v("read-ahead")]),e._v(" (prefetch large block multiples) and "),t("strong",[e._v("write-behind")]),e._v(" (group\nsmall logical writes into big physical writes) techniques.")]),e._v(" "),t("p",[e._v("Also, modern operating systems cache the disk in free RAM. This is called\n"),t("a",{attrs:{href:"https://en.wikipedia.org/wiki/Page_cache",target:"_blank",rel:"noopener noreferrer"}},[e._v("Pagecache"),t("OutboundLink")],1),e._v(". Since Kafka stores\nmessages in a standardized binary format unmodified throughout the whole\nflow (producer â†’ broker â†’ consumer), it can make use of the "),t("a",{attrs:{href:"https://en.wikipedia.org/wiki/Zero-copy",target:"_blank",rel:"noopener noreferrer"}},[e._v("zero-copy"),t("OutboundLink")],1),e._v(" optimization. That is when the\noperating system copies data from the Pagecache directly to a socket,\neffectively bypassing the Kafka broker application entirely.")]),e._v(" "),t("p",[e._v("Kafka has a protocol that groups messages together. This allows network\nrequests to group messages together and reduces network overhead. The\nserver, in turn, persists chunks of messages in one go, and consumers fetch\nlarge linear chunks at once.")]),e._v(" "),t("p",[e._v("All of these optimizations allow Kafka to deliver messages at near networkspeed.")]),e._v(" "),t("h3",{attrs:{id:"record-retention-in-kafka"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#record-retention-in-kafka"}},[e._v("#")]),e._v(" Record retention in Kafka")]),e._v(" "),t("p",[e._v("By default, Kafka retains records until it runs out of disk space. We can set\ntime-based limits (configurable retention period), size-based limits\n(configurable based on size), or compaction (keeps the latest version of\nrecord using the key). For example, we can set a retention policy of three\ndays, or two weeks, or a month, etc. The records in the topic are available for\nconsumption until discarded by time, size, or compaction.")]),e._v(" "),t("h3",{attrs:{id:"client-quota"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#client-quota"}},[e._v("#")]),e._v(" Client quota")]),e._v(" "),t("p",[e._v("It is possible for Kafka producers and consumers to produce/consume very\nhigh volumes of data or generate requests at a very high rate and thus\nmonopolize broker resources, cause network saturation, and, in general,\ndeny service to other clients and the brokers themselves. Having quotas\nprotects against these issues. Quotas become even more important in large\nmulti-tenant clusters where a small set of badly behaved clients can degrade\nthe user experience for the well-behaved ones.")]),e._v(" "),t("p",[e._v("In Kafka, quotas are byte-rate thresholds defined per "),t("code",[e._v("client-ID")]),e._v(" . A "),t("code",[e._v("client-ID")]),e._v(" logically identifies an application making a request. A single "),t("code",[e._v("client-ID")]),e._v("\ncan span multiple producer and consumer instances. The quota is applied\nfor all instances as a single entity. For example, if a "),t("code",[e._v("client-ID")]),e._v(" has a\nproducer quota of 10 MB/s, that quota is shared across all instances with that\nsame ID.")]),e._v(" "),t("p",[e._v("The broker does not return an error when a client exceeds its quota but\ninstead attempts to slow the client down. When the broker calculates that a\nclient has exceeded its quota, it slows the client down by holding the clientâ€™s\nresponse for enough time to keep the client under the quota. This approach\nkeeps the quota violation transparent to clients. This also prevents clients\nfrom having to implement special back-off and retry behavior.")]),e._v(" "),t("h3",{attrs:{id:"kafka-performance"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka-performance"}},[e._v("#")]),e._v(" Kafka performance")]),e._v(" "),t("p",[e._v("Here are a few reasons behind Kafkaâ€™s performance and popularity:")]),e._v(" "),t("p",[t("strong",[e._v("Scalability")]),e._v(": Two important features of Kafka contribute to its scalability.")]),e._v(" "),t("ul",[t("li",[e._v("A Kafka cluster can easily expand or shrink (brokers can be added or\nremoved) while in operation and without an outage.")]),e._v(" "),t("li",[e._v("A Kafka topic can be expanded to contain more partitions. Because a\npartition cannot expand across multiple brokers, its capacity is bounded\nby broker disk space. Being able to increase the number of partitions\nand the number of brokers means there is no limit to how much data a\nsingle topic can store.")])]),e._v(" "),t("p",[t("strong",[e._v("Fault-tolerance and reliability")]),e._v(": Kafka is designed in such a way that a\nbroker failure is detectable by ZooKeeper and other brokers in the cluster.\nBecause each topic can be replicated on multiple brokers, the cluster can\nrecover from broker failures and continue to work without any disruption of\nservice.")]),e._v(" "),t("p",[t("strong",[e._v("Throughput")]),e._v(": By using consumer groups, consumers can be parallelized, so\nthat multiple consumers can read from multiple partitions on a topic,\nallowing a very high message processing throughput.")]),e._v(" "),t("p",[t("strong",[e._v("Low Latency")]),e._v(": 99.99% of the time, data is read from disk cache and RAM;\nvery rarely, it hits the disk.")]),e._v(" "),t("h2",{attrs:{id:"summary"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#summary"}},[e._v("#")]),e._v(" Summary")]),e._v(" "),t("ol",[t("li",[e._v("Kafka provides low-latency, high-throughput, fault-tolerant "),t("strong",[e._v("publish and subscribe pipelines")]),e._v(" and can process huge continuous streams of events.")]),e._v(" "),t("li",[e._v("Kafka can function both as a "),t("strong",[e._v("message queue")]),e._v(" and a "),t("strong",[e._v("publisher-subscriber")]),e._v(" system.")]),e._v(" "),t("li",[e._v("At a high level, Kafka works as a "),t("strong",[e._v("distributed commit log")]),e._v(".")]),e._v(" "),t("li",[e._v("Kafka server is also called a "),t("strong",[e._v("broker")]),e._v(". A Kafka cluster can have one or more brokers.")]),e._v(" "),t("li",[e._v("A Kafka "),t("strong",[e._v("topic")]),e._v(" is a logical aggregation of messages.")]),e._v(" "),t("li",[e._v("Kafka solves the scaling problem of a messaging system by splitting a topic into multiple "),t("strong",[e._v("partitions")]),e._v(".")]),e._v(" "),t("li",[e._v("Every topic partition is replicated for fault tolerance and redundancy.")]),e._v(" "),t("li",[e._v("A partition has one leader replica and zero or more follower replicas.")]),e._v(" "),t("li",[e._v("Partition leader is responsible for all reads and writes. Each follower's responsibility is to replicate the leader's data to serve as a 'backup' partition.")]),e._v(" "),t("li",[e._v("Message ordering is preserved only on a per-partition basis (not across partitions of a topic).")]),e._v(" "),t("li",[e._v("Every partition replica needs to fit on a broker, and a partition cannot be divided over multiple brokers.")]),e._v(" "),t("li",[e._v("Every broker can have one or more leaders, covering different partitions and topics.")]),e._v(" "),t("li",[e._v("Kafka supports a single queue model with multiple readers by enabling consumer groups.")]),e._v(" "),t("li",[e._v("Kafka supports a publish-subscribe model by allowing consumers to subscribe to topics for which they want to receive messages.")]),e._v(" "),t("li",[e._v("ZooKeeper functions as a centralized configuration management service.")])]),e._v(" "),t("h3",{attrs:{id:"system-design-patterns"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#system-design-patterns"}},[e._v("#")]),e._v(" System design patterns")]),e._v(" "),t("h4",{attrs:{id:"high-water-mark-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#high-water-mark-2"}},[e._v("#")]),e._v(" High-water mark")]),e._v(" "),t("p",[e._v("To deal with non-repeatable reads and ensure data consistency, brokers keep track of the high-water mark, which is the largest offset that all ISRs of a particular partition share. Consumers can see messages only until the high\nwatermark.")]),e._v(" "),t("h4",{attrs:{id:"leader-and-follower"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#leader-and-follower"}},[e._v("#")]),e._v(" Leader and follower")]),e._v(" "),t("p",[e._v("Each Kafka partition has a designated leader responsible for all reads and writes for that partition. Each follower's responsibility is to replicate the leader's data to serve as a backup' partition.")]),e._v(" "),t("h4",{attrs:{id:"split-brain-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#split-brain-2"}},[e._v("#")]),e._v(" Split-brain")]),e._v(" "),t("p",[e._v("To handle split-brain (where we have multiple active controller brokers), Kafka uses 'epoch number,' which is simply a monotonically increasing number to indicate a server's generation. This means if the old Controller had an epoch number of '1', the new one would have 2Â°. This epoch is included in every request that is sent from the Controller to other brokers.")]),e._v(" "),t("p",[e._v("This way, brokers can easily differentiate the real Controller by simply trusting the Controller with the highest number. This epoch number is stored in ZooKeeper.")]),e._v(" "),t("h4",{attrs:{id:"segmented-log"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#segmented-log"}},[e._v("#")]),e._v(" Segmented log")]),e._v(" "),t("p",[e._v("Kafka uses log segmentation to implement storage for its partitions. As Kafka regularly needs to find messages on disk for purging, a single long file could be a performance bottleneck and error-prone. For easier management and better performance, the partition is split into segments.")])])}),[],!1,null,null,null);a.default=r.exports},427:function(e,a,s){e.exports=s.p+"assets/img/f10.58273be4.png"},953:function(e,a,s){e.exports=s.p+"assets/img/f1.9fc75764.png"},954:function(e,a,s){e.exports=s.p+"assets/img/f2.df421c0b.png"},955:function(e,a,s){e.exports=s.p+"assets/img/f3.1ba81a97.png"},956:function(e,a,s){e.exports=s.p+"assets/img/f4.776ee81d.png"},957:function(e,a,s){e.exports=s.p+"assets/img/f5.4bec6c80.png"},958:function(e,a,s){e.exports=s.p+"assets/img/f6.1f3a9226.png"},959:function(e,a,s){e.exports=s.p+"assets/img/f7.2fd92e81.png"},960:function(e,a,s){e.exports=s.p+"assets/img/f8.147927b1.png"},961:function(e,a,s){e.exports=s.p+"assets/img/f9.ac5fb259.png"},962:function(e,a,s){e.exports=s.p+"assets/img/f11.c67ba770.png"},963:function(e,a,s){e.exports=s.p+"assets/img/f12.8b4ece40.png"},964:function(e,a,s){e.exports=s.p+"assets/img/f13.d5ba4c17.png"},965:function(e,a,s){e.exports=s.p+"assets/img/f14.d2e77558.png"},966:function(e,a,s){e.exports=s.p+"assets/img/f16.f9615b54.png"}}]);