(window.webpackJsonp=window.webpackJsonp||[]).push([[54],{1453:function(e,t,a){"use strict";a.r(t);var i=a(7),s=Object(i.a)({},(function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[i("h1",{attrs:{id:"design-dropbox"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#design-dropbox"}},[e._v("#")]),e._v(" Design Dropbox")]),e._v(" "),i("p",[e._v("Let's design a file hosting service like Dropbox or Google Drive. Cloud file storage enables users to\nstore their data on remote servers. Usually, these servers are maintained by cloud storage providers and\nmade available to users over a network (typically through the Internet). Users pay for their cloud data\nstorage on a monthly basis. Similar Services: OneDrive, Google Drive")]),e._v(" "),i("p",[e._v("Difficulty Level: Medium")]),e._v(" "),i("h2",{attrs:{id:"_1-why-cloud-storage"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_1-why-cloud-storage"}},[e._v("#")]),e._v(" 1. Why Cloud Storage?")]),e._v(" "),i("p",[e._v("Cloud file storage services have become very popular recently as they simplify the storage and\nexchange of digital resources among multiple devices. The shift from using single personal computers\nto using multiple devices with different platforms and operating systems such as smartphones and\ntablets each with portable access from various geographical locations at any time, is believed to be\naccountable for the huge popularity of cloud storage services. Following are some of the top benefits of\nsuch services:")]),e._v(" "),i("p",[i("strong",[e._v("Availability")]),e._v(": The motto of cloud storage services is to have data availability anywhere, anytime. Users\ncan access their files/photos from any device whenever and wherever they like.")]),e._v(" "),i("p",[i("strong",[e._v("Reliability and Durability")]),e._v(": Another benefit of cloud storage is that it offers 100% reliability and\ndurability of data. Cloud storage ensures that users will never lose their data by keeping multiple copies\nof the data stored on different geographically located servers.")]),e._v(" "),i("p",[i("strong",[e._v("Scalability")]),e._v(": Users will never have to worry about getting out of storage space. With cloud storage you\nhave unlimited storage as long as you are ready to pay for it.")]),e._v(" "),i("p",[e._v("If you haven’t used dropbox.com before, we would highly recommend creating an account there and\nuploading/editing a file and also going through the different options their service offers. This will help\nyou a lot in understanding this chapter.")]),e._v(" "),i("h2",{attrs:{id:"_2-requirements-and-goals-of-the-system"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-requirements-and-goals-of-the-system"}},[e._v("#")]),e._v(" 2. Requirements and Goals of the System")]),e._v(" "),i("div",{staticClass:"custom-block tip"},[i("p",{staticClass:"custom-block-title"},[e._v("TIP")]),e._v(" "),i("p",[e._v("You should always clarify requirements at the beginning of the interview. Be sure to ask\nquestions to find the exact scope of the system that the interviewer has in mind.")])]),e._v(" "),i("p",[e._v("What do we wish to achieve from a Cloud Storage system? Here are the top-level requirements for our\nsystem:")]),e._v(" "),i("ol",[i("li",[e._v("Users should be able to upload and download their files/photos from any device.")]),e._v(" "),i("li",[e._v("Users should be able to share files or folders with other users.")]),e._v(" "),i("li",[e._v("Our service should support automatic synchronization between devices, i.e., after updating a file on one device, it should get synchronized on all devices.")]),e._v(" "),i("li",[e._v("The system should support storing large files up to a GB.")]),e._v(" "),i("li",[e._v("ACID-ity is required. Atomicity, Consistency, Isolation and Durability of all file operations\nshould be guaranteed.")]),e._v(" "),i("li",[e._v("Our system should support offline editing. Users should be able to add/delete/modify files while\noffline, and as soon as they come online, all their changes should be synced to the remote\nservers and other online devices.")])]),e._v(" "),i("p",[i("strong",[e._v("Extended Requirements")])]),e._v(" "),i("ul",[i("li",[e._v("The system should support snapshotting of the data, so that users can go back to any version of the files.")])]),e._v(" "),i("h2",{attrs:{id:"_3-some-design-considerations"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_3-some-design-considerations"}},[e._v("#")]),e._v(" 3. Some Design Considerations")]),e._v(" "),i("ul",[i("li",[e._v("We should expect huge read and write volumes.")]),e._v(" "),i("li",[e._v("Read to write ratio is expected to be nearly the same.")]),e._v(" "),i("li",[e._v("Internally, files can be stored in small parts or chunks (say 4MB); this can provide a lot of benefits i.e. all failed operations shall only be retried for smaller parts of a file. If a user fails to upload a file, then only the failing chunk will be retried.")]),e._v(" "),i("li",[e._v("We can reduce the amount of data exchange by transferring updated chunks only.")]),e._v(" "),i("li",[e._v("By removing duplicate chunks, we can save storage space and bandwidth usage.")]),e._v(" "),i("li",[e._v("Keeping a local copy of the metadata (file name, size, etc.) with the client can save us a lot of round trips to the server.")]),e._v(" "),i("li",[e._v("For small changes, clients can intelligently upload the diffs instead of the whole chunk.")])]),e._v(" "),i("h2",{attrs:{id:"_4-capacity-estimation-and-constraints"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_4-capacity-estimation-and-constraints"}},[e._v("#")]),e._v(" 4. Capacity Estimation and Constraints")]),e._v(" "),i("ul",[i("li",[e._v("Let’s assume that we have 500M total users, and 100M daily active users (DAU).")]),e._v(" "),i("li",[e._v("Let’s assume that on average each user connects from three different devices.")]),e._v(" "),i("li",[e._v("On average if a user has 200 files/photos, we will have 100 billion total files.")]),e._v(" "),i("li",[e._v("Let’s assume that average file size is 100KB, this would give us ten petabytes of total storage.")])]),e._v(" "),i("div",{staticClass:"language- extra-class"},[i("pre",{pre:!0,attrs:{class:"language-text"}},[i("code",[e._v("100B * 100KB => 10PB\n")])])]),i("ul",[i("li",[e._v("Let’s also assume that we will have one million active connections per minute.")])]),e._v(" "),i("h2",{attrs:{id:"_5-high-level-design"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_5-high-level-design"}},[e._v("#")]),e._v(" 5. High Level Design")]),e._v(" "),i("p",[e._v("The user will specify a folder as the workspace on their device. Any file/photo/folder placed in this\nfolder will be uploaded to the cloud, and whenever a file is modified or deleted, it will be reflected in\nthe same way in the cloud storage. The user can specify similar workspaces on all their devices and any\nmodification done on one device will be propagated to all other devices to have the same view of the\nworkspace everywhere.")]),e._v(" "),i("p",[e._v("At a high level, we need to store files and their metadata information like File Name, File Size,\nDirectory, etc., and who this file is shared with. So, we need some servers that can help the clients to\nupload/download files to Cloud Storage and some servers that can facilitate updating metadata about\nfiles and users. We also need some mechanism to notify all clients whenever an update happens so they\ncan synchronize their files.")]),e._v(" "),i("p",[e._v("As shown in the diagram below, Block servers will work with the clients to upload/download files from\ncloud storage and Metadata servers will keep metadata of files updated in a SQL or NoSQL database.\nSynchronization servers will handle the workflow of notifying all clients about different changes for\nsynchronization.")]),e._v(" "),i("p",[i("img",{attrs:{src:a(697),alt:"img"}}),i("br"),e._v(" "),i("em",[e._v("High level design for Dropbox")])]),e._v(" "),i("h2",{attrs:{id:"_6-component-design"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_6-component-design"}},[e._v("#")]),e._v(" 6. Component Design")]),e._v(" "),i("p",[e._v("Let’s go through the major components of our system one by one:")]),e._v(" "),i("h3",{attrs:{id:"a-client"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#a-client"}},[e._v("#")]),e._v(" a. Client")]),e._v(" "),i("p",[e._v("The Client Application monitors the workspace folder on the user’s machine and syncs all files/folders\nin it with the remote Cloud Storage. The client application will work with the storage servers to upload,\ndownload, and modify actual files to backend Cloud Storage. The client also interacts with the remote\nSynchronization Service to handle any file metadata updates, e.g., change in the file name, size,\nmodification date, etc.")]),e._v(" "),i("p",[e._v("Here are some of the essential operations for the client:")]),e._v(" "),i("ol",[i("li",[e._v("Upload and download files.")]),e._v(" "),i("li",[e._v("Detect file changes in the workspace folder.")]),e._v(" "),i("li",[e._v("Handle conflict due to offline or concurrent updates.")])]),e._v(" "),i("p",[i("strong",[e._v("How do we handle file transfer efficiently?")]),e._v(" As mentioned above, we can break each file into smaller chunks so that we transfer only those chunks that are modified and not the whole file. Let’s say we divide each file into fixed sizes of 4MB chunks. We can statically calculate what could be an optimal chunk size based on")]),e._v(" "),i("ol",[i("li",[e._v("Storage devices we use in the cloud to optimize space utilization and input/output operations per second (IOPS)")]),e._v(" "),i("li",[e._v("Network bandwidth")]),e._v(" "),i("li",[e._v("Average file size in the storage etc.\nIn our metadata, we should also keep a record of each file and the chunks that constitute it.")])]),e._v(" "),i("p",[i("strong",[e._v("Should we keep a copy of metadata with Client?")]),e._v(" Keeping a local copy of metadata not only enable us to do offline updates but also saves a lot of round trips to update remote metadata.")]),e._v(" "),i("p",[i("strong",[e._v("How can clients efficiently listen to changes happening with other clients?")]),e._v(" One solution could be\nthat the clients periodically check with the server if there are any changes. The problem with this\napproach is that we will have a delay in reflecting changes locally as clients will be checking for\nchanges periodically compared to a server notifying whenever there is some change. If the client\nfrequently checks the server for changes, it will not only be wasting bandwidth, as the server has to\nreturn an empty response most of the time, but will also be keeping the server busy. Pulling information\nin this manner is not scalable.")]),e._v(" "),i("p",[e._v("A solution to the above problem could be to use HTTP long polling. With long polling the client\nrequests information from the server with the expectation that the server may not respond immediately.\nIf the server has no new data for the client when the poll is received, instead of sending an empty\nresponse, the server holds the request open and waits for response information to become available.\nOnce it does have new information, the server immediately sends an HTTP/S response to the client,\ncompleting the open HTTP/S Request. Upon receipt of the server response, the client can immediately\nissue another server request for future updates.")]),e._v(" "),i("p",[e._v("Based on the above considerations, we can divide our client into following four parts:")]),e._v(" "),i("p",[e._v("I. "),i("strong",[e._v("Internal Metadata Database")]),e._v(" will keep track of all the files, chunks, their versions, and their location in the file system.")]),e._v(" "),i("p",[e._v("II. "),i("strong",[e._v("Chunker")]),e._v(" will split the files into smaller pieces called chunks. It will also be responsible for reconstructing a file from its chunks. Our chunking algorithm will detect the parts of the files that have been modified by the user and only transfer those parts to the Cloud Storage; this will save us bandwidth and synchronization time.")]),e._v(" "),i("p",[e._v("III. "),i("strong",[e._v("Watcher")]),e._v(" will monitor the local workspace folders and notify the Indexer (discussed below) of any\naction performed by the users, e.g. when users create, delete, or update files or folders. Watcher also\nlistens to any changes happening on other clients that are broadcasted by Synchronization service.")]),e._v(" "),i("p",[e._v("IV. "),i("strong",[e._v("Indexer")]),e._v(" will process the events received from the Watcher and update the internal metadata\ndatabase with information about the chunks of the modified files. Once the chunks are successfully\nsubmitted/downloaded to the Cloud Storage, the Indexer will communicate with the remote\nSynchronization Service to broadcast changes to other clients and update remote metadata database.")]),e._v(" "),i("p",[i("img",{attrs:{src:a(698),alt:"img"}})]),e._v(" "),i("p",[i("strong",[e._v("How should clients handle slow servers?")]),e._v(" Clients should exponentially back-off if the server is\nbusy/not-responding. Meaning, if a server is too slow to respond, clients should delay their retries and\nthis delay should increase exponentially.")]),e._v(" "),i("p",[i("strong",[e._v("Should mobile clients sync remote changes immediately?")]),e._v(" Unlike desktop or web clients, mobile\nclients usually sync on demand to save user’s bandwidth and space.")]),e._v(" "),i("h3",{attrs:{id:"b-metadata-database"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#b-metadata-database"}},[e._v("#")]),e._v(" b. Metadata Database")]),e._v(" "),i("p",[e._v("The Metadata Database is responsible for maintaining the versioning and metadata information about\nfiles/chunks, users, and workspaces. The Metadata Database can be a relational database such as\nMySQL, or a NoSQL database service such as DynamoDB. Regardless of the type of the database, the\nSynchronization Service should be able to provide a consistent view of the files using a database,\nespecially if more than one user is working with the same file simultaneously. Since NoSQL data stores\ndo not support ACID properties in favor of scalability and performance, we need to incorporate the\nsupport for ACID properties programmatically in the logic of our Synchronization Service in case we\nopt for this kind of database. However, using a relational database can simplify the implementation of\nthe Synchronization Service as they natively support ACID properties.")]),e._v(" "),i("p",[e._v("The metadata Database should be storing information about following objects:")]),e._v(" "),i("ol",[i("li",[e._v("Chunks")]),e._v(" "),i("li",[e._v("Files")]),e._v(" "),i("li",[e._v("User")]),e._v(" "),i("li",[e._v("Devices")]),e._v(" "),i("li",[e._v("Workspace (sync folders)")])]),e._v(" "),i("h3",{attrs:{id:"c-synchronization-service"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#c-synchronization-service"}},[e._v("#")]),e._v(" c. Synchronization Service")]),e._v(" "),i("p",[e._v("The Synchronization Service is the component that processes file updates made by a client and applies\nthese changes to other subscribed clients. It also synchronizes clients’ local databases with the\ninformation stored in the remote Metadata DB. The Synchronization Service is the most important part\nof the system architecture due to its critical role in managing the metadata and synchronizing users’\nfiles. Desktop clients communicate with the Synchronization Service to either obtain updates from the\nCloud Storage or send files and updates to the Cloud Storage and, potentially, other users. If a client\nwas offline for a period, it polls the system for new updates as soon as they come online. When the\nSynchronization Service receives an update request, it checks with the Metadata Database for\nconsistency and then proceeds with the update. Subsequently, a notification is sent to all subscribed\nusers or devices to report the file update.")]),e._v(" "),i("p",[e._v("The Synchronization Service should be designed in such a way that it transmits less data between\nclients and the Cloud Storage to achieve a better response time. To meet this design goal, the\nSynchronization Service can employ a differencing algorithm to reduce the amount of the data that\nneeds to be synchronized. Instead of transmitting entire files from clients to the server or vice versa, we\ncan just transmit the difference between two versions of a file. Therefore, only the part of the file that\nhas been changed is transmitted. This also decreases bandwidth consumption and cloud data storage for\nthe end user. As described above, we will be dividing our files into 4MB chunks and will be\ntransferring modified chunks only. Server and clients can calculate a hash (e.g., SHA-256) to see\nwhether to update the local copy of a chunk or not. On the server, if we already have a chunk with a\nsimilar hash (even from another user), we don’t need to create another copy, we can use the same\nchunk. This is discussed in detail later under Data Deduplication.")]),e._v(" "),i("p",[e._v("To be able to provide an efficient and scalable synchronization protocol we can consider using a\ncommunication middleware between clients and the Synchronization Service. The messaging\nmiddleware should provide scalable message queuing and change notifications to support a high\nnumber of clients using pull or push strategies. This way, multiple Synchronization Service instances\ncan receive requests from a global request Queue, and the communication middleware will be able to\nbalance its load.")]),e._v(" "),i("h3",{attrs:{id:"d-message-queuing-service"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#d-message-queuing-service"}},[e._v("#")]),e._v(" d. Message Queuing Service")]),e._v(" "),i("p",[e._v("An important part of our architecture is a messaging middleware that should be able to handle a\nsubstantial number of requests. A scalable Message Queuing Service that supports asynchronous\nmessage-based communication between clients and the Synchronization Service best fits the\nrequirements of our application. The Message Queuing Service supports asynchronous and loosely\ncoupled message-based communication between distributed components of the system. The Message\nQueuing Service should be able to efficiently store any number of messages in a highly available,\nreliable and scalable queue.")]),e._v(" "),i("p",[e._v("The Message Queuing Service will implement two types of queues in our system. The Request Queue\nis a global queue and all clients will share it. Clients’ requests to update the Metadata Database will be\nsent to the Request Queue first, from there the Synchronization Service will take it to update metadata.\nThe Response Queues that correspond to individual subscribed clients are responsible for delivering the\nupdate messages to each client. Since a message will be deleted from the queue once received by a\nclient, we need to create separate Response Queues for each subscribed client to share update\nmessages.")]),e._v(" "),i("p",[i("img",{attrs:{src:a(699),alt:"img"}})]),e._v(" "),i("h3",{attrs:{id:"e-cloud-block-storage"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#e-cloud-block-storage"}},[e._v("#")]),e._v(" e. Cloud/Block Storage")]),e._v(" "),i("p",[e._v("Cloud/Block Storage stores chunks of files uploaded by the users. Clients directly interact with the\nstorage to send and receive objects from it. Separation of the metadata from storage enables us to use\nany storage either in the cloud or in-house.")]),e._v(" "),i("p",[i("img",{attrs:{src:a(700),alt:"img"}}),i("br"),e._v(" "),i("em",[e._v("Detailed component design for Dropbox")])]),e._v(" "),i("h2",{attrs:{id:"_7-file-processing-workflow"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_7-file-processing-workflow"}},[e._v("#")]),e._v(" 7. File Processing Workflow")]),e._v(" "),i("p",[e._v("The sequence below shows the interaction between the components of the application in a scenario\nwhen Client A updates a file that is shared with Client B and C, so they should receive the update too.\nIf the other clients are not online at the time of the update, the Message Queuing Service keeps the\nupdate notifications in separate response queues for them until they come online later.")]),e._v(" "),i("ol",[i("li",[e._v("Client A uploads chunks to cloud storage.")]),e._v(" "),i("li",[e._v("Client A updates metadata and commits changes.")]),e._v(" "),i("li",[e._v("Client A gets confirmation and notifications are sent to Clients B and C about the changes.")]),e._v(" "),i("li",[e._v("Client B and C receive metadata changes and download updated chunks.")])]),e._v(" "),i("h2",{attrs:{id:"_8-data-deduplication"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_8-data-deduplication"}},[e._v("#")]),e._v(" 8. Data Deduplication")]),e._v(" "),i("p",[e._v("Data deduplication is a technique used for eliminating duplicate copies of data to improve storage\nutilization. It can also be applied to network data transfers to reduce the number of bytes that must be\nsent. For each new incoming chunk, we can calculate a hash of it and compare that hash with all the\nhashes of the existing chunks to see if we already have the same chunk present in our storage.\nWe can implement deduplication in two ways in our system:")]),e._v(" "),i("h3",{attrs:{id:"a-post-process-deduplication"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#a-post-process-deduplication"}},[e._v("#")]),e._v(" a. Post-process deduplication")]),e._v(" "),i("p",[e._v("With post-process deduplication, new chunks are first stored on the storage device and later some\nprocess analyzes the data looking for duplication. The benefit is that clients will not need to wait for the\nhash calculation or lookup to complete before storing the data, thereby ensuring that there is no\ndegradation in storage performance. Drawbacks of this approach are")]),e._v(" "),i("ol",[i("li",[e._v("We will unnecessarily be storing duplicate data, though for a short time")]),e._v(" "),i("li",[e._v("Duplicate data will be transferred consuming bandwidth.")])]),e._v(" "),i("h3",{attrs:{id:"b-in-line-deduplication"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#b-in-line-deduplication"}},[e._v("#")]),e._v(" b. In-line deduplication")]),e._v(" "),i("p",[e._v("Alternatively, deduplication hash calculations can be done in real-time as the clients are entering data\non their device. If our system identifies a chunk that it has already stored, only a reference to the\nexisting chunk will be added in the metadata, rather than a full copy of the chunk. This approach will\ngive us optimal network and storage usage.")]),e._v(" "),i("h2",{attrs:{id:"_9-metadata-partitioning"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_9-metadata-partitioning"}},[e._v("#")]),e._v(" 9. Metadata Partitioning")]),e._v(" "),i("p",[e._v("To scale out metadata DB, we need to partition it so that it can store information about millions of users\nand billions of files/chunks. We need to come up with a partitioning scheme that would divide and store\nour data in different DB servers.")]),e._v(" "),i("ol",[i("li",[i("p",[i("strong",[e._v("Vertical Partitioning")]),e._v(": We can partition our database in such a way that we store tables related to one particular feature on one server. For example, we can store all the user related tables in one database and all files/chunks related tables in another database. Although this approach is straightforward to implement it has some issues:")]),e._v(" "),i("ul",[i("li",[i("ol",[i("li",[e._v("Will we still have scale issues? What if we have trillions of chunks to be stored and our database cannot support storing such a huge number of records? How would we further partition such tables?")])])]),e._v(" "),i("li",[i("ol",{attrs:{start:"2"}},[i("li",[e._v("Joining two tables in two separate databases can cause performance and consistency issues. How frequently do we have to join user and file tables?")])])])])]),e._v(" "),i("li",[i("p",[i("strong",[e._v("Range Based Partitioning")]),e._v(": What if we store files/chunks in separate partitions based on the first letter of the File Path? In that case, we save all the files starting with the letter ‘A’ in one partition andthose that start with the letter ‘B’ into another partition and so on. This approach is called range based\npartitioning. We can even combine certain less frequently occurring letters into one database partition.\nWe should come up with this partitioning scheme statically so that we can always store/find a file in a\npredictable manner.")])])]),e._v(" "),i("p",[e._v("The main problem with this approach is that it can lead to unbalanced servers. For example, if we\ndecide to put all files starting with the letter ‘E’ into a DB partition, and later we realize that we have\ntoo many files that start with the letter ‘E’, to such an extent that we cannot fit them into one DB\npartition.")]),e._v(" "),i("ol",{attrs:{start:"3"}},[i("li",[i("strong",[e._v("Hash-Based Partitioning")]),e._v(": In this scheme we take a hash of the object we are storing and based on\nthis hash we figure out the DB partition to which this object should go. In our case, we can take the\nhash of the ‘FileID’ of the File object we are storing to determine the partition the file will be stored.\nOur hashing function will randomly distribute objects into different partitions, e.g., our hashing\nfunction can always map any ID to a number between "),i("code",[e._v("[1...256]")]),e._v(", and this number would be the partition\nwe will store our object.")])]),e._v(" "),i("p",[e._v("This approach can still lead to overloaded partitions, which can be solved by using Consistent Hashing.")]),e._v(" "),i("h2",{attrs:{id:"_10-caching"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_10-caching"}},[e._v("#")]),e._v(" 10. Caching")]),e._v(" "),i("p",[e._v("We can have two kinds of caches in our system. To deal with hot files/chunks we can introduce a cache\nfor Block storage. We can use an off-the-shelf solution like Memcached that can store whole chunks\nwith its respective IDs/Hashes and Block servers before hitting Block storage can quickly check if the\ncache has desired chunk. Based on clients’ usage pattern we can determine how many cache servers we\nneed. A high-end commercial server can have 144GB of memory; one such server can cache 36K\nchunks.")]),e._v(" "),i("p",[i("strong",[e._v("Which cache replacement policy would best fit our needs?")]),e._v(" When the cache is full, and we want to\nreplace a chunk with a newer/hotter chunk, how would we choose? Least Recently Used (LRU) can be\na reasonable policy for our system. Under this policy, we discard the least recently used chunk first.\nLoad Similarly, we can have a cache for Metadata DB.")]),e._v(" "),i("h2",{attrs:{id:"_11-load-balancer-lb"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_11-load-balancer-lb"}},[e._v("#")]),e._v(" 11. Load Balancer (LB)")]),e._v(" "),i("p",[e._v("We can add the Load balancing layer at two places in our system:")]),e._v(" "),i("ol",[i("li",[e._v("Between Clients and Block servers")]),e._v(" "),i("li",[e._v("Between Clients and Metadata servers.")])]),e._v(" "),i("p",[e._v("Initially, a simple Round Robin approach can be adopted that distributes incoming requests equally among backend servers. This LB is simple to implement and does not introduce any overhead. Another benefit of this approach is if a server is dead, LB will take it out of the rotation and will stop sending any traffic to it. A problem with Round Robin LB is, it won’t\ntake server load into consideration. If a server is overloaded or slow, the LB will not stop sending new\nrequests to that server. To handle this, a more intelligent LB solution can be placed that periodically\nqueries backend server about their load and adjusts traffic based on that.")]),e._v(" "),i("h2",{attrs:{id:"_12-security-permissions-and-file-sharing"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_12-security-permissions-and-file-sharing"}},[e._v("#")]),e._v(" 12. Security, Permissions and File Sharing")]),e._v(" "),i("p",[e._v("One of the primary concerns users will have while storing their files in the cloud is the privacy and\nsecurity of their data, especially since in our system users can share their files with other users or even\nmake them public to share it with everyone. To handle this, we will be storing the permissions of each\nfile in our metadata DB to reflect what files are visible or modifiable by any user.")])])}),[],!1,null,null,null);t.default=s.exports},697:function(e,t,a){e.exports=a.p+"assets/img/4.ec9e5421.png"},698:function(e,t,a){e.exports=a.p+"assets/img/5.a196ad04.png"},699:function(e,t,a){e.exports=a.p+"assets/img/6.6e073b84.png"},700:function(e,t,a){e.exports=a.p+"assets/img/7.5736e5f7.png"}}]);