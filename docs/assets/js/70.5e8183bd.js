(window.webpackJsonp=window.webpackJsonp||[]).push([[70],{576:function(e,t,a){"use strict";a.r(t);var n=a(7),o=Object(n.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h2",{attrs:{id:"chapter-9-document-databases"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#chapter-9-document-databases"}},[e._v("#")]),e._v(" Chapter 9. Document Databases")]),e._v(" "),a("p",[e._v("Documents are the main concept in document databases. The database stores and retrieves documents,\nwhich can be XML, JSON, BSON, and so on. These documents are self-describing, hierarchical tree\ndata structures which can consist of maps, collections, and scalar values. The documents stored are\nsimilar to each other but do not have to be exactly the same. Document databases store documents in\nthe value part of the key-value store; think about document databases as key-value stores where the\nvalue is examinable. Let’s look at how terminology compares in Oracle and MongoDB.")]),e._v(" "),a("p",[e._v("The _id is a special field that is found on all documents in Mongo, just like ROWID in Oracle. In\nMongoDB, _id can be assigned by the user, as long as it is unique.")]),e._v(" "),a("h3",{attrs:{id:"_9-1-what-is-a-document-database"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_9-1-what-is-a-document-database"}},[e._v("#")]),e._v(" 9.1. What Is a Document Database?")]),e._v(" "),a("p",[a("strong",[e._v("Click here to view code image")])]),e._v(" "),a("p",[e._v('{ "firstname": "Martin",\n"likes": [ "Biking",\n"Photography" ],\n"lastcity": "Boston",\n"lastVisited":\n}')]),e._v(" "),a("p",[e._v("The above document can be considered a row in a traditional RDBMS. Let’s look at another\ndocument:")]),e._v(" "),a("p",[a("strong",[e._v("Click here to view code image")])]),e._v(" "),a("p",[e._v('{\n"firstname": "Pramod",\n"citiesvisited": [ "Chicago", "London", "Pune", "Bangalore" ],\n"addresses": [\n{ "state": "AK",\n"city": "DILLINGHAM",\n"type": "R"\n},\n{ "state": "MH",\n"city": "PUNE",\n"type": "R" }\n],')]),e._v(" "),a("p",[e._v('"lastcity": "Chicago"\n}')]),e._v(" "),a("p",[e._v("Looking at the documents, we can see that they are similar, but have differences in attribute names.\nThis is allowed in document databases. The schema of the data can differ across documents, but these\ndocuments can still belong to the same collection—unlike an RDBMS where every row in a table has\nto follow the same schema. We represent a list of citiesvisited as an array, or a list of addresses\nas list of documents embedded inside the main document. Embedding child documents as subobjects\ninside documents provides for easy access and better performance.")]),e._v(" "),a("p",[e._v("If you look at the documents, you will see that some of the attributes are similar, such as\nfirstname or city. At the same time, there are attributes in the second document which do not exist\nin the first document, such as addresses, while likes is in the first document but not the second.")]),e._v(" "),a("p",[e._v("This different representation of data is not the same as in RDBMS where every column has to be\ndefined, and if it does not have data it is marked as empty or set to null. In documents, there are no\nempty attributes; if a given attribute is not found, we assume that it was not set or not relevant to the\ndocument. Documents allow for new attributes to be created without the need to define them or to\nchange the existing documents.")]),e._v(" "),a("p",[e._v("Some of the popular document databases we have seen are MongoDB [MongoDB], CouchDB\n[CouchDB], Terrastore [Terrastore], OrientDB [OrientDB], RavenDB [RavenDB], and of course the\nwell-known and often reviled Lotus Notes [Notes Storage Facility] that uses document storage.")]),e._v(" "),a("h3",{attrs:{id:"_9-2-features"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_9-2-features"}},[e._v("#")]),e._v(" 9.2. Features")]),e._v(" "),a("p",[e._v("While there are many specialized document databases, we will use MongoDB as a representative of\nthe feature set. Keep in mind that each product has some features that may not be found in other\ndocument databases.")]),e._v(" "),a("p",[e._v("Let’s take some time to understand how MongoDB works. Each MongoDB instance has multiple\n"),a("em",[e._v("databases")]),e._v(" , and each database can have multiple "),a("em",[e._v("collections")]),e._v(". When we compare this with RDBMS, an\nRDBMS instance is the same as MongoDB instance, the schemas in RDBMS are similar to MongoDB\ndatabases, and the RDBMS tables are collections in MongoDB. When we store a document, we have\nto choose which database and collection this document belongs in—for example,\ndatabase.collection.insert(document), which is usually represented as\ndb.coll.insert(document).")]),e._v(" "),a("p",[a("strong",[e._v("9.2.1. Consistency")])]),e._v(" "),a("p",[e._v("Consistency in MongoDB database is configured by using the "),a("strong",[e._v("replica sets")]),e._v(" and choosing to wait for\nthe writes to be replicated to all the slaves or a given number of slaves. Every write can specify the\nnumber of servers the write has to be propagated to before it returns as successful.")]),e._v(" "),a("p",[e._v('A command like db.runCommand({ getlasterror : 1 , w : "majority" }) tells the\ndatabase how strong is the consistency you want. For example, if you have one server and specify the\nw as majority, the write will return immediately since there is only one node. If you have three\nnodes in the replica set and specify w as majority, the write will have to complete at a minimum of\ntwo nodes before it is reported as a success. You can increase the w value for stronger consistency\nbut you will suffer on write performance, since now the writes have to complete at more nodes.\nReplica sets also allow you to increase the read performance by allowing reading from slaves by\nsetting slaveOk; this parameter can be set on the connection, or database, or collection, or')]),e._v(" "),a("p",[e._v("individually for each operation.")]),e._v(" "),a("p",[a("strong",[e._v("Click here to view code image")])]),e._v(" "),a("p",[e._v('Mongo mongo = new Mongo("localhost:27017");\nmongo.slaveOk();')]),e._v(" "),a("p",[e._v("Here we are setting slaveOk per operation, so that we can decide which operations can work with\ndata from the slave node.")]),e._v(" "),a("p",[a("strong",[e._v("Click here to view code image")])]),e._v(" "),a("p",[e._v('DBCollection collection = getOrderCollection();\nBasicDBObject query = new BasicDBObject();\nquery.put("name", "Martin");\nDBCursor cursor = collection.find(query).slaveOk();')]),e._v(" "),a("p",[e._v("Similar to various options available for read, you can change the settings to achieve strong write\nconsistency, if desired. By default, a write is reported successful once the database receives it; you\ncan change this so as to wait for the writes to be synced to disk or to propagate to two or more slaves.\nThis is known as WriteConcern: You make sure that certain writes are written to the master and\nsome slaves by setting WriteConcern to REPLICAS_SAFE. Shown below is code where we are\nsetting the WriteConcern for all writes to a collection:")]),e._v(" "),a("p",[a("strong",[e._v("Click here to view code image")])]),e._v(" "),a("p",[e._v('DBCollection shopping = database.getCollection("shopping");\nshopping.setWriteConcern(REPLICAS_SAFE);')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("WriteConcern can also be set per operation by specifying it on the save command:\n")])])]),a("p",[a("strong",[e._v("Click here to view code image")])]),e._v(" "),a("p",[e._v("WriteResult result = shopping.insert(order, REPLICAS_SAFE);")]),e._v(" "),a("p",[e._v("There is a tradeoff that you need to carefully think about, based on your application needs and\nbusiness requirements, to decide what settings make sense for slaveOk during read or what safety\nlevel you desire during write with WriteConcern.")]),e._v(" "),a("p",[a("strong",[e._v("9.2.2. Transactions")])]),e._v(" "),a("p",[e._v("Transactions, in the traditional RDBMS sense, mean that you can start modifying the database with\ninsert, update, or delete commands over different tables and then decide if you want to keep the\nchanges or not by using commit or rollback. These constructs are generally not available in NoSQL\nsolutions—a write either succeeds or fails. Transactions at the single-document level are known as\n"),a("strong",[e._v("atomic transactions")]),e._v(". Transactions involving more than one operation are not possible, although there\nare products such as RavenDB that do support transactions across multiple operations.")]),e._v(" "),a("p",[e._v("By default, all writes are reported as successful. A finer control over the write can be achieved by\nusing WriteConcern parameter. We ensure that order is written to more than one node before it’s\nreported successful by using WriteConcern.REPLICAS_SAFE. Different levels of WriteConcern let\nyou choose the safety level during writes; for example, when writing log entries, you can use lowest\nlevel of safety, WriteConcern.NONE.")]),e._v(" "),a("p",[a("strong",[e._v("Click here to view code image")])]),e._v(" "),a("p",[e._v("final Mongo mongo = new Mongo(mongoURI);\nmongo.setWriteConcern(REPLICAS_SAFE);")]),e._v(" "),a("p",[e._v("DBCollection shopping = mongo.getDB(orderDatabase)\n.getCollection(shoppingCollection);\ntry {\nWriteResult result = shopping.insert(order, REPLICAS_SAFE);\n//Writes made it to primary and at least one secondary\n} catch (MongoException writeException) {\n//Writes did not make it to minimum of two nodes including primary\ndealWithWriteFailure(order, writeException);\n}")]),e._v(" "),a("p",[a("strong",[e._v("9.2.3. Availability")])]),e._v(" "),a("p",[e._v("The CAP theorem (“The CAP Theorem,” p. 53 ) dictates that we can have only two of Consistency,\nAvailability, and Partition Tolerance. Document databases try to improve on availability by\nreplicating data using the master-slave setup. The same data is available on multiple nodes and the\nclients can get to the data even when the primary node is down. Usually, the application code does\nnot have to determine if the primary node is available or not. MongoDB implements replication,\nproviding high availability using "),a("strong",[e._v("replica sets")]),e._v(".")]),e._v(" "),a("p",[e._v("In a replica set, there are two or more nodes participating in an asynchronous master-slave\nreplication. The replica-set nodes elect the master, or primary, among themselves. Assuming all the\nnodes have equal voting rights, some nodes can be favored for being closer to the other servers, for\nhaving more RAM, and so on; users can affect this by assigning a priority—a number between 0 and\n1000—to a node.")]),e._v(" "),a("p",[e._v("All requests go to the master node, and the data is replicated to the slave nodes. If the master node\ngoes down, the remaining nodes in the replica set vote among themselves to elect a new master; all\nfuture requests are routed to the new master, and the slave nodes start getting data from the new\nmaster. When the node that failed comes back online, it joins in as a slave and catches up with the rest\nof the nodes by pulling all the data it needs to get current.")]),e._v(" "),a("p",[e._v("Figure 9.1 is an example configuration of replica sets. We have two nodes, "),a("strong",[e._v("mongo A")]),e._v(" and "),a("strong",[e._v("mongo\nB")]),e._v(" , running the MongoDB database in the primary data-center, and "),a("strong",[e._v("mongo C")]),e._v(" in the secondary\ndatacenter. If we want nodes in the primary datacenter to be elected as primary nodes, we can assign\nthem a higher priority than the other nodes. More nodes can be added to the replica sets without\nhaving to take them offline.")]),e._v(" "),a("p",[a("strong",[e._v("Figure 9.1. Replica set configuration with higher priority assigned to nodes in the same\ndatacenter")]),e._v("\nThe application writes or reads from the primary (master) node. When connection is established,\nthe application only needs to connect to one node (primary or not, does not matter) in the replica set,\nand the rest of the nodes are discovered automatically. When the primary node goes down, the driver\ntalks to the new primary elected by the replica set. The application does not have to manage any of\nthe communication failures or node selection criteria. Using replica sets gives you the ability to have\na highly available document data store.")]),e._v(" "),a("p",[e._v("Replica sets are generally used for data redundancy, automated failover, read scaling, server\nmaintenance without downtime, and disaster recovery. Similar availability setups can be achieved\nwith CouchDB, RavenDB, Terrastore, and other products.")]),e._v(" "),a("p",[a("strong",[e._v("9.2.4. Query Features")])]),e._v(" "),a("p",[e._v("Document databases provide different query features. CouchDB allows you to query via views—\ncomplex queries on documents which can be either materialized (“Materialized Views,” p. 30 ) or\ndynamic (think of them as RDBMS views which are either materialized or not). With CouchDB, if\nyou need to aggregate the number of reviews for a product as well as the average rating, you could\nadd a view implemented via map-reduce (“Basic Map-Reduce,” p. 68 ) to return the count of reviews\nand the average of their ratings.")]),e._v(" "),a("p",[e._v("When there are many requests, you don’t want to compute the count and average for every request;\ninstead you can add a materialized view that precomputes the values and stores the results in the\ndatabase. These materialized views are updated when queried, if any data was changed since the last\nupdate.")]),e._v(" "),a("p",[e._v("One of the good features of document databases, as compared to key-value stores, is that we can\nquery the data inside the document without having to retrieve the whole document by its key and then\nintrospect the document. This feature brings these databases closer to the RDBMS query model.")]),e._v(" "),a("p",[e._v("MongoDB has a query language which is expressed via JSON and has constructs such as $query\nfor the where clause, $orderby for sorting the data, or $explain to show the execution plan of the\nquery. There are many more constructs like these that can be combined to create a MongoDB query.")]),e._v(" "),a("p",[e._v("Let’s look at certain queries that we can do against MongoDB. Suppose we want to return all the\ndocuments in an order collection (all rows in the order table). The SQL for this would be:")]),e._v(" "),a("p",[e._v("SELECT * FROM order")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("The equivalent query in Mongo shell would be:\n")])])]),a("p",[e._v("db.order.find()")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("Selecting the orders for a single customerId of 883c2c5b4e5b would be:\n")])])]),a("p",[a("strong",[e._v("Click here to view code image")])]),e._v(" "),a("p",[e._v('SELECT * FROM order WHERE customerId = "883c2c5b4e5b"')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("The equivalent query in Mongo to get all orders for a single customerId of 883c2c5b4e5b:\n")])])]),a("p",[a("strong",[e._v("Click here to view code image")])]),e._v(" "),a("p",[e._v('db.order.find({"customerId":"883c2c5b4e5b"})')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("Similarly, selecting orderId and orderDate for one customer in SQL would be:\n")])])]),a("p",[a("strong",[e._v("Click here to view code image")])]),e._v(" "),a("p",[e._v('SELECT orderId,orderDate FROM order WHERE customerId = "883c2c5b4e5b"')]),e._v(" "),a("p",[e._v("and the equivalent in Mongo would be:")]),e._v(" "),a("p",[a("strong",[e._v("Click here to view code image")])]),e._v(" "),a("p",[e._v('db.order.find({customerId:"883c2c5b4e5b"},{orderId:1,orderDate:1})')]),e._v(" "),a("p",[e._v("Similarly, queries to count, sum, and so on are all available. Since the documents are aggregated\nobjects, it is really easy to query for documents that have to be matched using the fields with child\nobjects. Let’s say we want to query for all the orders where one of the items ordered has a name like\nRefactoring. The SQL for this requirement would be:")]),e._v(" "),a("p",[a("strong",[e._v("Click here to view code image")])]),e._v(" "),a("p",[e._v("SELECT * FROM customerOrder, orderItem, product\nWHERE\ncustomerOrder.orderId = orderItem.customerOrderId\nAND orderItem.productId = product.productId\nAND product.name LIKE '%Refactoring%'")]),e._v(" "),a("p",[e._v("and the equivalent Mongo query would be:")]),e._v(" "),a("p",[a("strong",[e._v("Click here to view code image")])]),e._v(" "),a("p",[e._v('db.orders.find({"items.product.name":/Refactoring/})')]),e._v(" "),a("p",[e._v("The query for MongoDB is simpler because the objects are embedded inside a single document\nand you can query based on the embedded child documents.")]),e._v(" "),a("p",[a("strong",[e._v("9.2.5. Scaling")])]),e._v(" "),a("p",[e._v("The idea of scaling is to add nodes or change data storage without simply migrating the database to a\nbigger box. We are not talking about making application changes to handle more load; instead, we are\ninterested in what features are in the database so that it can handle more load.")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("Scaling for heavy-read loads can be achieved by adding more read slaves, so that all the reads can\n")])])]),a("p",[e._v("be directed to the slaves. Given a heavy-read application, with our 3-node replica-set cluster, we can\nadd more read capacity to the cluster as the read load increases just by adding more slave nodes to\nthe replica set to execute reads with the slaveOk flag (Figure 9.2). This is horizontal scaling for\nreads.")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("Figure 9.2. Adding a new node, mongo D, to an existing replica-set cluster\nOnce the new node, mongo D, is started, it needs to be added to the replica set.\n")])])]),a("p",[e._v('rs.add("mongod:27017");')]),e._v(" "),a("p",[e._v("When a new node is added, it will sync up with the existing nodes, join the replica set as\nsecondary node, and start serving read requests. An advantage of this setup is that we do not have to\nrestart any other nodes, and there is no downtime for the application either.")]),e._v(" "),a("p",[e._v("When we want to scale for write, we can start sharding (“Sharding,” p. 38 ) the data. Sharding is\nsimilar to partitions in RDBMS where we split data by value in a certain column, such as state or\nyear. With RDBMS, partitions are usually on the same node, so the client application does not have to\nquery a specific partition but can keep querying the base table; the RDBMS takes care of finding the\nright partition for the query and returns the data.")]),e._v(" "),a("p",[e._v("In sharding, the data is also split by certain field, but then moved to different Mongo nodes. The\ndata is dynamically moved between nodes to ensure that shards are always balanced. We can add\nmore nodes to the cluster and increase the number of writable nodes, enabling horizontal scaling for\nwrites.")]),e._v(" "),a("p",[a("strong",[e._v("Click here to view code image")])]),e._v(" "),a("p",[e._v('db.runCommand( { shardcollection : "ecommerce.customer",\nkey : {firstname : 1} } )')]),e._v(" "),a("p",[e._v("Splitting the data on the first name of the customer ensures that the data is balanced across the\nshards for optimal write performance; furthermore, each shard can be a replica set ensuring better\nread performance within the shard (Figure 9.3). When we add a new shard to this existing sharded\ncluster, the data will now be balanced across four shards instead of three. As all this data movement\nand infrastructure refactoring is happening, the application will not experience any downtime,\nalthough the cluster may not perform optimally when large amounts of data are being moved to\nrebalance the shards.")]),e._v(" "),a("p",[a("strong",[e._v("Figure 9.3. MongoDB sharded setup where each shard is a replica set")]),e._v("\nThe shard key plays an important role. You may want to place your MongoDB database shards\ncloser to their users, so sharding based on user location may be a good idea. When sharding by\ncustomer location, all user data for the East Coast of the USA is in the shards that are served from the\nEast Coast, and all user data for the West Coast is in the shards that are on the West Coast.")]),e._v(" "),a("h3",{attrs:{id:"_9-3-suitable-use-cases"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_9-3-suitable-use-cases"}},[e._v("#")]),e._v(" 9.3. Suitable Use Cases")]),e._v(" "),a("p",[a("strong",[e._v("9.3.1. Event Logging")])]),e._v(" "),a("p",[e._v("Applications have different event logging needs; within the enterprise, there are many different\napplications that want to log events. Document databases can store all these different types of events\nand can act as a central data store for event storage. This is especially true when the type of data\nbeing captured by the events keeps changing. Events can be sharded by the name of the application\nwhere the event originated or by the type of event such as order_processed or customer_logged.")]),e._v(" "),a("p",[a("strong",[e._v("9.3.2. Content Management Systems, Blogging Platforms")])]),e._v(" "),a("p",[e._v("Since document databases have no predefined schemas and usually understand JSON documents, they\nwork well in content management systems or applications for publishing websites, managing user\ncomments, user registrations, profiles, web-facing documents.")]),e._v(" "),a("p",[a("strong",[e._v("9.3.3. Web Analytics or Real-Time Analytics")])]),e._v(" "),a("p",[e._v("Document databases can store data for real-time analytics; since parts of the document can be\nupdated, it’s very easy to store page views or unique visitors, and new metrics can be easily added\nwithout schema changes.")]),e._v(" "),a("p",[a("strong",[e._v("9.3.4. E-Commerce Applications")])]),e._v(" "),a("p",[e._v("E-commerce applications often need to have flexible schema for products and orders, as well as the\nability to evolve their data models without expensive database refactoring or data migration\n(“Schema Changes in a NoSQL Data Store,” p. 128 ).")]),e._v(" "),a("h3",{attrs:{id:"_9-4-when-not-to-use"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_9-4-when-not-to-use"}},[e._v("#")]),e._v(" 9.4. When Not to Use")]),e._v(" "),a("p",[e._v("There are problem spaces where document databases are not the best solution.")]),e._v(" "),a("p",[a("strong",[e._v("9.4.1. Complex Transactions Spanning Different Operations")])]),e._v(" "),a("p",[e._v("If you need to have atomic cross-document operations, then document databases may not be for you.\nHowever, there are some document databases that do support these kinds of operations, such as\nRavenDB.")]),e._v(" "),a("p",[a("strong",[e._v("9.4.2. Queries against Varying Aggregate Structure")])]),e._v(" "),a("p",[e._v("Flexible schema means that the database does not enforce any restrictions on the schema. Data is\nsaved in the form of application entities. If you need to query these entities ad hoc, your queries will\nbe changing (in RDBMS terms, this would mean that as you join criteria between tables, the tables to\njoin keep changing). Since the data is saved as an aggregate, if the design of the aggregate is\nconstantly changing, you need to save the aggregates at the lowest level of granularity—basically, you\nneed to normalize the data. In this scenario, document databases may not work.")])])}),[],!1,null,null,null);t.default=o.exports}}]);