(window.webpackJsonp=window.webpackJsonp||[]).push([[101],{1067:function(e,t,a){e.exports=a.p+"assets/img/20.7a5b481f.png"},1068:function(e,t,a){e.exports=a.p+"assets/img/21.221dda3c.png"},1649:function(e,t,a){"use strict";a.r(t);var s=a(7),n=Object(s.a)({},(function(){var e=this,t=e.$createElement,s=e._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[s("h1",{attrs:{id:"designing-twitter-search"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#designing-twitter-search"}},[e._v("#")]),e._v(" Designing Twitter Search")]),e._v(" "),s("p",[e._v("Twitter is one of the largest social networking service where users can share photos, news, and textbased messages. In this chapter, we will design a service that can store and search user tweets. Similar Problems: Tweet search.")]),e._v(" "),s("p",[e._v("Difficulty Level: Medium")]),e._v(" "),s("h2",{attrs:{id:"_1-what-is-twitter-search"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-what-is-twitter-search"}},[e._v("#")]),e._v(" 1. What is Twitter Search?")]),e._v(" "),s("p",[e._v("Twitter users can update their status whenever they like. Each status (called tweet) consists of plain text\nand our goal is to design a system that allows searching over all the user tweets.")]),e._v(" "),s("h2",{attrs:{id:"_2-requirements-and-goals-of-the-system"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-requirements-and-goals-of-the-system"}},[e._v("#")]),e._v(" 2. Requirements and Goals of the System")]),e._v(" "),s("ul",[s("li",[e._v("Let’s assume Twitter has 1.5 billion total users with 800 million daily active users.")]),e._v(" "),s("li",[e._v("On average Twitter gets 400 million tweets every day.")]),e._v(" "),s("li",[e._v("The average size of a tweet is 300 bytes.")]),e._v(" "),s("li",[e._v("Let’s assume there will be 500M searches every day.")]),e._v(" "),s("li",[e._v("The search query will consist of multiple words combined with AND/OR.")])]),e._v(" "),s("p",[e._v("We need to design a system that can efficiently store and query tweets.")]),e._v(" "),s("h2",{attrs:{id:"_3-capacity-estimation-and-constraints"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-capacity-estimation-and-constraints"}},[e._v("#")]),e._v(" 3. Capacity Estimation and Constraints")]),e._v(" "),s("p",[s("strong",[e._v("Storage Capacity")]),e._v(": Since we have 400 million new tweets every day and each tweet on average is 300\nbytes, the total storage we need, will be:")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("400M * 300 => 120GB/day\n")])])]),s("p",[e._v("Total storage per second:")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("120GB / 24hours / 3600sec ~= 1.38MB/second \n")])])]),s("h2",{attrs:{id:"_4-system-apis"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-system-apis"}},[e._v("#")]),e._v(" 4. System APIs")]),e._v(" "),s("p",[e._v("We can have SOAP or REST APIs to expose functionality of our service; following could be the\ndefinition of the search API:")]),e._v(" "),s("p",[s("code",[e._v("search(api_dev_key, search_terms, maximum_results_to_return, sort, page_token)")])]),e._v(" "),s("p",[s("strong",[e._v("Parameters")]),e._v(":")]),e._v(" "),s("ul",[s("li",[e._v("api_dev_key (string): The API developer key of a registered account. This will be used to, among other things, throttle users based on their allocated quota.")]),e._v(" "),s("li",[e._v("search_terms (string): A string containing the search terms.")]),e._v(" "),s("li",[e._v("maximum_results_to_return (number): Number of tweets to return.")]),e._v(" "),s("li",[e._v("sort (number): Optional sort mode: Latest first (0 - default), Best matched (1), Most liked (2).")]),e._v(" "),s("li",[e._v("page_token (string): This token will specify a page in the result set that should be returned.")])]),e._v(" "),s("p",[s("strong",[e._v("Returns")]),e._v(": (JSON)\nA JSON containing information about a list of tweets matching the search query. Each result entry can have the user ID & name, tweet text, tweet ID, creation time, number of likes, etc.")]),e._v(" "),s("h2",{attrs:{id:"_5-high-level-design"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-high-level-design"}},[e._v("#")]),e._v(" 5. High Level Design")]),e._v(" "),s("p",[e._v("At the high level, we need to store all the statues in a database and also build an index that can keep\ntrack of which word appears in which tweet. This index will help us quickly find tweets that users are\ntrying to search.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(1067),alt:"img"}}),s("br"),e._v(" "),s("em",[e._v("High level design for Twitter search")])]),e._v(" "),s("h2",{attrs:{id:"_6-detailed-component-design"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_6-detailed-component-design"}},[e._v("#")]),e._v(" 6. Detailed Component Design")]),e._v(" "),s("h3",{attrs:{id:"_1-storage"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-storage"}},[e._v("#")]),e._v(" 1. Storage:")]),e._v(" "),s("p",[e._v("We need to store 120GB of new data every day. Given this huge amount of data, we need\nto come up with a data partitioning scheme that will be efficiently distributing the data onto multiple\nservers. If we plan for next five years, we will need the following storage:")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("120GB * 365days * 5years ~= 200TB\n")])])]),s("p",[e._v("If we never want to be more than 80% full at any time, we approximately will need 250TB of total\nstorage. Let’s assume that we want to keep an extra copy of all tweets for fault tolerance; then, our total\nstorage requirement will be 500TB. If we assume a modern server can store up to 4TB of data, we\nwould need 125 such servers to hold all of the required data for the next five years.\nLet’s start with a simplistic design where we store the tweets in a MySQL database. We can assume that\nwe store the tweets in a table having two columns, TweetID and TweetText. Let’s assume we partition\nour data based on TweetID. If our TweetIDs are unique system-wide, we can define a hash function that\ncan map a TweetID to a storage server where we can store that tweet object.\nHow can we create system-wide unique TweetIDs? If we are getting 400M new tweets each day,\nthen how many tweet objects we can expect in five years?")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("400M * 365 days * 5 years => 730 billion\n")])])]),s("p",[e._v("This means we would need a five bytes number to identify TweetIDs uniquely. Let’s assume we have a\nservice that can generate a unique TweetID whenever we need to store an object (The TweetID\ndiscussed here will be similar to TweetID discussed in Designing Twitter). We can feed the TweetID to\nour hash function to find the storage server and store our tweet object there.")]),e._v(" "),s("h3",{attrs:{id:"_2-index"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-index"}},[e._v("#")]),e._v(" 2. Index:")]),e._v(" "),s("p",[e._v("What should our index look like? Since our tweet queries will consist of words, let’s build the\nindex that can tell us which word comes in which tweet object. Let’s first estimate how big our index\nwill be. If we want to build an index for all the English words and some famous nouns like people\nnames, city names, etc., and if we assume that we have around 300K English words and 200K nouns,\nthen we will have 500k total words in our index. Let’s assume that the average length of a word is five\ncharacters. If we are keeping our index in memory, we need 2.5MB of memory to store all the words:")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("500K * 5 => 2.5 MB\n")])])]),s("p",[e._v("Let’s assume that we want to keep the index in memory for all the tweets from only past two years.\nSince we will be getting 730B tweets in 5 years, this will give us 292B tweets in two years. Given that\neach TweetID will be 5 bytes, how much memory will we need to store all the TweetIDs?")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("292B * 5 => 1460 GB\n")])])]),s("p",[e._v("So our index would be like a big distributed hash table, where ‘key’ would be the word and ‘value’ will\nbe a list of TweetIDs of all those tweets which contain that word. Assuming on average we have 40\nwords in each tweet and since we will not be indexing prepositions and other small words like ‘the’,\n‘an’, ‘and’ etc., let’s assume we will have around 15 words in each tweet that need to be indexed. This\nmeans each TweetID will be stored 15 times in our index. So total memory we will need to store our\nindex:")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("(1460 * 15) + 2.5MB ~= 21 TB\n")])])]),s("p",[e._v("Assuming a high-end server has 144GB of memory, we would need 152 such servers to hold our index.\nWe can shard our data based on two criteria:\nSharding based on Words: While building our index, we will iterate through all the words of a tweet\nand calculate the hash of each word to find the server where it would be indexed. To find all tweets\ncontaining a specific word we have to query only the server which contains this word.\nWe have a couple of issues with this approach:")]),e._v(" "),s("ol",[s("li",[e._v("What if a word becomes hot? Then there will be a lot of queries on the server holding that word. This high load will affect the performance of our service.")]),e._v(" "),s("li",[e._v("Over time, some words can end up storing a lot of TweetIDs compared to others, therefore, maintaining a uniform distribution of words while tweets are growing is quite tricky.")])]),e._v(" "),s("p",[e._v("To recover from these situations we either have to repartition our data or use Consistent Hashing.\nSharding based on the tweet object: While storing, we will pass the TweetID to our hash function to\nfind the server and index all the words of the tweet on that server. While querying for a particular word,\nwe have to query all the servers, and each server will return a set of TweetIDs. A centralized server will\naggregate these results to return them to the user.")]),e._v(" "),s("p",[s("img",{attrs:{src:a(1068),alt:"img"}}),e._v(" "),s("em",[e._v("Detailed component design")])]),e._v(" "),s("h2",{attrs:{id:"_7-fault-tolerance"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_7-fault-tolerance"}},[e._v("#")]),e._v(" 7. Fault Tolerance")]),e._v(" "),s("p",[e._v("What will happen when an index server dies? We can have a secondary replica of each server and if the\nprimary server dies it can take control after the failover. Both primary and secondary servers will have\nthe same copy of the index.")]),e._v(" "),s("p",[e._v("What if both primary and secondary servers die at the same time? We have to allocate a new server and\nrebuild the same index on it. How can we do that? We don’t know what words/tweets were kept on this\nserver. If we were using ‘Sharding based on the tweet object’, the brute-force solution would be to\niterate through the whole database and filter TweetIDs using our hash function to figure out all the\nrequired tweets that would be stored on this server. This would be inefficient and also during the time\nwhen the server was being rebuilt we would not be able to serve any query from it, thus missing some\ntweets that should have been seen by the user.")]),e._v(" "),s("p",[e._v("How can we efficiently retrieve a mapping between tweets and the index server? We have to build a\nreverse index that will map all the TweetID to their index server. Our Index-Builder server can hold this\ninformation. We will need to build a Hashtable where the ‘key’ will be the index server number and the\n‘value’ will be a HashSet containing all the TweetIDs being kept at that index server. Notice that we are\nkeeping all the TweetIDs in a HashSet; this will enable us to add/remove tweets from our index\nquickly. So now, whenever an index server has to rebuild itself, it can simply ask the Index-Builder\nserver for all the tweets it needs to store and then fetch those tweets to build the index. This approach\nwill surely be fast. We should also have a replica of the Index-Builder server for fault tolerance.")]),e._v(" "),s("h2",{attrs:{id:"_8-cache"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_8-cache"}},[e._v("#")]),e._v(" 8. Cache")]),e._v(" "),s("p",[e._v("To deal with hot tweets we can introduce a cache in front of our database. We can use Memcached,\nwhich can store all such hot tweets in memory. Application servers, before hitting the backend\ndatabase, can quickly check if the cache has that tweet. Based on clients’ usage patterns, we can adjust\nhow many cache servers we need. For cache eviction policy, Least Recently Used (LRU) seems\nsuitable for our system.")]),e._v(" "),s("h2",{attrs:{id:"_9-load-balancing"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_9-load-balancing"}},[e._v("#")]),e._v(" 9. Load Balancing")]),e._v(" "),s("p",[e._v("We can add a load balancing layer at two places in our system")]),e._v(" "),s("ol",[s("li",[e._v("Between Clients and Application servers and")]),e._v(" "),s("li",[e._v("Between Application servers and Backend server. Initially, a simple Round Robin approach can be adopted; that distributes incoming requests equally among backend servers.")])]),e._v(" "),s("p",[e._v("This LB is simple to implement and does not introduce any overhead. Another benefit of this approach is LB will\ntake dead servers out of the rotation and will stop sending any traffic to it. A problem with Round\nRobin LB is it won’t take server load into consideration. If a server is overloaded or slow, the LB will\nnot stop sending new requests to that server. To handle this, a more intelligent LB solution can be\nplaced that periodically queries the backend server about their load and adjust traffic based on that.")]),e._v(" "),s("h2",{attrs:{id:"_10-ranking"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_10-ranking"}},[e._v("#")]),e._v(" 10. Ranking")]),e._v(" "),s("p",[e._v("How about if we want to rank the search results by social graph distance, popularity, relevance, etc?\nLet’s assume we want to rank tweets by popularity, like how many likes or comments a tweet is getting,\netc. In such a case, our ranking algorithm can calculate a ‘popularity number’ (based on the number of\nlikes etc.) and store it with the index. Each partition can sort the results based on this popularity number\nbefore returning results to the aggregator server. The aggregator server combines all these results, sorts\nthem based on the popularity number, and sends the top results to the user.")])])}),[],!1,null,null,null);t.default=n.exports}}]);