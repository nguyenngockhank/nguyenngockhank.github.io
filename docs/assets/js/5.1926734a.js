(window.webpackJsonp=window.webpackJsonp||[]).push([[5],{1059:function(e,t,a){"use strict";a.r(t);var o=a(7),n=Object(o.a)({},(function(){var e=this,t=e.$createElement,o=e._self._c||t;return o("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[o("h1",{attrs:{id:"chapter-7-map-reduce"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#chapter-7-map-reduce"}},[e._v("#")]),e._v(" Chapter 7. Map-Reduce")]),e._v(" "),o("p",[e._v("The rise of aggregate-oriented databases is in large part due to the growth of clusters. Running on a\ncluster means you have to make your tradeoffs in data storage differently than when running on a\nsingle machine. Clusters don’t just change the rules for data storage—they also change the rules for\ncomputation. If you store lots of data on a cluster, processing that data efficiently means you have to\nthink differently about how you organize your processing.")]),e._v(" "),o("p",[e._v("With a centralized database, there are generally two ways you can run the processing logic against\nit: either on the database server itself or on a client machine. Running it on a client machine gives you more flexibility in choosing a programming environment, which usually makes for programs that are\neasier to create or extend. This comes at the cost of having to shlep lots of data from the database\nserver. If you need to hit a lot of data, then it makes sense to do the processing on the server, paying\nthe price in programming convenience and increasing the load on the database server.")]),e._v(" "),o("p",[e._v("When you have a cluster, there is good news immediately—you have lots of machines to spread the\ncomputation over. However, you also still need to try to reduce the amount of data that needs to be\ntransferred across the network by doing as much processing as you can on the same node as the data it\nneeds.")]),e._v(" "),o("p",[e._v("The map-reduce pattern (a form of "),o("em",[e._v("Scatter-Gather")]),e._v(" [Hohpe and Woolf]) is a way to organize\nprocessing in such a way as to take advantage of multiple machines on a cluster while keeping as\nmuch processing and the data it needs together on the same machine. It first gained prominence with\nGoogle’s MapReduce framework [Dean and Ghemawat]. A widely used open-source implementation\nis part of the Hadoop project, although several databases include their own implementations. As with\nmost patterns, there are differences in detail between these implementations, so we’ll concentrate on\nthe general concept. The name “map-reduce” reveals its inspiration from the map and reduce\noperations on collections in functional programming languages.")]),e._v(" "),o("h2",{attrs:{id:"_7-1-basic-map-reduce"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#_7-1-basic-map-reduce"}},[e._v("#")]),e._v(" 7.1. Basic Map-Reduce")]),e._v(" "),o("p",[e._v("To explain the basic idea, we’ll start from an example we’ve already flogged to death—that of\ncustomers and orders. Let’s assume we have chosen orders as our aggregate, with each order having\nline items. Each line item has a product ID, quantity, and the price charged. This aggregate makes a\nlot of sense as usually people want to see the whole order in one access. We have lots of orders, so\nwe’ve sharded the dataset over many machines.")]),e._v(" "),o("p",[e._v("However, sales analysis people want to see a product and its total revenue for the last seven days.\nThis report doesn’t fit the aggregate structure that we have—which is the downside of using\naggregates. In order to get the product revenue report, you’ll have to visit every machine in the cluster and examine many records on each machine.")]),e._v(" "),o("p",[e._v("This is exactly the kind of situation that calls for map-reduce. The first stage in a map-reduce job is\nthe map. A map is a function whose input is a single aggregate and whose output is a bunch of key-\nvalue pairs. In this case, the input would be an order. The output would be key-value pairs\ncorresponding to the line items. Each one would have the product ID as the key and an embedded map\nwith the quantity and price as the values (see Figure 7.1).")]),e._v(" "),o("p",[o("img",{attrs:{src:a(652),alt:"img"}})]),e._v(" "),o("p",[o("strong",[e._v("Figure 7.1. A map function reads records from the database and emits key-value pairs.")])]),e._v(" "),o("p",[e._v("Each application of the map function is independent of all the others. This allows them to be safely\nparallelizable, so that a map-reduce framework can create efficient map tasks on each node and freely\nallocate each order to a map task. This yields a great deal of parallelism and locality of data access.\nFor this example, we are just selecting a value out of the record, but there’s no reason why we can’t\ncarry out some arbitrarily complex function as part of the map—providing it only depends on one\naggregate’s worth of data.")]),e._v(" "),o("p",[e._v("A map operation only operates on a single record; the reduce function takes multiple map outputs\nwith the same key and combines their values. So, a map function might yield 1000 line items from\norders for “Database Refactoring”; the reduce function would reduce down to one, with the totals for\nthe quantity and revenue. While the map function is limited to working only on data from a single\naggregate, the reduce function can use all values emitted for a single key (see Figure 7.2).")]),e._v(" "),o("p",[o("img",{attrs:{src:a(653),alt:"img"}})]),e._v(" "),o("p",[o("strong",[e._v("Figure 7.2. A reduce function takes several key-value pairs with the same key and aggregates them into one.")])]),e._v(" "),o("p",[e._v("The map-reduce framework arranges for map tasks to be run on the correct nodes to process all the\ndocuments and for data to be moved to the reduce function. To make it easier to write the reduce\nfunction, the framework collects all the values for a single pair and calls the reduce function once with the key and the collection of all the values for that key. So to run a map-reduce job, you just need to write these two functions.")]),e._v(" "),o("h2",{attrs:{id:"_7-2-partitioning-and-combining"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#_7-2-partitioning-and-combining"}},[e._v("#")]),e._v(" 7.2. Partitioning and Combining")]),e._v(" "),o("p",[e._v("In the simplest form, we think of a map-reduce job as having a single reduce function. The outputs\nfrom all the map tasks running on the various nodes are concatenated together and sent into the reduce.\nWhile this will work, there are things we can do to increase the parallelism and to reduce the data\ntransfer (see Figure 7.3).")]),e._v(" "),o("p",[o("img",{attrs:{src:a(654),alt:"img"}})]),e._v(" "),o("p",[o("strong",[e._v("Figure 7.3. Partitioning allows reduce functions to run in parallel on different keys.")])]),e._v(" "),o("p",[e._v("The first thing we can do is increase parallelism by partitioning the output of the mappers. Each\nreduce function operates on the results of a single key. This is a limitation—it means you can’t do\nanything in the reduce that operates across keys—but it’s also a benefit in that it allows you to run\nmultiple reducers in parallel. To take advantage of this, the results of the mapper are divided up\nbased the key on each processing node. Typically, multiple keys are grouped together into partitions.\nThe framework then takes the data from all the nodes for one partition, combines it into a single group\nfor that partition, and sends it off to a reducer. Multiple reducers can then operate on the partitions in parallel, with the final results merged together. (This step is also called “shuffling,” and the partitions are sometimes referred to as “buckets” or “regions.”)")]),e._v(" "),o("p",[e._v("The next problem we can deal with is the amount of data being moved from node to node between\nthe map and reduce stages. Much of this data is repetitive, consisting of multiple key-value pairs for\nthe same key. A combiner function cuts this data down by combining all the data for the same key into a single value (see Figure 7.4). A combiner function is, in essence, a reducer function—indeed, in\nmany cases the same function can be used for combining as the final reduction. The reduce function\nneeds a special shape for this to work: Its output must match its input. We call such a function a\n"),o("strong",[e._v("combinable reducer")]),e._v(".")]),e._v(" "),o("p",[o("img",{attrs:{src:a(655),alt:"img"}})]),e._v(" "),o("p",[o("strong",[e._v("Figure 7.4. Combining reduces data before sending it across the network.")])]),e._v(" "),o("p",[e._v("Not all reduce functions are combinable. Consider a function that counts the number of unique\ncustomers for a particular product. The map function for such an operation would need to emit the\nproduct and the customer. The reducer can then combine them and count how many times each\ncustomer appears for a particular product, emitting the product and the count (see Figure 7.5). But this\nreducer’s output is different from its input, so it can’t be used as a combiner. You can still run a\ncombining function here: one that just eliminates duplicate product-customer pairs, but it will be\ndifferent from the final reducer.")]),e._v(" "),o("p",[o("img",{attrs:{src:a(656),alt:"img"}})]),e._v(" "),o("p",[o("strong",[e._v("Figure 7.5. This reduce function, which counts how many unique customers order a particular tea, is not combinable.")])]),e._v(" "),o("p",[e._v("When you have combining reducers, the map-reduce framework can safely run not only in parallel\n(to reduce different partitions), but also in series to reduce the same partition at different times and\nplaces. In addition to allowing combining to occur on a node before data transmission, you can also\nstart combining before mappers have finished. This provides a good bit of extra flexibility to the\nmap-reduce processing. Some map-reduce frameworks require all reducers to be combining\nreducers, which maximizes this flexibility. If you need to do a noncombining reducer with one of these frameworks, you’ll need to separate the processing into pipelined map-reduce steps.")]),e._v(" "),o("h2",{attrs:{id:"_7-3-composing-map-reduce-calculations"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#_7-3-composing-map-reduce-calculations"}},[e._v("#")]),e._v(" 7.3. Composing Map-Reduce Calculations")]),e._v(" "),o("p",[e._v("The map-reduce approach is a way of thinking about concurrent processing that trades off flexibility\nin how you structure your computation for a relatively straightforward model for parallelizing the\ncomputation over a cluster. Since it’s a tradeoff, there are constraints on what you can do in your\ncalculations. Within a map task, you can only operate on a single aggregate. Within a reduce task, you\ncan only operate on a single key. This means you have to think differently about structuring your\nprograms so they work well within these constraints.")]),e._v(" "),o("p",[e._v("One simple limitation is that you have to structure your calculations around operations that fit in\nwell with the notion of a reduce operation. A good example of this is calculating averages. Let’s\nconsider the kind of orders we’ve been looking at so far; suppose we want to know the average\nordered quantity of each product. An important property of averages is that they are not composable\n—that is, if I take two groups of orders, I can’t combine their averages alone. Instead, I need to take\ntotal amount and the count of orders from each group, combine those, and then calculate the average\nfrom the combined sum and count (see Figure 7.6).")]),e._v(" "),o("p",[o("img",{attrs:{src:a(657),alt:"img"}})]),e._v(" "),o("p",[o("strong",[e._v("Figure 7.6. When calculating averages, the sum and count can be combined in the reduce calculation, but the average must be calculated from the combined sum and count.")])]),e._v(" "),o("p",[e._v("This notion of looking for calculations that reduce neatly also affects how we do counts. To make a\ncount, the mapping function will emit count fields with a value of 1 , which can be summed to get a\ntotal count (see Figure 7.7).")]),e._v(" "),o("p",[o("img",{attrs:{src:a(658),alt:"img"}})]),e._v(" "),o("p",[o("strong",[e._v("Figure 7.7. When making a count, each map emits 1 , which can be summed to get a total.")])]),e._v(" "),o("h3",{attrs:{id:"_7-3-1-a-two-stage-map-reduce-example"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#_7-3-1-a-two-stage-map-reduce-example"}},[e._v("#")]),e._v(" "),o("strong",[e._v("7.3.1. A Two Stage Map-Reduce Example")])]),e._v(" "),o("p",[e._v("As map-reduce calculations get more complex, it’s useful to break them down into stages using a\npipes-and-filters approach, with the output of one stage serving as input to the next, rather like the\npipelines in UNIX.")]),e._v(" "),o("p",[e._v("Consider an example where we want to compare the sales of products for each month in 2011 to\nthe prior year. To do this, we’ll break the calculations down into two stages. The first stage will\nproduce records showing the aggregate figures for a single product in a single month of the year. The\nsecond stage then uses these as inputs and produces the result for a single product by comparing one\nmonth’s results with the same month in the prior year (see Figure 7.8).")]),e._v(" "),o("p",[o("img",{attrs:{src:a(659),alt:"img"}})]),e._v(" "),o("p",[o("strong",[e._v("Figure 7.8. A calculation broken down into two map-reduce steps, which will be expanded in the next three figures")])]),e._v(" "),o("p",[e._v("A first stage (Figure 7.9) would read the original order records and output a series of key-value\npairs for the sales of each product per month.")]),e._v(" "),o("p",[o("img",{attrs:{src:a(660),alt:"img"}})]),e._v(" "),o("p",[o("strong",[e._v("Figure 7.9. Creating records for monthly sales of a product")])]),e._v(" "),o("p",[e._v("This stage is similar to the map-reduce examples we’ve seen so far. The only new feature is using\na composite key so that we can reduce records based on the values of multiple fields.")]),e._v(" "),o("p",[e._v("The second-stage mappers (Figure 7.10) process this output depending on the year. A 2011 record\npopulates the current year quantity while a 2010 record populates a prior year quantity. Records for\nearlier years (such as 2009) don’t result in any mapping output being emitted.")]),e._v(" "),o("p",[o("img",{attrs:{src:a(661),alt:"img"}})]),e._v(" "),o("p",[o("strong",[e._v("Figure 7.10. The second stage mapper creates base records for year-on-year comparisons.")])]),e._v(" "),o("p",[e._v("The reduce in this case (Figure 7.11) is a merge of records, where combining the values by\nsumming allows two different year outputs to be reduced to a single value (with a calculation based\non the reduced values thrown in for good measure).")]),e._v(" "),o("p",[o("img",{attrs:{src:a(662),alt:"img"}})]),e._v(" "),o("p",[o("strong",[e._v("Figure 7.11. The reduction step is a merge of incomplete records.")])]),e._v(" "),o("p",[e._v("Decomposing this report into multiple map-reduce steps makes it easier to write. Like many\ntransformation examples, once you’ve found a transformation framework that makes it easy to\ncompose steps, it’s usually easier to compose many small steps together than try to cram heaps of\nlogic into a single step.")]),e._v(" "),o("p",[e._v("Another advantage is that the intermediate output may be useful for different outputs too, so you can\nget some reuse. This reuse is important as it saves time both in programming and in execution. The\nintermediate records can be saved in the data store, forming a materialized view (“Materialized\nViews,” p. 30 ). Early stages of map-reduce operations are particularly valuable to save since they\noften represent the heaviest amount of data access, so building them once as a basis for many\ndownstream uses saves a lot of work. As with any reuse activity, however, it’s important to build\nthem out of experience with real queries, as speculative reuse rarely fulfills its promise. So it’s\nimportant to look at the forms of various queries as they are built and factor out the common parts of\nthe calculations into materialized views.")]),e._v(" "),o("p",[e._v("Map-reduce is a pattern that can be implemented in any programming language. However, the\nconstraints of the style make it a good fit for languages specifically designed for map-reduce\ncomputations. "),o("a",{attrs:{href:"https://pig.apache.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Apache Pig"),o("OutboundLink")],1),e._v(", an offshoot of the "),o("a",{attrs:{href:"https://hadoop.apache.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Hadoop"),o("OutboundLink")],1),e._v(" project, is a language specifically built to make it easy to write map-reduce programs. It certainly makes it much easier to work with Hadoop than the underlying Java libraries. In a similar vein, if you want to specify map-reduce programs using an SQL-like syntax, there is hive [Hive], another Hadoop offshoot.")]),e._v(" "),o("p",[e._v("The map-reduce pattern is important to know about even outside of the context of NoSQL\ndatabases. Google’s original map-reduce system operated on files stored on a distributed file system\n—an approach that’s used by the open-source Hadoop project. While it takes some thought to get used\nto the constraints of structuring computations in map-reduce steps, the result is a calculation that is\ninherently well-suited to running on a cluster. When dealing with high volumes of data, you need to\ntake a cluster-oriented approach. Aggregate-oriented databases fit well with this style of calculation.\nWe think that in the next few years many more organizations will be processing the volumes of data\nthat demand a cluster-oriented solution—and the map-reduce pattern will see more and more use.")]),e._v(" "),o("h3",{attrs:{id:"_7-3-2-incremental-map-reduce"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#_7-3-2-incremental-map-reduce"}},[e._v("#")]),e._v(" "),o("strong",[e._v("7.3.2. Incremental Map-Reduce")])]),e._v(" "),o("p",[e._v("The examples we’ve discussed so far are complete map-reduce computations, where we start with\nraw inputs and create a final output. Many map-reduce computations take a while to perform, even\nwith clustered hardware, and new data keeps coming in which means we need to rerun the\ncomputation to keep the output up to date. Starting from scratch each time can take too long, so often\nit’s useful to structure a map-reduce computation to allow incremental updates, so that only the\nminimum computation needs to be done.")]),e._v(" "),o("p",[e._v("The map stages of a map-reduce are easy to handle incrementally—only if the input data changes\ndoes the mapper need to be rerun. Since maps are isolated from each other, incremental updates are\nstraightforward.")]),e._v(" "),o("p",[e._v("The more complex case is the reduce step, since it pulls together the outputs from many maps and\nany change in the map outputs could trigger a new reduction. This recomputation can be lessened\ndepending on how parallel the reduce step is. If we are partitioning the data for reduction, then any\npartition that’s unchanged does not need to be re-reduced. Similarly, if there’s a combiner step, it\ndoesn’t need to be rerun if its source data hasn’t changed.")]),e._v(" "),o("p",[e._v("If our reducer is combinable, there’s some more opportunities for computation avoidance. If the\nchanges are additive—that is, if we are only adding new records but are not changing or deleting any\nold records—then we can just run the reduce with the existing result and the new additions. If there\nare destructive changes, that is updates and deletes, then we can avoid some recomputation by\nbreaking up the reduce operation into steps and only recalculating those steps whose inputs have\nchanged—essentially, using a "),o("em",[e._v("Dependency Network")]),e._v(" [Fowler DSL] to organize the computation.")]),e._v(" "),o("p",[e._v("The map-reduce framework controls much of this, so you have to understand how a specific\nframework supports incremental operation.")]),e._v(" "),o("h2",{attrs:{id:"_7-4-further-reading"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#_7-4-further-reading"}},[e._v("#")]),e._v(" 7.4. Further Reading")]),e._v(" "),o("p",[e._v("If you’re going to use map-reduce calculations, your first port of call will be the documentation for\nthe particular database you are using. Each database has its own approach, vocabulary, and quirks,\nand that’s what you’ll need to be familiar with. Beyond that, there is a need to capture more general\ninformation on how to structure map-reduce jobs to maximize maintainability and performance. We\ndon’t have any specific books to point to yet, but we suspect that a good though easily overlooked\nsource are books on Hadoop. Although Hadoop is not a database, it’s a tool that uses map-reduce\nheavily, so writing an effective map-reduce task with Hadoop is likely to be useful in other contexts\n(subject to the changes in detail between Hadoop and whatever systems you’re using).")]),e._v(" "),o("h2",{attrs:{id:"_7-5-key-points"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#_7-5-key-points"}},[e._v("#")]),e._v(" 7.5. Key Points")]),e._v(" "),o("ul",[o("li",[e._v("Map-reduce is a pattern to allow computations to be parallelized over a cluster.")]),e._v(" "),o("li",[e._v("The map task reads data from an aggregate and boils it down to relevant key-value pairs. Maps only read a single record at a time and can thus be parallelized and run on the node that stores the record.")]),e._v(" "),o("li",[e._v("Reduce tasks take many values for a single key output from map tasks and summarize them into a single output. Each reducer operates on the result of a single key, so it can be parallelized by key.")]),e._v(" "),o("li",[e._v("Reducers that have the same form for input and output can be combined into pipelines. This improves parallelism and reduces the amount of data to be transferred.")]),e._v(" "),o("li",[e._v("Map-reduce operations can be composed into pipelines where the output of one reduce is the input to another operation’s map.")]),e._v(" "),o("li",[e._v("If the result of a map-reduce computation is widely used, it can be stored as a materialized view.")]),e._v(" "),o("li",[e._v("Materialized views can be updated through incremental map-reduce operations that only compute changes to the view instead of recomputing everything from scratch.")])])])}),[],!1,null,null,null);t.default=n.exports},652:function(e,t,a){e.exports=a.p+"assets/img/image--022.046763f1.jpg"},653:function(e,t,a){e.exports=a.p+"assets/img/image--023.18f371ec.jpg"},654:function(e,t,a){e.exports=a.p+"assets/img/image--024.c878a00e.jpg"},655:function(e,t,a){e.exports=a.p+"assets/img/image--025.46d7abe8.jpg"},656:function(e,t,a){e.exports=a.p+"assets/img/image--026.237c40e7.jpg"},657:function(e,t,a){e.exports=a.p+"assets/img/image--027.270b316f.jpg"},658:function(e,t,a){e.exports=a.p+"assets/img/image--028.823c6807.jpg"},659:function(e,t,a){e.exports=a.p+"assets/img/image--029.42f2f2ef.jpg"},660:function(e,t,a){e.exports=a.p+"assets/img/image--030.7600d898.jpg"},661:function(e,t,a){e.exports=a.p+"assets/img/image--031.1597fbad.jpg"},662:function(e,t,a){e.exports=a.p+"assets/img/image--032.b47ef83a.jpg"}}]);