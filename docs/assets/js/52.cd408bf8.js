(window.webpackJsonp=window.webpackJsonp||[]).push([[52],{1096:function(t,s,a){"use strict";a.r(s);var n=a(7),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h1",{attrs:{id:"ai-notes"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#ai-notes"}},[t._v("#")]),t._v(" AI Notes")]),t._v(" "),n("p",[n("a",{attrs:{href:"https://phamdinhkhanh.github.io/content",target:"_blank",rel:"noopener noreferrer"}},[t._v("SÃ¡ch tiáº¿ng viá»‡t"),n("OutboundLink")],1)]),t._v(" "),n("h2",{attrs:{id:"vector"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#vector"}},[t._v("#")]),t._v(" Vector")]),t._v(" "),n("p",[t._v("https://www.mathsisfun.com/algebra/vectors.html")]),t._v(" "),n("p",[t._v("How many features of object (student, vehicle, ...)")]),t._v(" "),n("ul",[n("li",[t._v("E.g: Grade of math & literature of students => vector 2D")]),t._v(" "),n("li",[t._v("Vector is display data")])]),t._v(" "),n("p",[n("strong",[t._v("Image")]),t._v("\nblack & white image => each px has value 0 - 255\ncolorful image => RGB - each px is vector 3D")]),t._v(" "),n("p",[n("strong",[t._v("Face recognition")])]),t._v(" "),n("ul",[n("li",[t._v("E.g Image 10px x 10px => vector 100 Dimensions")]),t._v(" "),n("li",[t._v("From multiple images => bring all to vectors with same dimensions")]),t._v(" "),n("li",[t._v("AI => find the correlation of vectors return ("),n("code",[t._v("f(x)")]),t._v(" => "),n("code",[t._v("probability")]),t._v(" ) => recognition")])]),t._v(" "),n("p",[n("strong",[t._v("Voice / Languague recognition")]),t._v("\nencoding => from voice to vector. Fb or GG will do it for us ðŸ˜—\nfew famous encoding")]),t._v(" "),n("ul",[n("li",[t._v("TFIDF")]),t._v(" "),n("li",[t._v("word2vec")]),t._v(" "),n("li",[t._v("BERT")]),t._v(" "),n("li",[t._v("fasttext\nSentences has same meaning, vectors should be near.")])]),t._v(" "),n("p",[n("strong",[t._v("Distance of 2 vectors")]),t._v(" "),n("img",{attrs:{src:a(463),alt:"Img"}})]),t._v(" "),n("div",{staticClass:"language-py extra-class"},[n("pre",{pre:!0,attrs:{class:"language-py"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("distance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("p2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\t"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" math"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sqrt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("p2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("p2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" p2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" p2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[n("strong",[t._v("Matrix")]),t._v(" was made by vectors")]),t._v(" "),n("h2",{attrs:{id:"k-means"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#k-means"}},[t._v("#")]),t._v(" K-means")]),t._v(" "),n("p",[t._v("https://phamdinhkhanh.github.io/deepai-book/ch_ml/KMeans.html")]),t._v(" "),n("p",[t._v("k-means clustering is a method of vector quantization, originally from signal processing, that aims to partition "),n("code",[t._v("n")]),t._v(" observations into "),n("code",[t._v("k")]),t._v(" clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster.")]),t._v(" "),n("p",[n("img",{attrs:{src:a(464),alt:"k-mean"}})]),t._v(" "),n("ul",[n("li",[t._v("cluster-ceatroid")]),t._v(" "),n("li",[t._v("label")])]),t._v(" "),n("p",[n("a",{attrs:{href:"https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans",target:"_blank",rel:"noopener noreferrer"}},[t._v("sklearn.cluster.KMeans"),n("OutboundLink")],1)]),t._v(" "),n("div",{staticClass:"language-py extra-class"},[n("pre",{pre:!0,attrs:{class:"language-py"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cluster "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" KMeans\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# init ")]),t._v("\npoints "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nK "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# run")]),t._v("\nkmeans "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" KMeans"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("n_clusters"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("K"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("points"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \nlabels "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" kmeans"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("points"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nclusters "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" kmeans"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cluster_centers_\n")])])]),n("p",[n("strong",[t._v("Choose K - elbow method")]),t._v(" "),n("img",{attrs:{src:a(465),alt:"elbow"}})]),t._v(" "),n("p",[n("strong",[t._v("Image compression")])]),t._v(" "),n("h2",{attrs:{id:"linear-regression"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#linear-regression"}},[t._v("#")]),t._v(" Linear Regression")]),t._v(" "),n("p",[t._v("https://phamdinhkhanh.github.io/deepai-book/ch_ml/prediction.html")]),t._v(" "),n("p",[t._v("https://www.youtube.com/watch?v=nk2CQITm_eo&ab_channel=StatQuestwithJoshStarmer")]),t._v(" "),n("div",{staticClass:"language-py extra-class"},[n("pre",{pre:!0,attrs:{class:"language-py"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pyplot "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" linear_model\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Random data")]),t._v("\nA "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("19")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("23")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("22")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("29")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("29")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("35")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("37")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("40")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("46")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("T\nb "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("13")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("T\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Create model")]),t._v("\nlr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" linear_model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("LinearRegression"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Fit (train the model)")]),t._v("\nlr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("A"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# y = ax+b, a: coefficient, b: intercept")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("lr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("intercept_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("lr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("coef_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Draw random data")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("A"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'ro'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Draw line")]),t._v("\nx0 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("46")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("T\ny0 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" x0 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" lr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("coef_ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" lr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("intercept_\n\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x0"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y0"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h2",{attrs:{id:"gradient-descent"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#gradient-descent"}},[t._v("#")]),t._v(" Gradient Descent")]),t._v(" "),n("ul",[n("li",[t._v("Line")]),t._v(" "),n("li",[t._v("Parabole")])]),t._v(" "),n("h2",{attrs:{id:"knn"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#knn"}},[t._v("#")]),t._v(" KNN")]),t._v(" "),n("p",[t._v("supervised learning - data has labels\nnot use much in practice, because prediction process very slow")]),t._v(" "),n("h2",{attrs:{id:"vokas"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#vokas"}},[t._v("#")]),t._v(" Vokas")]),t._v(" "),n("ul",[n("li",[t._v("feature")]),t._v(" "),n("li",[t._v("fit <--\x3e train model")]),t._v(" "),n("li",[t._v("single prediction / batch prediction")]),t._v(" "),n("li",[t._v("supervised learning - data has labels")]),t._v(" "),n("li",[t._v("unsupervised learning - data has no label")]),t._v(" "),n("li",[t._v("row space => column space")])])])}),[],!1,null,null,null);s.default=e.exports},463:function(t,s,a){t.exports=a.p+"assets/img/vector-distance-formula.97ff407f.png"},464:function(t,s,a){t.exports=a.p+"assets/img/kmean.9065804d.png"},465:function(t,s,a){t.exports=a.p+"assets/img/elbow.854914f2.png"}}]);