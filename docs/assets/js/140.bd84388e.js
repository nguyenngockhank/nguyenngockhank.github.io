(window.webpackJsonp=window.webpackJsonp||[]).push([[140],{1655:function(e,t,a){"use strict";a.r(t);var i=a(7),o=Object(i.a)({},(function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[i("h1",{attrs:{id:"designing-youtube-or-netflix"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#designing-youtube-or-netflix"}},[e._v("#")]),e._v(" Designing Youtube or Netflix")]),e._v(" "),i("p",[e._v("Let's design a video sharing service like Youtube, where users will be able to upload/view/search\nvideos. Similar Services: netflix.com, vimeo.com, dailymotion.com, veoh.com")]),e._v(" "),i("p",[e._v("Difficulty Level: Medium")]),e._v(" "),i("h2",{attrs:{id:"_1-why-youtube"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_1-why-youtube"}},[e._v("#")]),e._v(" 1. Why Youtube?")]),e._v(" "),i("p",[e._v("Youtube is one of the most popular video sharing websites in the world. Users of the service can\nupload, view, share, rate, and report videos as well as add comments on videos.")]),e._v(" "),i("h2",{attrs:{id:"_2-requirements-and-goals-of-the-system"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-requirements-and-goals-of-the-system"}},[e._v("#")]),e._v(" 2. Requirements and Goals of the System")]),e._v(" "),i("p",[e._v("For the sake of this exercise, we plan to design a simpler version of Youtube with following\nrequirements:")]),e._v(" "),i("h3",{attrs:{id:"functional-requirements"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#functional-requirements"}},[e._v("#")]),e._v(" Functional Requirements:")]),e._v(" "),i("ol",[i("li",[e._v("Users should be able to upload videos.")]),e._v(" "),i("li",[e._v("Users should be able to share and view videos.")]),e._v(" "),i("li",[e._v("Users should be able to perform searches based on video titles.")]),e._v(" "),i("li",[e._v("Our services should be able to record stats of videos, e.g., likes/dislikes, total number of views,\netc.")]),e._v(" "),i("li",[e._v("Users should be able to add and view comments on videos.")])]),e._v(" "),i("h3",{attrs:{id:"non-functional-requirements"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#non-functional-requirements"}},[e._v("#")]),e._v(" Non-Functional Requirements:")]),e._v(" "),i("ol",[i("li",[e._v("The system should be highly reliable, any video uploaded should not be lost.")]),e._v(" "),i("li",[e._v("The system should be highly available. Consistency can take a hit (in the interest of\navailability); if a user doesn’t see a video for a while, it should be fine.")]),e._v(" "),i("li",[e._v("Users should have a real time experience while watching videos and should not feel any lag.")])]),e._v(" "),i("p",[i("strong",[e._v("Not in scope:")]),e._v(" Video recommendations, most popular videos, channels, subscriptions, watch later,\nfavorites, etc.")]),e._v(" "),i("h2",{attrs:{id:"_3-capacity-estimation-and-constraints"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_3-capacity-estimation-and-constraints"}},[e._v("#")]),e._v(" 3. Capacity Estimation and Constraints")]),e._v(" "),i("p",[e._v("Let’s assume we have 1.5 billion total users, 800 million of whom are daily active users. If, on average,\na user views five videos per day then the total video-views per second would be:")]),e._v(" "),i("div",{staticClass:"language- extra-class"},[i("pre",{pre:!0,attrs:{class:"language-text"}},[i("code",[e._v("800M * 5 / 86400 sec => 46K videos/sec\n")])])]),i("p",[e._v("Let’s assume our upload: view ratio is 1:200, i.e., for every video upload we have 200 videos viewed,\ngiving us 230 videos uploaded per second.")]),e._v(" "),i("div",{staticClass:"language- extra-class"},[i("pre",{pre:!0,attrs:{class:"language-text"}},[i("code",[e._v("46K / 200 => 230 videos/sec \n")])])]),i("p",[i("strong",[e._v("Storage Estimates")]),e._v(": Let’s assume that every minute 500 hours worth of videos are uploaded to\nYoutube. If on average, one minute of video needs 50MB of storage (videos need to be stored in\nmultiple formats), the total storage needed for videos uploaded in a minute would be:")]),e._v(" "),i("div",{staticClass:"language- extra-class"},[i("pre",{pre:!0,attrs:{class:"language-text"}},[i("code",[e._v("500 hours * 60 min * 50MB => 1500 GB/min (25 GB/sec)\n")])])]),i("p",[e._v("These numbers are estimated with ignoring video compression and replication, which would change\nour estimates.")]),e._v(" "),i("p",[i("strong",[e._v("Bandwidth estimates")]),e._v(": With 500 hours of video uploads per minute and assuming each video upload\ntakes a bandwidth of 10MB/min, we would be getting 300GB of uploads every minute.")]),e._v(" "),i("div",{staticClass:"language- extra-class"},[i("pre",{pre:!0,attrs:{class:"language-text"}},[i("code",[e._v("500 hours * 60 mins * 10MB => 300GB/min (5GB/sec)\n")])])]),i("p",[e._v("Assuming an upload:view ratio of 1:200, we would need 1TB/s outgoing bandwidth.")]),e._v(" "),i("h2",{attrs:{id:"_4-system-apis"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_4-system-apis"}},[e._v("#")]),e._v(" 4. System APIs")]),e._v(" "),i("p",[e._v("We can have SOAP or REST APIs to expose the functionality of our service. The following could be\nthe definitions of the APIs for uploading and searching videos:")]),e._v(" "),i("h3",{attrs:{id:"upload-api"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#upload-api"}},[e._v("#")]),e._v(" Upload API")]),e._v(" "),i("p",[i("code",[e._v("uploadVideo(api_dev_key, video_title, vide_description, tags[], category_id, default_language, recording_details, video_contents)")])]),e._v(" "),i("p",[i("strong",[e._v("Parameters:")])]),e._v(" "),i("ul",[i("li",[e._v("api_dev_key (string): The API developer key of a registered account. This will be used to, among other things, throttle users based on their allocated quota.")]),e._v(" "),i("li",[e._v("video_title (string): Title of the video.")]),e._v(" "),i("li",[e._v("vide_description (string): Optional description of the video.")]),e._v(" "),i("li",[e._v("tags (string[]): Optional tags for the video.")]),e._v(" "),i("li",[e._v("category_id (string): Category of the video, e.g., Film, Song, People, etc.")]),e._v(" "),i("li",[e._v("default_language (string): For example English, Mandarin, Hindi, etc.")]),e._v(" "),i("li",[e._v("recording_details (string): Location where the video was recorded.")]),e._v(" "),i("li",[e._v("video_contents (stream): Video to be uploaded.")])]),e._v(" "),i("p",[i("strong",[e._v("Returns")]),e._v(": (string)\nA successful upload will return HTTP 202 (request accepted) and once the video encoding is completed\nthe user is notified through email with a link to access the video. We can also expose a queryable API\nto let users know the current status of their uploaded video.")]),e._v(" "),i("h3",{attrs:{id:"search-api"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#search-api"}},[e._v("#")]),e._v(" Search API")]),e._v(" "),i("p",[i("code",[e._v("searchVideo(api_dev_key, search_query, user_location, maximum_videos_to_return, page_token)")])]),e._v(" "),i("p",[i("strong",[e._v("Parameters")]),e._v(":")]),e._v(" "),i("ul",[i("li",[e._v("api_dev_key (string): The API developer key of a registered account of our service.")]),e._v(" "),i("li",[e._v("search_query (string): A string containing the search terms.")]),e._v(" "),i("li",[e._v("user_location (string): Optional location of the user performing the search.")]),e._v(" "),i("li",[e._v("maximum_videos_to_return (number): Maximum number of results returned in one request.")]),e._v(" "),i("li",[e._v("page_token (string): This token will specify a page in the result set that should be returned.")])]),e._v(" "),i("p",[i("strong",[e._v("Returns")]),e._v(": (JSON)")]),e._v(" "),i("p",[e._v("A JSON containing information about the list of video resources matching the search query. Each video\nresource will have a video title, a thumbnail, a video creation date, and a view count.")]),e._v(" "),i("h3",{attrs:{id:"stream-api"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#stream-api"}},[e._v("#")]),e._v(" Stream API")]),e._v(" "),i("p",[i("code",[e._v("streamVideo(api_dev_key, video_id, offset, codec, resolution)")])]),e._v(" "),i("p",[i("strong",[e._v("Parameters")]),e._v(":")]),e._v(" "),i("ul",[i("li",[e._v("api_dev_key (string): The API developer key of a registered account of our service.")]),e._v(" "),i("li",[e._v("video_id (string): A string to identify the video.")]),e._v(" "),i("li",[e._v("offset (number): We should be able to stream video from any offset; this offset would be a time in seconds from the beginning of the video. If we support playing/pausing a video from multiple devices, we will need to store the offset on the server. This will enable the users to start watching a video on any device from the same point where they left off.")]),e._v(" "),i("li",[e._v("codec (string) & resolution(string): We should send the codec and resolution info in the API from the\nclient to support play/pause from multiple devices. Imagine you are watching a video on your TV’s\nNetflix app, paused it, and started watching it on your phone’s Netflix app. In this case, you would need\ncodec and resolution, as both these devices have a different resolution and use a different codec.")])]),e._v(" "),i("p",[i("strong",[e._v("Returns")]),e._v(": (STREAM)\nA media stream (a video chunk) from the given offset.")]),e._v(" "),i("h2",{attrs:{id:"_5-high-level-design"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_5-high-level-design"}},[e._v("#")]),e._v(" 5. High Level Design")]),e._v(" "),i("p",[e._v("At a high-level we would need the following components:")]),e._v(" "),i("ol",[i("li",[i("strong",[e._v("Processing Queue")]),e._v(": Each uploaded video will be pushed to a processing queue to be de-queued\nlater for encoding, thumbnail generation, and storage.")]),e._v(" "),i("li",[i("strong",[e._v("Encoder")]),e._v(": To encode each uploaded video into multiple formats.")]),e._v(" "),i("li",[i("strong",[e._v("Thumbnails generator")]),e._v(": To generate a few thumbnails for each video.")]),e._v(" "),i("li",[i("strong",[e._v("Video and Thumbnail storage")]),e._v(": To store video and thumbnail files in some distributed file storage.")]),e._v(" "),i("li",[i("strong",[e._v("User Database")]),e._v(": To store user’s information, e.g., name, email, address, etc.")]),e._v(" "),i("li",[i("strong",[e._v("Video metadata storage")]),e._v(": A metadata database to store all the information about videos like\ntitle, file path in the system, uploading user, total views, likes, dislikes, etc. It will also be used\nto store all the video comments.")])]),e._v(" "),i("p",[i("img",{attrs:{src:a(428),alt:"img"}}),i("br"),e._v(" "),i("em",[e._v("High level design of Youtube")])]),e._v(" "),i("h2",{attrs:{id:"_6-database-schema"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_6-database-schema"}},[e._v("#")]),e._v(" 6. Database Schema")]),e._v(" "),i("p",[i("strong",[e._v("Video metadata storage - MySql")]),e._v("\nVideos metadata can be stored in a SQL database. The following information should be stored with each video:")]),e._v(" "),i("ul",[i("li",[e._v("VideoID")]),e._v(" "),i("li",[e._v("Title")]),e._v(" "),i("li",[e._v("Description")]),e._v(" "),i("li",[e._v("Size")]),e._v(" "),i("li",[e._v("Thumbnail")]),e._v(" "),i("li",[e._v("Uploader/User")]),e._v(" "),i("li",[e._v("Total number of likes")]),e._v(" "),i("li",[e._v("Total number of dislikes")]),e._v(" "),i("li",[e._v("Total number of views")])]),e._v(" "),i("p",[e._v("For each video comment, we need to store following information:")]),e._v(" "),i("ul",[i("li",[e._v("CommentID")]),e._v(" "),i("li",[e._v("VideoID")]),e._v(" "),i("li",[e._v("UserID")]),e._v(" "),i("li",[e._v("Comment")]),e._v(" "),i("li",[e._v("TimeOfCreation")])]),e._v(" "),i("p",[i("strong",[e._v("User data storage - MySql")])]),e._v(" "),i("ul",[i("li",[e._v("UserID, Name, email, address, age, registration details etc.")])]),e._v(" "),i("h2",{attrs:{id:"_7-detailed-component-design"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_7-detailed-component-design"}},[e._v("#")]),e._v(" 7. Detailed Component Design")]),e._v(" "),i("p",[e._v("The service would be read-heavy, so we will focus on building a system that can retrieve videos\nquickly. We can expect our read:write ratio to be 200:1, which means for every video upload there are\n200 video views.")]),e._v(" "),i("p",[i("strong",[e._v("Where would videos be stored")]),e._v("? Videos can be stored in a distributed file storage system like "),i("a",{attrs:{href:"https://en.wikipedia.org/wiki/Apache_Hadoop#HDFS",target:"_blank",rel:"noopener noreferrer"}},[e._v("HDFS"),i("OutboundLink")],1),e._v(" or\n"),i("a",{attrs:{href:"https://en.wikipedia.org/wiki/Gluster#GlusterFS",target:"_blank",rel:"noopener noreferrer"}},[e._v("GlusterFS"),i("OutboundLink")],1),e._v(".")]),e._v(" "),i("p",[i("strong",[e._v("How should we efficiently manage read traffic")]),e._v("? We should segregate our read traffic from write\ntraffic. Since we will have multiple copies of each video, we can distribute our read traffic on different\nservers. For metadata, we can have master-slave configurations where writes will go to master first and\nthen gets applied at all the slaves. Such configurations can cause some staleness in data, e.g., when a\nnew video is added, its metadata would be inserted in the master first and before it gets applied at the\nslave our slaves would not be able to see it; and therefore it will be returning stale results to the user.\nThis staleness might be acceptable in our system as it would be very short-lived and the user would be\nable to see the new videos after a few milliseconds.")]),e._v(" "),i("p",[i("strong",[e._v("Where would thumbnails be stored?")]),e._v(" There will be a lot more thumbnails than videos. If we assume\nthat every video will have five thumbnails, we need to have a very efficient storage system that can\nserve a huge read traffic. There will be two consideration before deciding which storage system should\nbe used for thumbnails:")]),e._v(" "),i("ol",[i("li",[e._v("Thumbnails are small files with, say, a maximum 5KB each.")]),e._v(" "),i("li",[e._v("Read traffic for thumbnails will be huge compared to videos. Users will be watching one video\nat a time, but they might be looking at a page that has 20 thumbnails of other videos.")])]),e._v(" "),i("p",[e._v("Let’s evaluate storing all the thumbnails on a disk. Given that we have a huge number of files, we have\nto perform a lot of seeks to different locations on the disk to read these files. This is quite inefficient\nand will result in higher latencies.")]),e._v(" "),i("p",[i("a",{attrs:{href:"https://en.wikipedia.org/wiki/Bigtable",target:"_blank",rel:"noopener noreferrer"}},[e._v("Bigtable"),i("OutboundLink")],1),e._v(" can be a reasonable choice here as it combines multiple files into one block to store on the\ndisk and is very efficient in reading a small amount of data. Both of these are the two most significant\nrequirements of our service. Keeping hot thumbnails in the cache will also help in improving the\nlatencies and, given that thumbnails files are small in size, we can easily cache a large number of such\nfiles in memory.")]),e._v(" "),i("p",[i("strong",[e._v("Video Uploads")]),e._v(": Since videos could be huge, if while uploading the connection drops we should\nsupport resuming from the same point.")]),e._v(" "),i("p",[i("strong",[e._v("Video Encoding")]),e._v(": Newly uploaded videos are stored on the server and a new task is added to the\nprocessing queue to encode the video into multiple formats. Once all the encoding will be completed\nthe uploader will be notified and the video is made available for view/sharing.")]),e._v(" "),i("p",[i("img",{attrs:{src:a(428),alt:"img"}}),i("br"),e._v(" "),i("em",[e._v("Detailed component design of Youtube")])]),e._v(" "),i("h2",{attrs:{id:"_8-metadata-sharding"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_8-metadata-sharding"}},[e._v("#")]),e._v(" 8. Metadata Sharding")]),e._v(" "),i("p",[e._v("Since we have a huge number of new videos every day and our read load is extremely high, therefore,\nwe need to distribute our data onto multiple machines so that we can perform read/write operations\nefficiently. We have many options to shard our data. Let’s go through different strategies of sharding\nthis data one by one:")]),e._v(" "),i("p",[i("strong",[e._v("Sharding based on UserID:")]),e._v(" We can try storing all the data for a particular user on one server. While\nstoring, we can pass the UserID to our hash function which will map the user to a database server\nwhere we will store all the metadata for that user’s videos. While querying for videos of a user, we can\nask our hash function to find the server holding the user’s data and then read it from there. To search\nvideos by titles we will have to query all servers and each server will return a set of videos. A\ncentralized server will then aggregate and rank these results before returning them to the user.")]),e._v(" "),i("p",[e._v("This approach has a couple of issues:")]),e._v(" "),i("ol",[i("li",[e._v("What if a user becomes popular? There could be a lot of queries on the server holding that user;\nthis could create a performance bottleneck. This will also affect the overall performance of our\nservice.")]),e._v(" "),i("li",[e._v("Over time, some users can end up storing a lot of videos compared to others. Maintaining a\nuniform distribution of growing user data is quite tricky.")])]),e._v(" "),i("p",[e._v("To recover from these situations either we have to repartition/redistribute our data or used consistent\nhashing to balance the load between servers.")]),e._v(" "),i("p",[i("strong",[e._v("Sharding based on VideoID")]),e._v(": Our hash function will map each VideoID to a random server where we\nwill store that Video’s metadata. To find videos of a user we will query all servers and each server will\nreturn a set of videos. A centralized server will aggregate and rank these results before returning them\nto the user. This approach solves our problem of popular users but shifts it to popular videos.")]),e._v(" "),i("p",[e._v("We can further improve our performance by introducing a cache to store hot videos in front of the\ndatabase servers.")]),e._v(" "),i("h2",{attrs:{id:"_9-video-deduplication"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_9-video-deduplication"}},[e._v("#")]),e._v(" 9. Video Deduplication")]),e._v(" "),i("p",[e._v("With a huge number of users uploading a massive amount of video data our service will have to deal\nwith widespread video duplication. Duplicate videos often differ in aspect ratios or encodings, can\ncontain overlays or additional borders, or can be excerpts from a longer original video. The\nproliferation of duplicate videos can have an impact on many levels:")]),e._v(" "),i("ol",[i("li",[e._v("Data Storage: We could be wasting storage space by keeping multiple copies of the same video.")]),e._v(" "),i("li",[e._v("Caching: Duplicate videos would result in degraded cache efficiency by taking up space that\ncould be used for unique content.")]),e._v(" "),i("li",[e._v("Network usage: Duplicate videos will also increase the amount of data that must be sent over\nthe network to in-network caching systems.")]),e._v(" "),i("li",[e._v("Energy consumption: Higher storage, inefficient cache, and network usage could result in\nenergy wastage.")])]),e._v(" "),i("p",[e._v("For the end user, these inefficiencies will be realized in the form of duplicate search results, longer\nvideo startup times, and interrupted streaming.")]),e._v(" "),i("p",[e._v("For our service, deduplication makes most sense early; when a user is uploading a video as compared\nto post-processing it to find duplicate videos later. Inline deduplication will save us a lot of resources\nthat can be used to encode, transfer, and store the duplicate copy of the video. As soon as any user starts\nuploading a video, our service can run video matching algorithms (e.g., "),i("a",{attrs:{href:"https://en.wikipedia.org/wiki/Block-matching_algorithm",target:"_blank",rel:"noopener noreferrer"}},[e._v("Block Matching"),i("OutboundLink")],1),e._v(", "),i("a",{attrs:{href:"https://en.wikipedia.org/wiki/Phase_correlation",target:"_blank",rel:"noopener noreferrer"}},[e._v("Phase Correlation"),i("OutboundLink")],1),e._v(", etc.) to find duplications. If we already have a copy of the video being uploaded, we can\neither stop the upload and use the existing copy or continue the upload and use the newly uploaded\nvideo if it is of higher quality. If the newly uploaded video is a subpart of an existing video or, vice\nversa, we can intelligently divide the video into smaller chunks so that we only upload the parts that are\nmissing.")]),e._v(" "),i("h2",{attrs:{id:"_10-load-balancing"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_10-load-balancing"}},[e._v("#")]),e._v(" 10. Load Balancing")]),e._v(" "),i("p",[e._v("We should use Consistent Hashing among our cache servers, which will also help in balancing the load\nbetween cache servers. Since we will be using a static hash-based scheme to map videos to hostnames\nit can lead to an uneven load on the logical replicas due to the different popularity of each video. For\ninstance, if a video becomes popular, the logical replica corresponding to that video will experience\nmore traffic than other servers. These uneven loads for logical replicas can then translate into uneven\nload distribution on corresponding physical servers. To resolve this issue any busy server in one location can redirect a client to a less busy server in the same cache location. We can use dynamic\nHTTP redirections for this scenario.")]),e._v(" "),i("p",[e._v("However, the use of redirections also has its drawbacks. First, since our service tries to load balance\nlocally, it leads to multiple redirections if the host that receives the redirection can’t serve the video.\nAlso, each redirection requires a client to make an additional HTTP request; it also leads to higher\ndelays before the video starts playing back. Moreover, inter-tier (or cross data-center) redirections lead\na client to a distant cache location because the higher tier caches are only present at a small number of\nlocations.")]),e._v(" "),i("h2",{attrs:{id:"_11-cache"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_11-cache"}},[e._v("#")]),e._v(" 11. Cache")]),e._v(" "),i("p",[e._v("To serve globally distributed users, our service needs a massive-scale video delivery system. Our\nservice should push its content closer to the user using a large number of geographically distributed\nvideo cache servers. We need to have a strategy that will maximize user performance and also evenly\ndistributes the load on its cache servers.")]),e._v(" "),i("p",[e._v("We can introduce a cache for metadata servers to cache hot database rows. Using Memcache to cache\nthe data and Application servers before hitting database can quickly check if the cache has the desired\nrows. Least Recently Used (LRU) can be a reasonable cache eviction policy for our system. Under this\npolicy, we discard the least recently viewed row first.")]),e._v(" "),i("p",[i("strong",[e._v("How can we build more intelligent cache?")]),e._v(" If we go with 80-20 rule, i.e., 20% of daily read volume\nfor videos is generating 80% of traffic, meaning that certain videos are so popular that the majority of\npeople view them; it follows that we can try caching 20% of daily read volume of videos and metadata.")]),e._v(" "),i("h2",{attrs:{id:"_12-content-delivery-network-cdn"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_12-content-delivery-network-cdn"}},[e._v("#")]),e._v(" 12. Content Delivery Network (CDN)")]),e._v(" "),i("p",[e._v("A CDN is a system of distributed servers that deliver web content to a user based in the geographic\nlocations of the user, the origin of the web page and a content delivery server. Take a look at ‘CDN’\nsection in our Caching chapter.\nOur service can move popular videos to CDNs:")]),e._v(" "),i("ul",[i("li",[e._v("CDNs replicate content in multiple places. There’s a better chance of videos being closer to the\nuser and, with fewer hops, videos will stream from a friendlier network.")]),e._v(" "),i("li",[e._v("CDN machines make heavy use of caching and can mostly serve videos out of memory.")])]),e._v(" "),i("p",[e._v("Less popular videos (1-20 views per day) that are not cached by CDNs can be served by our servers in\nvarious data centers.")]),e._v(" "),i("h2",{attrs:{id:"_13-fault-tolerance"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_13-fault-tolerance"}},[e._v("#")]),e._v(" 13. Fault Tolerance")]),e._v(" "),i("p",[e._v("We should use Consistent Hashing for distribution among database servers. Consistent hashing will not\nonly help in replacing a dead server, but also help in distributing load among servers.")])])}),[],!1,null,null,null);t.default=o.exports},428:function(e,t,a){e.exports=a.p+"assets/img/13.a207e005.png"}}]);