(window.webpackJsonp=window.webpackJsonp||[]).push([[8],{554:function(t,e,a){t.exports=a.p+"assets/img/image--046.2c48092e.jpg"},555:function(t,e,a){t.exports=a.p+"assets/img/image--047.ecd9ee8f.jpg"},556:function(t,e,a){t.exports=a.p+"assets/img/image--048.216f859e.jpg"},557:function(t,e,a){t.exports=a.p+"assets/img/image--049.f5ec9710.jpg"},558:function(t,e,a){t.exports=a.p+"assets/img/image--050.4d070bce.jpg"},559:function(t,e,a){t.exports=a.p+"assets/img/image--051.00405a60.jpg"},914:function(t,e,a){"use strict";a.r(e);var s=a(7),n=Object(s.a)({},(function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"chapter-12-schema-migrations"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#chapter-12-schema-migrations"}},[t._v("#")]),t._v(" Chapter 12. Schema Migrations")]),t._v(" "),s("h2",{attrs:{id:"_12-1-schema-changes"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_12-1-schema-changes"}},[t._v("#")]),t._v(" 12.1. Schema Changes")]),t._v(" "),s("p",[t._v("The recent trend in discussing NoSQL databases is to highlight their "),s("em",[t._v("schemaless")]),t._v(" nature—it is a\npopular feature that allows developers to concentrate on the domain design without worrying about\nschema changes. It’s especially true with the rise of agile methods [Agile Methods] where responding\nto changing requirements is important.")]),t._v(" "),s("p",[t._v("Discussions, iterations, and feedback loops involving domain experts and product owners are\nimportant to derive the right understanding of the data; these discussions must not be hampered by a\ndatabase’s schema complexity. With NoSQL data stores, changes to the schema can be made with the\nleast amount of friction, improving developer productivity (“The Emergence of NoSQL,” p. 9 ). We\nhave seen that developing and maintaining an application in the brave new world of schemaless\ndatabases requires careful attention to be given to schema migration.")]),t._v(" "),s("h2",{attrs:{id:"_12-2-schema-changes-in-rdbms"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_12-2-schema-changes-in-rdbms"}},[t._v("#")]),t._v(" 12.2. Schema Changes in RDBMS")]),t._v(" "),s("p",[t._v("While developing with standard RDBMS technologies, we develop objects, their corresponding\ntables, and their relationships. Consider a simple object model and data model that has Customer,\nOrder, and OrderItems. The ER model would look like Figure 12.1.")]),t._v(" "),s("p",[s("img",{attrs:{src:a(554),alt:"img"}})]),t._v(" "),s("p",[s("strong",[t._v("Figure 12.1. Data model of an e-commerce system")])]),t._v(" "),s("p",[t._v('While this data model supports the current object model, life is good. The first time there is a\nchange in the object model, such as introducing preferredShippingType on the Customer object,\nwe have to change the object and change the database table, because without changing the table the\napplication will be out of sync with the database. When we get errors like ORA-00942: table or\nview does not exist or ORA-00904: "PREFERRED_SHIPPING_TYPE": invalid identifier,\nwe know we have this problem.')]),t._v(" "),s("p",[t._v("Typically, a database schema migration has been a project in itself. For deployment of the schema\nchanges, database change scripts are developed, using diff techniques, for all the changes in the\ndevelopment database. This approach of creating migration scripts during the deployment/release\ntime is error-prone and does not support agile development methods.")]),t._v(" "),s("h3",{attrs:{id:"_12-2-1-migrations-for-green-field-projects"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_12-2-1-migrations-for-green-field-projects"}},[t._v("#")]),t._v(" "),s("strong",[t._v("12.2.1. Migrations for Green Field Projects")])]),t._v(" "),s("p",[t._v("Scripting the database schema changes during development is better, since we can store these schema\nchanges along with the data migration scripts in the same script file. These script files should be")]),t._v(" "),s("p",[t._v("named with incrementing sequential numbers which reflect the database versions; for example, the\nfirst change to the database could have script file named as 001_Description_Of_Change.sql.\nScripting changes this way allows for the database migrations to be run preserving the order of\nchanges. Shown in Figure 12.2 is a folder of all the changes done to a database so far.")]),t._v(" "),s("p",[s("img",{attrs:{src:a(555),alt:"img"}})]),t._v(" "),s("p",[s("strong",[t._v("Figure 12.2. Sequence of migrations applied to a database")])]),t._v(" "),s("p",[t._v("Now, suppose we need to change the OrderItem table to store the DiscountedPrice and the\nFullPrice of the item. This will need a change to the OrderItem table and will be change number\n007 in our sequence of changes, as shown in Figure 12.3.")]),t._v(" "),s("p",[s("img",{attrs:{src:a(556),alt:"img"}})]),t._v(" "),s("p",[s("strong",[t._v("Figure 12.3. New change 007_DiscountedPrice.sql applied to the database")])]),t._v(" "),s("p",[t._v("We applied a new change to the database. This change’s script has the code for adding a new\ncolumn, renaming the existing column, and migrating the data needed to make the new feature work.\nShown below is the script contained in the change 007_DiscountedPrice.sql:")]),t._v(" "),s("div",{staticClass:"language-sql extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ALTER")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" orderitem "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ADD")]),t._v(" discountedprice NUMBER"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("UPDATE")]),t._v(" orderitem "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SET")]),t._v(" discountedprice "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" price"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ALTER")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" orderitem "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("MODIFY")]),t._v(" discountedprice "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ALTER")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" orderitem "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("RENAME")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("COLUMN")]),t._v(" price "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TO")]),t._v(" fullprice"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--//@UNDO")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ALTER")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" orderitem "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("RENAME")]),t._v(" fullprice "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TO")]),t._v(" price"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ALTER")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" orderitem "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DROP")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("COLUMN")]),t._v(" discountedprice"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[t._v("The change script shows the schema changes to the database as well as the data migrations needed\nto be done. In the example shown, we are using DBDeploy [DBDeploy] as the framework to manage\nthe changes to the database. DBDeploy maintains a table in the database, named ChangeLog, where\nall the changes made to the database are stored. In this table, Change_Number is what tells everyone\nwhich changes have been applied to the database. This Change_Number, which is the database\nversion, is then used to find the corresponding numbered script in the folder and apply the changes")]),t._v(" "),s("p",[t._v("which have not been applied yet. When we write a script with the change number 007 and apply it to\nthe database using DBDeploy, DBDeploy will check the ChangeLog and pick up all the scripts from\nthe folder that have not yet been applied. Figure 12.4 is the screenshot of DBDeploy applying the\nchange to the database.")]),t._v(" "),s("p",[s("img",{attrs:{src:a(557),alt:"img"}})]),t._v(" "),s("p",[s("strong",[t._v("Figure 12.4. DBDeploy upgrading the database with change number 007")])]),t._v(" "),s("p",[t._v("The best way to integrate with the rest of the developers is to use your project’s version control\nrepository to store all these change scripts, so that you can keep track of the version of the software\nand the database in the same place, eliminating possible mismatches between the database and the\napplication. There are many other tools for such upgrades, including Liquibase [Liquibase], MyBatis\nMigrator [MyBatis Migrator], DBMaintain [DBMaintain].")]),t._v(" "),s("h3",{attrs:{id:"_12-2-2-migrations-in-legacy-projects"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_12-2-2-migrations-in-legacy-projects"}},[t._v("#")]),t._v(" "),s("strong",[t._v("12.2.2. Migrations in Legacy Projects")])]),t._v(" "),s("p",[t._v("Not every project is a green field. How to implement migrations when an existing application is in\nproduction? We found that taking an existing database and extracting its structure into scripts, along\nwith all the database code and any reference data, works as a baseline for the project. This baseline\nshould not contain transactional data. Once the baseline is ready, further changes can be done using\nthe migrations technique described above (Figure 12.5).")]),t._v(" "),s("p",[s("img",{attrs:{src:a(558),alt:"img"}})]),t._v(" "),s("p",[s("strong",[t._v("Figure 12.5. Use of baseline scripts with a legacy database")])]),t._v(" "),s("p",[t._v("One of the main aspects of migrations should be maintaining backward compatibility of the\ndatabase schema. In many enterprises there are multiple applications using the database; when we\nchange the database for one application, this change should not break other applications. We can\nachieve backward compatibility by maintaining a transition phase for the change, as described in\ndetail in "),s("em",[t._v("Refactoring Databases")]),t._v(" [Ambler and Sadalage].")]),t._v(" "),s("p",[t._v("During a "),s("strong",[t._v("transition phase")]),t._v(" , the old schema and the new schema are maintained in parallel and are\navailable for all the applications using the database. For this, we have to introduce scaffolding code,\nsuch as triggers, views, and virtual columns ensuring other applications can access the database\nschema and the data they require without any code changes.")]),t._v(" "),s("div",{staticClass:"language-sql extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ALTER")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" customer \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ADD")]),t._v(" fullname VARCHAR2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("60")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("UPDATE")]),t._v(" customer "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SET")]),t._v(" fullname "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" fname"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("OR")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("REPLACE")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TRIGGER")]),t._v(" SyncCustomerFullName\nBEFORE "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("OR")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("UPDATE")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" customer\nREFERENCING OLD "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" OLD NEW "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" NEW\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FOR EACH ROW")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BEGIN")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("IF")]),t._v(" :NEW"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fname "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("IS")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),t._v(" \n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" :NEW"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fname :"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" :NEW"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fullname"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("IF")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("IF")]),t._v(" :NEW"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fullname "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("IS")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),t._v(" \n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" :NEW"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fullname :"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" :NEW"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fname\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("IF")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--Drop Trigger and fname")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--when all applications start using customer.fullname")]),t._v("\n")])])]),s("p",[t._v("In the example, we are trying to rename the customer.fname column to customer.fullname as\nwe want to avoid any ambiguity of fname meaning either fullname or firstname. A direct rename\nof the fname column and changing the application code we are responsible for may just work, for our\napplication—but will not for the other applications in the enterprise that are accessing the same\ndatabase.")]),t._v(" "),s("p",[t._v("Using the transition phase technique, we introduce the new column fullname, copy the data over to\nfullname, but leave the old column fname around. We also introduce a BEFORE UPDATE trigger to\nsynchronize data between the columns before they are committed to the database.")]),t._v(" "),s("p",[t._v("Now, when applications read data from the table, they will read either from fname or from\nfullname but will always get the right data. We can drop the trigger and the fname column once all\nthe applications have moved on to using the new fullname column.")]),t._v(" "),s("p",[t._v("It’s very hard to do schema migrations on large datasets in RDBMS, especially if we have to keep\nthe database available to the applications, as large data movements and structural changes usually\ncreate locks on the database tables.")]),t._v(" "),s("h2",{attrs:{id:"_12-3-schema-changes-in-a-nosql-data-store"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_12-3-schema-changes-in-a-nosql-data-store"}},[t._v("#")]),t._v(" 12.3. Schema Changes in a NoSQL Data Store")]),t._v(" "),s("p",[t._v("An RDBMS database has to be changed before the application is changed. This is what the "),s("em",[t._v("schema-\nfree")]),t._v(" , or "),s("em",[t._v("schemaless")]),t._v(" , approach tries to avoid, aiming at flexibility of schema changes per entity.\nFrequent changes to the schema are needed to react to frequent market changes and product\ninnovations.")]),t._v(" "),s("p",[t._v("When developing with NoSQL databases, in some cases the schema does not have to be thought\nabout beforehand. We still have to design and think about other aspects, such as the types of\nrelationships (with graph databases), or the names of the column families, rows, columns, order of\ncolumns (with column databases), or how are the keys assigned and what is the structure of the data\ninside the value object (with key-value stores). Even if we didn’t think about these up front, or if we\nwant to change our decisions, it is easy to do so.")]),t._v(" "),s("p",[t._v("The claim that NoSQL databases are entirely schemaless is misleading; while they store the data\nwithout regard to the schema the data adheres to, that schema has to be defined by the application,\nbecause the data stream has to be parsed by the application when reading the data from the database.\nAlso, the application has to create the data that would be saved in the database. If the application\ncannot parse the data from the database, we have a schema mismatch even if, instead of the RDBMS\ndatabase throwing a error, this error is now encountered by the application. Thus, even in schemaless\ndatabases, the schema of the data has to be taken into consideration when refactoring the application.")]),t._v(" "),s("p",[t._v("Schema changes especially matter when there is a deployed application and existing production\ndata. For the sake of simplicity, assume we are using a document data store like MongoDB\n[MongoDB] and we have the same data model as before: customer, order, and orderItems.")]),t._v(" "),s("div",{staticClass:"language-json extra-class"},[s("pre",{pre:!0,attrs:{class:"language-json"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"_id"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"4BD8AE97C47016442AF4A580"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"customerid"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("99999")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Foo Sushi Inc"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"since"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"12/12/2012"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"order"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"orderid"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"4821-UXWE-122012"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"orderdate"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"12/12/2001"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"orderItems"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"product"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Fortune Cookies"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"price"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("19.99")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("Application code to write this document structure to MongoDB:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("BasicDBObject")]),t._v(" orderItem "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("BasicDBObject")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\norderItem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"product"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" productName"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\norderItem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"price"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" price"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\norderItems"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("orderItem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[t._v("Code to read the document back from the database:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("BasicDBObject")]),t._v(" item "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("BasicDBObject")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" orderItem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" productName "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getString")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"product"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Double")]),t._v(" price "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getDouble")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"price"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[t._v("Changing the objects to add preferredShippingType does not require any change in the database,\nas the database does not care that different documents do not follow the same schema. This allows for\nfaster development and easy deployments. All that needs to be deployed is the application—no\nchanges on the database side are needed. The code has to make sure that documents that do not have\nthe preferredShippingType attribute can still be parsed—and that’s all.")]),t._v(" "),s("p",[t._v("Of course we are simplifying the schema change situation here. Let’s look at the schema change we\nmade before: introducing discountedPrice and renaming price to fullPrice. To make this change,\nwe rename the price attribute to fullPrice and add discountedPrice attribute. The changed\ndocument is")]),t._v(" "),s("div",{staticClass:"language-json extra-class"},[s("pre",{pre:!0,attrs:{class:"language-json"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"_id"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"5BD8AE97C47016442AF4A580"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"customerid"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("66778")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"India House"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"since"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"12/12/2012"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"order"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"orderid"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"4821-UXWE-222012"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"orderdate"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"12/12/2001"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"orderItems"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"product"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Chair Covers"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"fullPrice"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("29.99")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"discountedPrice"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("26.99")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("Once we deploy this change, new customers and their orders can be saved and read back without\nproblems, but for existing orders the price of their product cannot be read, because now the code is\nlooking for fullPrice but the document has only price.")]),t._v(" "),s("h3",{attrs:{id:"_12-3-1-incremental-migration"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_12-3-1-incremental-migration"}},[t._v("#")]),t._v(" "),s("strong",[t._v("12.3.1. Incremental Migration")])]),t._v(" "),s("p",[t._v("Schema mismatch trips many new converts to the NoSQL world. When schema is changed on the\napplication, we have to make sure to convert all the existing data to the new schema (depending on\ndata size, this might be an expensive operation). Another option would be to make sure that data,\nbefore the schema changed, can still be parsed by the new code, and when it’s saved, it is saved back\nin the new schema. This technique, known as "),s("strong",[t._v("incremental migration")]),t._v(" , will migrate data over time;\nsome data may never get migrated, because it was never accessed. We are reading both price and\nfullPrice from the document:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("BasicDBObject")]),t._v(" item "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("BasicDBObject")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" orderItem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" productName "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getString")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"product"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Double")]),t._v(" fullPrice "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getDouble")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"price"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("fullPrice "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    fullPrice "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getDouble")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fullPrice"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Double")]),t._v(" discountedPrice "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getDouble")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"discountedPrice"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[t._v("When writing the document back, the old attribute price is not saved:")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("BasicDBObject")]),t._v(" orderItem "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("BasicDBObject")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\norderItem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"product"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" productName"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\norderItem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fullPrice"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" price"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\norderItem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"discountedPrice"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" discountedPrice"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\norderItems"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("orderItem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[t._v("When using incremental migration, there could be many versions of the object on the application\nside that can translate the old schema to the new schema; while saving the object back, it is saved\nusing the new object. This gradual migration of the data helps the application evolve faster.")]),t._v(" "),s("p",[t._v("The incremental migration technique will complicate the object design, especially as new changes\nare being introduced yet old changes are not being taken out. This period between the change\ndeployment and the last object in the database migrating to the new schema is known as the transition\nperiod (Figure 12.6). Keep it as short as possible and focus it to the minimum possible scope—this\nwill help you keep your objects clean.")]),t._v(" "),s("p",[s("img",{attrs:{src:a(559),alt:"img"}})]),t._v(" "),s("p",[s("strong",[t._v("Figure 12.6. Transition period of schema changes")])]),t._v(" "),s("p",[t._v("The incremental migration technique can also be implemented with a schema_version field on the\ndata, used by the application to choose the correct code to parse the data into the objects. When\nsaving, the data is migrated to the latest version and the schema_version is updated to reflect that.")]),t._v(" "),s("p",[t._v("Having a proper translation layer between your domain and the database is important so that, as the\nschema changes, managing multiple versions of the schema is restricted to the translation layer and\ndoes not leak into the whole application.")]),t._v(" "),s("p",[t._v("Mobile apps create special requirements. Since we cannot enforce the latest upgrades of the\napplication, the application should be able to handle almost all versions of the schema.")]),t._v(" "),s("h3",{attrs:{id:"_12-3-2-migrations-in-graph-databases"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_12-3-2-migrations-in-graph-databases"}},[t._v("#")]),t._v(" "),s("strong",[t._v("12.3.2. Migrations in Graph Databases")])]),t._v(" "),s("p",[t._v("Graph databases have edges that have types and properties. If you change the type of these edges in\nthe codebase, you no longer can traverse the database, rendering it unusable. To get around this, you\ncan traverse all the edges and change the type of each edge. This operation can be expensive and\nrequires you to write code to migrate all the edges in the database.")]),t._v(" "),s("p",[t._v("If we need to maintain backward compatibility or do not want to change the whole graph in one go,\nwe can just create new edges between the nodes; later when we are comfortable about the change, the\nold edges can be dropped. We can use traversals with multiple edge types to traverse the graph using\nthe new and old edge types. This technique may help a great deal with large databases, especially if\nwe want to maintain high availability.")]),t._v(" "),s("p",[t._v("If we have to change properties on all the nodes or edges, we have to fetch all the nodes and\nchange all the properties that need to be changed. An example would be adding NodeCreatedBy and\nNodeCreatedOn to all existing nodes to track the changes being made to each node.")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Node")]),t._v(" node "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" database"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getAllNodes")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    node"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("setProperty")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"NodeCreatedBy"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getSystemUser")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    node"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("setProperty")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"NodeCreatedOn"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getSystemTimeStamp")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("We may have to change the data in the nodes. New data may be derived from the existing node\ndata, or it could be imported from some other source. The migration can be done by fetching all nodes\nusing an index provided by the source of data and writing relevant data to each node.")]),t._v(" "),s("h3",{attrs:{id:"_12-3-3-changing-aggregate-structure"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_12-3-3-changing-aggregate-structure"}},[t._v("#")]),t._v(" "),s("strong",[t._v("12.3.3. Changing Aggregate Structure")])]),t._v(" "),s("p",[t._v("Sometimes you need to change the schema design, for example by splitting large objects into smaller\nones that are stored independently. Suppose you have a customer aggregate that contains all the\ncustomers orders, and you want to separate the customer and each of their orders into different\naggregate units.")]),t._v(" "),s("p",[t._v("You then have to ensure that the code can work with both versions of the aggregates. If it does not\nfind the old objects, it will look for the new aggregates.")]),t._v(" "),s("p",[t._v("Code that runs in the background can read one aggregate at a time, make the necessary change, and\nsave the data back into different aggregates. The advantage of operating on one aggregate at a time is\nthat this way, you’re not affecting data availability for the application.")]),t._v(" "),s("h2",{attrs:{id:"_12-4-further-reading"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_12-4-further-reading"}},[t._v("#")]),t._v(" 12.4. Further Reading")]),t._v(" "),s("p",[t._v("For more on migrations with relational databases, see [Ambler and Sadalage]. Although much of this\ncontent is specific to relational work, the general principles in migration will also apply to other\ndatabases.")]),t._v(" "),s("h2",{attrs:{id:"_12-5-key-points"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_12-5-key-points"}},[t._v("#")]),t._v(" 12.5. Key Points")]),t._v(" "),s("ul",[s("li",[t._v("Databases with strong schemas, such as relational databases, can be migrated by saving each schema change, plus its data migration, in a version-controlled sequence.")]),t._v(" "),s("li",[t._v("Schemaless databases still need careful migration due to the implicit schema in any code that accesses the data.")]),t._v(" "),s("li",[t._v("Schemaless databases can use the same migration techniques as databases with strong schemas.")]),t._v(" "),s("li",[t._v("Schemaless databases can also read data in a way that’s tolerant to changes in the data’s implicit schema and use incremental migration to update data.")])])])}),[],!1,null,null,null);e.default=n.exports}}]);