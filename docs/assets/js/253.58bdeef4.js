(window.webpackJsonp=window.webpackJsonp||[]).push([[253],{821:function(e,t,a){"use strict";a.r(t);var s=a(7),n=Object(s.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"_9-unit-tests"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_9-unit-tests"}},[e._v("#")]),e._v(" 9. Unit Tests")]),e._v(" "),a("p",[e._v("Our profession has come a long way in the last ten years. In 1997 no one had heard of\nTest Driven Development. For the vast majority of us, unit tests were short bits of throw-\naway code that we wrote to make sure our programs “worked.” We would painstakingly\nwrite our classes and methods, and then we would concoct some ad hoc code to test\nthem. Typically this would involve some kind of simple driver program that would allow\nus to manually interact with the program we had written.")]),e._v(" "),a("p",[e._v("I remember writing a C++ program for an embedded real-time system back in the\nmid-90s. The program was a simple timer with the following signature:")]),e._v(" "),a("p",[e._v("void Timer::ScheduleCommand(Command* theCommand, int milliseconds)\nThe idea was simple; the executemethod of the Commandwould be executed in a new\nthread after the specified number of milliseconds. The problem was, how to test it.")]),e._v(" "),a("p",[e._v("122 "),a("strong",[e._v("Chapter 9: Unit Tests")])]),e._v(" "),a("p",[e._v("I cobbled together a simple driver program that listened to the keyboard. Every time a\ncharacter was typed, it would schedule a command that would type the same character five\nseconds later. Then I tapped out a rhythmic melody on the keyboard and waited for that\nmelody to replay on the screen five seconds later.")]),e._v(" "),a("p",[e._v("“I... want-a-girl... just... like-the-girl-who-marr... ied... dear... old... dad.”\nI actually sang that melody while typing the “.” key, and then I sang it again as the\ndots appeared on the screen.")]),e._v(" "),a("p",[e._v("That was my test! Once I saw it work and demonstrated it to my colleagues, I threw\nthe test code away.")]),e._v(" "),a("p",[e._v("As I said, our profession has come a long way. Nowadays I would write a test that made\nsure that every nook and cranny of that code worked as I expected it to. I would isolate my\ncode from the operating system rather than just calling the standard timing functions. I\nwould mock out those timing functions so that I had absolute control over the time. I would\nschedule commands that set boolean flags, and then I would step the time forward, watching\nthose flags and ensuring that they went from false to true just as I changed the time to the\nright value.")]),e._v(" "),a("p",[e._v("Once I got a suite of tests to pass, I would make sure that those tests were convenient\nto run for anyone else who needed to work with the code. I would ensure that the tests and\nthe code were checked in together into the same source package.")]),e._v(" "),a("p",[e._v("Yes, we’ve come a long way; but we have farther to go. The Agile and TDD move-\nments have encouraged many programmers to write automated unit tests, and more are\njoining their ranks every day. But in the mad rush to add testing to our discipline, many\nprogrammers have missed some of the more subtle, and important, points of writing\ngood tests.")]),e._v(" "),a("h2",{attrs:{id:"the-three-laws-of-tdd"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#the-three-laws-of-tdd"}},[e._v("#")]),e._v(" The Three Laws of TDD ...")]),e._v(" "),a("p",[e._v("By now everyone knows that TDD asks us to write unit tests first, before we write produc-\ntion code. But that rule is just the tip of the iceberg. Consider the following three laws:^1")]),e._v(" "),a("p",[a("strong",[e._v("First Law")]),e._v(" You may not write production code until you have written a failing unit test.")]),e._v(" "),a("p",[a("strong",[e._v("Second Law")]),e._v(" You may not write more of a unit test than is sufficient to fail, and not com-\npiling is failing.")]),e._v(" "),a("p",[a("strong",[e._v("Third Law")]),e._v(" You may not write more production code than is sufficient to pass the cur-\nrently failing test.")]),e._v(" "),a("ol",[a("li",[a("em",[e._v("Professionalism and Test-Driven Development")]),e._v(" , Robert C. Martin, Object Mentor, IEEE Software, May/June 2007 (Vol. 24,\nNo. 3) pp. 32–36\n"),a("a",{attrs:{href:"http://doi.ieeecomputersociety.org/10.1109/MS.2007.85",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://doi.ieeecomputersociety.org/10.1109/MS.2007.85"),a("OutboundLink")],1)])]),e._v(" "),a("p",[a("strong",[e._v("Keeping Tests Clean")]),e._v(" 123")]),e._v(" "),a("p",[e._v("These three laws lock you into a cycle that is perhaps thirty seconds long. The tests\nand the production code are written "),a("em",[e._v("together,")]),e._v(" with the tests just a few seconds ahead of the\nproduction code.")]),e._v(" "),a("p",[e._v("If we work this way, we will write dozens of tests every day, hundreds of tests every\nmonth, and thousands of tests every year. If we work this way, those tests will cover virtu-\nally all of our production code. The sheer bulk of those tests, which can rival the size of the\nproduction code itself, can present a daunting management problem.")]),e._v(" "),a("h2",{attrs:{id:"keeping-tests-clean"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#keeping-tests-clean"}},[e._v("#")]),e._v(" Keeping Tests Clean ..")]),e._v(" "),a("p",[e._v("Some years back I was asked to coach a team who had explicitly decided that their test\ncode "),a("em",[e._v("should not")]),e._v(" be maintained to the same standards of quality as their production code.\nThey gave each other license to break the rules in their unit tests. “Quick and dirty” was\nthe watchword. Their variables did not have to be well named, their test functions did not\nneed to be short and descriptive. Their test code did not need to be well designed and\nthoughtfully partitioned. So long as the test code worked, and so long as it covered the pro-\nduction code, it was good enough.")]),e._v(" "),a("p",[e._v("Some of you reading this might sympathize with that decision. Perhaps, long in the\npast, you wrote tests of the kind that I wrote for that Timerclass. It’s a huge step from\nwriting that kind of throw-away test, to writing a suite of automated unit tests. So, like the\nteam I was coaching, you might decide that having dirty tests is better than having no\ntests.")]),e._v(" "),a("p",[e._v("What this team did not realize was that having dirty tests is equivalent to, if not worse\nthan, having no tests. The problem is that tests must change as the production code\nevolves. The dirtier the tests, the harder they are to change. The more tangled the test code,\nthe more likely it is that you will spend more time cramming new tests into the suite than it\ntakes to write the new production code. As you modify the production code, old tests start\nto fail, and the mess in the test code makes it hard to get those tests to pass again. So the\ntests become viewed as an ever-increasing liability.")]),e._v(" "),a("p",[e._v("From release to release the cost of maintaining my team’s test suite rose. Eventually it\nbecame the single biggest complaint among the developers. When managers asked why\ntheir estimates were getting so large, the developers blamed the tests. In the end they were\nforced to discard the test suite entirely.")]),e._v(" "),a("p",[e._v("But, without a test suite they lost the ability to make sure that changes to their code\nbase worked as expected. Without a test suite they could not ensure that changes to one\npart of their system did not break other parts of their system. So their defect rate began to\nrise. As the number of unintended defects rose, they started to fear making changes. They\nstopped cleaning their production code because they feared the changes would do more\nharm than good. Their production code began to rot. In the end they were left with no tests,\ntangled and bug-riddled production code, frustrated customers, and the feeling that their\ntesting effort had failed them.")]),e._v(" "),a("p",[e._v("124 "),a("strong",[e._v("Chapter 9: Unit Tests")])]),e._v(" "),a("p",[e._v("In a way they were right. Their testing effort "),a("em",[e._v("had")]),e._v(" failed them. But it was their decision\nto allow the tests to be messy that was the seed of that failure. Had they kept their tests\nclean, their testing effort would not have failed. I can say this with some certainty because\nI have participated in, and coached, many teams who have been successful with "),a("em",[e._v("clean")]),e._v(" unit\ntests.")]),e._v(" "),a("p",[e._v("The moral of the story is simple: "),a("em",[e._v("Test code is just as important as production code.")]),e._v(" It\nis not a second-class citizen. It requires thought, design, and care. It must be kept as clean\nas production code.")]),e._v(" "),a("h2",{attrs:{id:"tests-enable-the-ilities"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tests-enable-the-ilities"}},[e._v("#")]),e._v(" Tests Enable the -ilities...")]),e._v(" "),a("p",[e._v("If you don’t keep your tests clean, you will lose them. And without them, you lose the very\nthing that keeps your production code flexible. Yes, you read that correctly. It is "),a("em",[e._v("unit tests")]),e._v("\nthat keep our code flexible, maintainable, and reusable. The reason is simple. If you have\ntests, you do not fear making changes to the code! Without tests every change is a possible\nbug. No matter how flexible your architecture is, no matter how nicely partitioned your\ndesign, without tests you will be reluctant to make changes because of the fear that you\nwill introduce undetected bugs.")]),e._v(" "),a("p",[e._v("But "),a("em",[e._v("with")]),e._v(" tests that fear virtually disappears. The higher your test coverage, the less\nyour fear. You can make changes with near impunity to code that has a less than stellar\narchitecture and a tangled and opaque design. Indeed, you can "),a("em",[e._v("improve")]),e._v(" that architecture\nand design without fear!")]),e._v(" "),a("p",[e._v("So having an automated suite of unit tests that cover the production code is the key to\nkeeping your design and architecture as clean as possible. Tests enable all the -ilities,\nbecause tests enable "),a("em",[e._v("change")]),e._v(".")]),e._v(" "),a("p",[e._v("So if your tests are dirty, then your ability to change your code is hampered, and you\nbegin to lose the ability to improve the structure of that code. The dirtier your tests, the\ndirtier your code becomes. Eventually you lose the tests, and your code rots.")]),e._v(" "),a("h2",{attrs:{id:"clean-tests"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#clean-tests"}},[e._v("#")]),e._v(" Clean Tests .")]),e._v(" "),a("p",[e._v("What makes a clean test? Three things. Readability, readability, and readability. Read-\nability is perhaps even more important in unit tests than it is in production code. What\nmakes tests readable? The same thing that makes all code readable: clarity, simplicity,\nand density of expression. In a test you want to say a lot with as few expressions as\npossible.")]),e._v(" "),a("p",[e._v("Consider the code from FitNesse in Listing 9-1. These three tests are difficult to\nunderstand and can certainly be improved. First, there is a terrible amount of duplicate\ncode [G5] in the repeated calls to addPageandassertSubString. More importantly, this\ncode is just loaded with details that interfere with the expressiveness of the test.")]),e._v(" "),a("p",[a("strong",[e._v("Clean Tests")]),e._v(" 125")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('Listing 9-1\nSerializedPageResponderTest.java\npublic void testGetPageHieratchyAsXml() throws Exception\n{\ncrawler.addPage(root, PathParser.parse("PageOne"));\ncrawler.addPage(root, PathParser.parse("PageOne.ChildOne"));\ncrawler.addPage(root, PathParser.parse("PageTwo"));\nrequest.setResource("root");\nrequest.addInput("type", "pages");\nResponder responder = new SerializedPageResponder();\nSimpleResponse response =\n(SimpleResponse) responder.makeResponse(\nnew FitNesseContext(root), request);\nString xml = response.getContent();\nassertEquals("text/xml", response.getContentType());\nassertSubString("<name>PageOne</name>", xml);\nassertSubString("<name>PageTwo</name>", xml);\nassertSubString("<name>ChildOne</name>", xml);\n}\npublic void testGetPageHieratchyAsXmlDoesntContainSymbolicLinks()\nthrows Exception\n{\nWikiPage pageOne = crawler.addPage(root, PathParser.parse("PageOne"));\ncrawler.addPage(root, PathParser.parse("PageOne.ChildOne"));\ncrawler.addPage(root, PathParser.parse("PageTwo"));\nPageData data = pageOne.getData();\nWikiPageProperties properties = data.getProperties();\nWikiPageProperty symLinks = properties.set(SymbolicPage.PROPERTY_NAME);\nsymLinks.set("SymPage", "PageTwo");\npageOne.commit(data);\nrequest.setResource("root");\nrequest.addInput("type", "pages");\nResponder responder = new SerializedPageResponder();\nSimpleResponse response =\n(SimpleResponse) responder.makeResponse(\nnew FitNesseContext(root), request);\nString xml = response.getContent();\nassertEquals("text/xml", response.getContentType());\nassertSubString("<name>PageOne</name>", xml);\nassertSubString("<name>PageTwo</name>", xml);\nassertSubString("<name>ChildOne</name>", xml);\nassertNotSubString("SymPage", xml);\n}\n')])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('public void testGetDataAsHtml() throws Exception\n{\ncrawler.addPage(root, PathParser.parse("TestPageOne"), "test page");\nrequest.setResource("TestPageOne");\nrequest.addInput("type", "data");\n')])])]),a("p",[e._v("126 "),a("strong",[e._v("Chapter 9: Unit Tests")])]),e._v(" "),a("p",[e._v("For example, look at the PathParsercalls. They transform strings into PagePath\ninstances used by the crawlers. This transformation is completely irrelevant to the test at\nhand and serves only to obfuscate the intent. The details surrounding the creation of the\nresponderand the gathering and casting of the responseare also just noise. Then there’s the\nham-handed way that the request URL is built from a resource and an argument. (I helped\nwrite this code, so I feel free to roundly criticize it.)")]),e._v(" "),a("p",[e._v("In the end, this code was not designed to be read. The poor reader is inundated with a\nswarm of details that must be understood before the tests make any real sense.")]),e._v(" "),a("p",[e._v("Now consider the improved tests in Listing 9-2. These tests do the exact same thing,\nbut they have been refactored into a much cleaner and more explanatory form.")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('Responder responder = new SerializedPageResponder();\nSimpleResponse response =\n(SimpleResponse) responder.makeResponse(\nnew FitNesseContext(root), request);\nString xml = response.getContent();\nassertEquals("text/xml", response.getContentType());\nassertSubString("test page", xml);\nassertSubString("<Test", xml);\n}\n')])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('Listing 9-2\nSerializedPageResponderTest.java (refactored)\npublic void testGetPageHierarchyAsXml() throws Exception {\nmakePages("PageOne", "PageOne.ChildOne", "PageTwo");\nsubmitRequest("root", "type:pages");\nassertResponseIsXML();\nassertResponseContains(\n"<name>PageOne</name>", "<name>PageTwo</name>", "<name>ChildOne</name>"\n);\n}\npublic void testSymbolicLinksAreNotInXmlPageHierarchy() throws Exception {\nWikiPage page = makePage("PageOne");\nmakePages("PageOne.ChildOne", "PageTwo");\naddLinkTo(page, "PageTwo", "SymPage");\nsubmitRequest("root", "type:pages");\nassertResponseIsXML();\nassertResponseContains(\n"<name>PageOne</name>", "<name>PageTwo</name>", "<name>ChildOne</name>"\n);\nassertResponseDoesNotContain("SymPage");\n}\n')])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("Listing 9-1 (continued)\nSerializedPageResponderTest.java\n")])])]),a("p",[a("strong",[e._v("Clean Tests")]),e._v(" 127")]),e._v(" "),a("p",[e._v("The BUILD-OPERATE-CHECK^2 pattern is made obvious by the structure of these tests.\nEach of the tests is clearly split into three parts. The first part builds up the test data, the\nsecond part operates on that test data, and the third part checks that the operation yielded\nthe expected results.")]),e._v(" "),a("p",[e._v("Notice that the vast majority of annoying detail has been eliminated. The tests get\nright to the point and use only the data types and functions that they truly need. Anyone\nwho reads these tests should be able to work out what they do very quickly, without being\nmisled or overwhelmed by details.")]),e._v(" "),a("h2",{attrs:{id:"domain-specific-testing-language"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#domain-specific-testing-language"}},[e._v("#")]),e._v(" Domain-Specific Testing Language")]),e._v(" "),a("p",[e._v("The tests in Listing 9-2 demonstrate the technique of building a domain-specific language\nfor your tests. Rather than using the APIs that programmers use to manipulate the sys-\ntem, we build up a set of functions and utilities that make use of those APIs and that\nmake the tests more convenient to write and easier to read. These functions and utilities\nbecome a specialized API used by the tests. They are a testing "),a("em",[e._v("language")]),e._v(" that program-\nmers use to help themselves to write their tests and to help those who must read those\ntests later on.")]),e._v(" "),a("p",[e._v("This testing API is not designed up front; rather it evolves from the continued refac-\ntoring of test code that has gotten too tainted by obfuscating detail. Just as you saw me\nrefactor Listing 9-1 into Listing 9-2, so too will disciplined developers refactor their test\ncode into more succinct and expressive forms.")]),e._v(" "),a("h2",{attrs:{id:"a-dual-standard"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#a-dual-standard"}},[e._v("#")]),e._v(" A Dual Standard .")]),e._v(" "),a("p",[e._v("In one sense the team I mentioned at the beginning of this chapter had things right. The\ncode within the testing API "),a("em",[e._v("does")]),e._v(" have a different set of engineering standards than produc-\ntion code. It must still be simple, succinct, and expressive, but it need not be as efficient as\nproduction code. After all, it runs in a test environment, not a production environment, and\nthose two environment have very different needs.")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('public void testGetDataAsXml() throws Exception {\nmakePageWithContent("TestPageOne", "test page");\nsubmitRequest("TestPageOne", "type:data");\nassertResponseIsXML();\nassertResponseContains("test page", "<Test");\n}\n')])])]),a("ol",{attrs:{start:"2"}},[a("li",[a("a",{attrs:{href:"http://fitnesse.org/FitNesse.AcceptanceTestPatterns",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://fitnesse.org/FitNesse.AcceptanceTestPatterns"),a("OutboundLink")],1)])]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("Listing 9-2 (continued)\nSerializedPageResponderTest.java (refactored)\n")])])]),a("p",[e._v("128 "),a("strong",[e._v("Chapter 9: Unit Tests")])]),e._v(" "),a("p",[e._v("Consider the test in Listing 9-3. I wrote this test as part of an environment control sys-\ntem I was prototyping. Without going into the details you can tell that this test checks that\nthe low temperature alarm, the heater, and the blower are all turned on when the tempera-\nture is “way too cold.”")]),e._v(" "),a("p",[e._v("There are, of course, lots of details here. For example, what is that ticfunction all\nabout? In fact, I’d rather you not worry about that while reading this test. I’d rather you just\nworry about whether you agree that the end state of the system is consistent with the tem-\nperature being “way too cold.”")]),e._v(" "),a("p",[e._v("Notice, as you read the test, that your eye needs to bounce back and forth between\nthe name of the state being checked, and the "),a("em",[e._v("sense")]),e._v(" of the state being checked. You see\nheaterState, and then your eyes glissade left to assertTrue. You see coolerStateand your\neyes must track left to assertFalse. This is tedious and unreliable. It makes the test hard\nto read.")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("I improved the reading of this test greatly by transforming it into Listing 9-4.\n")])])]),a("p",[e._v("Of course I hid the detail of the ticfunction by creating a wayTooColdfunction. But the\nthing to note is the strange string in the assertEquals. Upper case means “on,” lower case\nmeans “off,” and the letters are always in the following order: {heater, blower, cooler,\nhi-temp-alarm, lo-temp-alarm}.")]),e._v(" "),a("p",[e._v("Even though this is close to a violation of the rule about mental mapping,^3 it seems\nappropriate in this case. Notice, once you know the meaning, your eyes glide across")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("Listing 9-3\nEnvironmentControllerTest.java\n@Test\npublic void turnOnLoTempAlarmAtThreashold() throws Exception {\nhw.setTemp(WAY_TOO_COLD);\ncontroller.tic();\nassertTrue(hw.heaterState());\nassertTrue(hw.blowerState());\nassertFalse(hw.coolerState());\nassertFalse(hw.hiTempAlarm());\nassertTrue(hw.loTempAlarm());\n}\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('Listing 9-4\nEnvironmentControllerTest.java (refactored)\n@Test\npublic void turnOnLoTempAlarmAtThreshold() throws Exception {\nwayTooCold();\nassertEquals("HBchL", hw.getState());\n}\n')])])]),a("ol",{attrs:{start:"3"}},[a("li",[e._v("“Avoid Mental Mapping” on page 25.")])]),e._v(" "),a("p",[a("strong",[e._v("Clean Tests")]),e._v(" 129")]),e._v(" "),a("p",[e._v("that string and you can quickly interpret the results. Reading the test becomes almost a\npleasure. Just take a look at Listing 9-5 and see how easy it is to understand these tests.")]),e._v(" "),a("p",[e._v("ThegetStatefunction is shown in Listing 9-6. Notice that this is not very efficient\ncode. To make it efficient, I probably should have used a StringBuffer.")]),e._v(" "),a("p",[e._v("StringBuffers are a bit ugly. Even in production code I will avoid them if the cost is\nsmall; and you could argue that the cost of the code in Listing 9-6 is very small. However,\nthis application is clearly an embedded real-time system, and it is likely that computer and\nmemory resources are very constrained. The "),a("em",[e._v("test")]),e._v(" environment, however, is not likely to be\nconstrained at all.")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('Listing 9-5\nEnvironmentControllerTest.java (bigger selection)\n@Test\npublic void turnOnCoolerAndBlowerIfTooHot() throws Exception {\ntooHot();\nassertEquals("hBChl", hw.getState());\n}\n@Test\npublic void turnOnHeaterAndBlowerIfTooCold() throws Exception {\ntooCold();\nassertEquals("HBchl", hw.getState());\n}\n@Test\npublic void turnOnHiTempAlarmAtThreshold() throws Exception {\nwayTooHot();\nassertEquals("hBCHl", hw.getState());\n}\n@Test\npublic void turnOnLoTempAlarmAtThreshold() throws Exception {\nwayTooCold();\nassertEquals("HBchL", hw.getState());\n}\n')])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('Listing 9-6\nMockControlHardware.java\npublic String getState() {\nString state = "";\nstate += heater? "H" : "h";\nstate += blower? "B" : "b";\nstate += cooler? "C" : "c";\nstate += hiTempAlarm? "H" : "h";\nstate += loTempAlarm? "L" : "l";\nreturn state;\n}\n')])])]),a("p",[e._v("130 "),a("strong",[e._v("Chapter 9: Unit Tests")])]),e._v(" "),a("p",[e._v("That is the nature of the dual standard. There are things that you might never do in a\nproduction environment that are perfectly fine in a test environment. Usually they involve\nissues of memory or CPU efficiency. But they "),a("em",[e._v("never")]),e._v(" involve issues of cleanliness.")]),e._v(" "),a("h2",{attrs:{id:"one-assert-per-test"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#one-assert-per-test"}},[e._v("#")]),e._v(" One Assert per Test ...")]),e._v(" "),a("p",[e._v("There is a school of thought^4 that says that every test function in a JUnit test should have one\nand only one assert statement. This rule may seem draconian, but the advantage can be seen\nin Listing 9-5. Those tests come to a single conclusion that is quick and easy to understand.")]),e._v(" "),a("p",[e._v("But what about Listing 9-2? It seems unreasonable that we could somehow easily\nmerge the assertion that the output is XML and that it contains certain substrings. How-\never, we can break the test into two separate tests, each with its own particular assertion, as\nshown in Listing 9-7.")]),e._v(" "),a("p",[e._v("Notice that I have changed the names of the functions to use the common given-when-\nthen^5 convention. This makes the tests even easier to read. Unfortunately, splitting the tests\nas shown results in a lot of duplicate code.")]),e._v(" "),a("p",[e._v("We can eliminate the duplication by using the TEMPLATE METHOD^6 pattern and putting\nthe "),a("em",[e._v("given/when")]),e._v(" parts in the base class, and the "),a("em",[e._v("then")]),e._v(" parts in different derivatives. Or we could\ncreate a completely separate test class and put the "),a("em",[e._v("given")]),e._v(" and "),a("em",[e._v("when")]),e._v(" parts in the @Beforefunc-\ntion, and the "),a("em",[e._v("when")]),e._v(" parts in each @Test function. But this seems like too much mechanism for\nsuch a minor issue. In the end, I prefer the multiple asserts in Listing 9-2.")]),e._v(" "),a("ol",{attrs:{start:"4"}},[a("li",[e._v("See Dave Astel’s blog entry: "),a("a",{attrs:{href:"http://www.artima.com/weblogs/viewpost.jsp?thread=35578",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://www.artima.com/weblogs/viewpost.jsp?thread=35578"),a("OutboundLink")],1)])]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('Listing 9-7\nSerializedPageResponderTest.java (Single Assert)\npublic void testGetPageHierarchyAsXml() throws Exception {\ngivenPages("PageOne", "PageOne.ChildOne", "PageTwo");\nwhenRequestIsIssued("root", "type:pages");\nthenResponseShouldBeXML();\n}\n')])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('public void testGetPageHierarchyHasRightTags() throws Exception {\ngivenPages("PageOne", "PageOne.ChildOne", "PageTwo");\nwhenRequestIsIssued("root", "type:pages");\nthenResponseShouldContain(\n"<name>PageOne</name>", "<name>PageTwo</name>", "<name>ChildOne</name>"\n);\n}\n')])])]),a("ol",{attrs:{start:"5"}},[a("li",[e._v("[RSpec].")]),e._v(" "),a("li",[e._v("[GOF].")])]),e._v(" "),a("p",[a("strong",[e._v("One Assert per Test")]),e._v(" 131")]),e._v(" "),a("p",[e._v("I think the single assert rule is a good guideline.^7 I usually try to create a domain-\nspecific testing language that supports it, as in Listing 9-5. But I am not afraid to put\nmore than one assert in a test. I think the best thing we can say is that the number of\nasserts in a test ought to be minimized.")]),e._v(" "),a("h2",{attrs:{id:"single-concept-per-test"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#single-concept-per-test"}},[e._v("#")]),e._v(" Single Concept per Test ..")]),e._v(" "),a("p",[e._v("Perhaps a better rule is that we want to test a single concept in each test function. We don’t\nwant long test functions that go testing one miscellaneous thing after another. Listing 9-8\nis an example of such a test. This test should be split up into three independent tests\nbecause it tests three independent things. Merging them all together into the same function\nforces the reader to figure out why each section is there and what is being tested by that\nsection.")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("The three test functions probably ought to be like this:\n")])])]),a("ul",[a("li",[a("em",[e._v("Given")]),e._v(" the last day of a month with 31 days (like May):\n"),a("strong",[e._v("1.")]),e._v(" "),a("em",[e._v("When")]),e._v(" you add one month, such that the last day of that month is the 30th\n(like June), "),a("em",[e._v("then")]),e._v(" the date should be the 30th of that month, not the 31st.\n"),a("strong",[e._v("2.")]),e._v(" "),a("em",[e._v("When")]),e._v(" you add two months to that date, such that the final month has 31 days,\n"),a("em",[e._v("then")]),e._v(" the date should be the 31st.")])]),e._v(" "),a("ol",{attrs:{start:"7"}},[a("li",[e._v("“Keep to the code!”")])]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("Listing 9-8\n/**\n* Miscellaneous tests for the addMonths() method.\n*/\npublic void testAddMonths() {\nSerialDate d1 = SerialDate.createInstance(31, 5, 2004);\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("SerialDate d2 = SerialDate.addMonths(1, d1);\nassertEquals(30, d2.getDayOfMonth());\nassertEquals(6, d2.getMonth());\nassertEquals(2004, d2.getYYYY());\nSerialDate d3 = SerialDate.addMonths(2, d1);\nassertEquals(31, d3.getDayOfMonth());\nassertEquals(7, d3.getMonth());\nassertEquals(2004, d3.getYYYY());\nSerialDate d4 = SerialDate.addMonths(1, SerialDate.addMonths(1, d1));\nassertEquals(30, d4.getDayOfMonth());\nassertEquals(7, d4.getMonth());\nassertEquals(2004, d4.getYYYY());\n}\n")])])]),a("p",[e._v("132 "),a("strong",[e._v("Chapter 9: Unit Tests")])]),e._v(" "),a("ul",[a("li",[a("em",[e._v("Given")]),e._v(" the last day of a month with 30 days in it (like June):\n"),a("strong",[e._v("1.")]),e._v(" "),a("em",[e._v("When")]),e._v(" you add one month such that the last day of that month has 31 days, "),a("em",[e._v("then")]),e._v(" the\ndate should be the 30th, not the 31st.\nStated like this, you can see that there is a general rule hiding amidst the miscella-\nneous tests. When you increment the month, the date can be no greater than the last day of\nthe month. This implies that incrementing the month on February 28th should yield March\n28th. "),a("em",[e._v("That")]),e._v(" test is missing and would be a useful test to write.")])]),e._v(" "),a("p",[e._v("So it’s not the multiple asserts in each section of Listing 9-8 that causes the problem.\nRather it is the fact that there is more than one concept being tested. So probably the best\nrule is that you should minimize the number of asserts per concept and test just one con-\ncept per test function.")]),e._v(" "),a("h2",{attrs:{id:"f-i-r-s-t"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#f-i-r-s-t"}},[e._v("#")]),e._v(" F.I.R.S.T. .")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("8\n")])])]),a("p",[e._v("Clean tests follow five other rules that form the above acronym:")]),e._v(" "),a("p",[a("strong",[e._v("Fast")]),e._v(" Tests should be fast. They should run quickly. When tests run slow, you won’t want\nto run them frequently. If you don’t run them frequently, you won’t find problems early\nenough to fix them easily. You won’t feel as free to clean up the code. Eventually the code\nwill begin to rot.")]),e._v(" "),a("p",[a("strong",[e._v("Independent")]),e._v(" Tests should not depend on each other. One test should not set up the condi-\ntions for the next test. You should be able to run each test independently and run the tests in\nany order you like. When tests depend on each other, then the first one to fail causes a cas-\ncade of downstream failures, making diagnosis difficult and hiding downstream defects.")]),e._v(" "),a("p",[a("strong",[e._v("Repeatable")]),e._v(" Tests should be repeatable in any environment. You should be able to run the\ntests in the production environment, in the QA environment, and on your laptop while\nriding home on the train without a network. If your tests aren’t repeatable in any environ-\nment, then you’ll always have an excuse for why they fail. You’ll also find yourself unable\nto run the tests when the environment isn’t available.")]),e._v(" "),a("p",[a("strong",[e._v("Self-Validating")]),e._v(" The tests should have a boolean output. Either they pass or fail. You\nshould not have to read through a log file to tell whether the tests pass. You should not have\nto manually compare two different text files to see whether the tests pass. If the tests aren’t\nself-validating, then failure can become subjective and running the tests can require a long\nmanual evaluation.")]),e._v(" "),a("ol",{attrs:{start:"8"}},[a("li",[e._v("Object Mentor Training Materials.")])]),e._v(" "),a("p",[a("strong",[e._v("Bibliography")]),e._v(" 133")]),e._v(" "),a("p",[a("strong",[e._v("Timely")]),e._v(" The tests need to be written in a timely fashion. Unit tests should be written "),a("em",[e._v("just\nbefore")]),e._v(" the production code that makes them pass. If you write tests after the production\ncode, then you may find the production code to be hard to test. You may decide that some\nproduction code is too hard to test. You may not design the production code to be testable.")]),e._v(" "),a("h2",{attrs:{id:"conclusion"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#conclusion"}},[e._v("#")]),e._v(" Conclusion ..")]),e._v(" "),a("p",[e._v("We have barely scratched the surface of this topic. Indeed, I think an entire book could be\nwritten about "),a("em",[e._v("clean tests")]),e._v(". Tests are as important to the health of a project as the production\ncode is. Perhaps they are even more important, because tests preserve and enhance the\nflexibility, maintainability, and reusability of the production code. So keep your tests con-\nstantly clean. Work to make them expressive and succinct. Invent testing APIs that act as\ndomain-specific language that helps you write the tests.")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("If you let the tests rot, then your code will rot too. Keep your tests clean.\n")])])]),a("h2",{attrs:{id:"bibliography"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#bibliography"}},[e._v("#")]),e._v(" Bibliography ...")]),e._v(" "),a("p",[a("strong",[e._v("[RSpec]:")]),e._v(" "),a("em",[e._v("RSpec: Behavior Driven Development for Ruby Programmers")]),e._v(" ,\nAslak Hellesøy, David Chelimsky, Pragmatic Bookshelf, 2008.")]),e._v(" "),a("p",[a("strong",[e._v("[GOF]:")]),e._v(" "),a("em",[e._v("Design Patterns: Elements of Reusable Object Oriented Software")]),e._v(" , Gamma et al.,\nAddison-Wesley, 1996.")])])}),[],!1,null,null,null);t.default=n.exports}}]);