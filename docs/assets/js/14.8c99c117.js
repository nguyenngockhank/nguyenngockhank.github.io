(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{1628:function(e,a,t){"use strict";t.r(a);var s=t(7),i=Object(s.a)({},(function(){var e=this,a=e.$createElement,s=e._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[s("h1",{attrs:{id:"design-bigtable"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#design-bigtable"}},[e._v("#")]),e._v(" Design BigTable")]),e._v(" "),s("h2",{attrs:{id:"overview"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#overview"}},[e._v("#")]),e._v(" Overview")]),e._v(" "),s("h3",{attrs:{id:"goal"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#goal"}},[e._v("#")]),e._v(" Goal")]),e._v(" "),s("p",[e._v("Design a distributed and scalable system that can store a huge amount of\nstructured data. The data will be indexed by a row key where each row can\nhave an unbounded number of columns.")]),e._v(" "),s("h3",{attrs:{id:"what-is-bigtable"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#what-is-bigtable"}},[e._v("#")]),e._v(" What is BigTable")]),e._v(" "),s("p",[e._v("BigTable is a "),s("strong",[e._v("distributed")]),e._v(" and "),s("strong",[e._v("massively scalable")]),e._v(" wide-column store. It is\ndesigned to store huge sets of structured data. As its name suggests, BigTable\nprovides storage for very big tables (often in the terabyte range).")]),e._v(" "),s("p",[e._v("In terms of the CAP theorem, BigTable is a CP system, i.e., "),s("strong",[e._v("it has strictly consistent reads and writes")]),e._v(". BigTable can be used as an input source or output destination for "),s("a",{attrs:{href:"https://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("MapReduce"),s("OutboundLink")],1),e._v(" jobs.")]),e._v(" "),s("h3",{attrs:{id:"background"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#background"}},[e._v("#")]),e._v(" Background")]),e._v(" "),s("p",[e._v("BigTable was developed at Google and has been in use since 2005 in dozens\nof Google services. Because of the large scale of its services, Google could not\nuse commercial databases. Also, the cost of using an external solution would\nhave been too high. That is why Google chose to build an in-house solution.\nBigTable is a highly available and high-performing database that powers\nmultiple applications across Google — where each application has different\nneeds in terms of the size of data to be stored and latency with which results\nare expected")]),e._v(" "),s("p",[e._v("Though BigTable is not open-source itself, its paper was crucial in inspiring\npowerful open-source databases like "),s("a",{attrs:{href:"https://cassandra.apache.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Cassandra"),s("OutboundLink")],1),e._v(" (which borrows BigTable’s data model),\n"),s("a",{attrs:{href:"https://hbase.apache.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("HBase"),s("OutboundLink")],1),e._v(" (a distributed non-relational database) and "),s("a",{attrs:{href:"https://hypertable.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Hypertable"),s("OutboundLink")],1),e._v(".")]),e._v(" "),s("h3",{attrs:{id:"bigtable-use-cases"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#bigtable-use-cases"}},[e._v("#")]),e._v(" BigTable use cases")]),e._v(" "),s("p",[e._v("Google built BigTable to store large amounts of data and perform thousands\nof queries per second on that data. Examples of BigTable data are billions of\nURLs with many versions per page, petabytes of Google Earth data, and\nbillions of users’ search data.")]),e._v(" "),s("p",[e._v("BigTable is suitable to store large datasets that are greater than one TB\nwhere each row is less than 10MB. Since BigTable does not provide ACID\n(atomicity, consistency, isolation, durability) properties or transaction\nsupport, Online Transaction Processing ("),s("a",{attrs:{href:"https://en.wikipedia.org/wiki/Online_transaction_processing",target:"_blank",rel:"noopener noreferrer"}},[e._v("OLTP"),s("OutboundLink")],1),e._v(") applications\nwith transaction processes should not use BigTable. For BigTable, data\nshould be structured in the form of key-value pairs or rows-columns. Nonstructured data like images or movies should not be stored in BigTable.")]),e._v(" "),s("p",[e._v("Here are the examples of data that Google stores in BigTable:")]),e._v(" "),s("ul",[s("li",[e._v("URL and its related data, e.g., PageRank, page contents, crawl metadata (e.g., when a page was crawled, what was the response code, etc.), links, anchors (links pointing to a page). There are billions of URLs with many\nversions of a page.")]),e._v(" "),s("li",[e._v("Per-user data, e.g., preference settings, recent queries/search results. Google has hundreds of millions of users.")])]),e._v(" "),s("p",[s("strong",[e._v("BigTable can be used to store the following types of data:")])]),e._v(" "),s("ol",[s("li",[e._v("Time series data: As the data is naturally ordered")]),e._v(" "),s("li",[e._v("Internet of Things (IoT) data: Constant streams of writes")]),e._v(" "),s("li",[e._v("Financial Data: Often represented as time-series data")])]),e._v(" "),s("h2",{attrs:{id:"data-model"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#data-model"}},[e._v("#")]),e._v(" Data Model")]),e._v(" "),s("p",[e._v("In simple terms, BigTable can be characterized as a sparse, distributed,\npersistent, multidimensional, sorted map. Let’s dig deeper to understand\neach of these characteristics of BigTable.")]),e._v(" "),s("p",[e._v("Traditional DBs have a two-dimensional layout of the data, where each cell\nvalue is identified by the "),s("strong",[e._v("‘Row ID’")]),e._v(" and "),s("strong",[e._v("‘Column Name’")]),e._v(":")]),e._v(" "),s("p",[s("img",{attrs:{src:t(715),alt:"2dimensional"}}),e._v(" "),s("em",[e._v("Two-dimensional layout of a traditional database")])]),e._v(" "),s("p",[e._v("BigTable has a "),s("strong",[e._v("four-dimensional data model")]),e._v(". The four dimensions are:")]),e._v(" "),s("ol",[s("li",[s("strong",[e._v("Row Key")]),e._v(": Uniquely identifies a row")]),e._v(" "),s("li",[s("strong",[e._v("Column Family")]),e._v(": Represents a group of columns")]),e._v(" "),s("li",[s("strong",[e._v("Column Name")]),e._v(": Uniquely identifies a column")]),e._v(" "),s("li",[s("strong",[e._v("Timestamp")]),e._v(": Each column cell can have different versions of a value, each identified by a timestamp")])]),e._v(" "),s("p",[s("img",{attrs:{src:t(716),alt:"bigtable"}}),e._v(" "),s("em",[e._v("BigTable's four-dimensional data model")])]),e._v(" "),s("p",[e._v("The data is indexed (or sorted) by row key, column key, and a timestamp.\nTherefore, to access a cell’s contents, we need values for all of them. If no\ntimestamp is specified, BigTable retrieves the most recent version.")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("( row_key : string, column_name : string, timestamp : int64 ) → cell contents (string)\n")])])]),s("h3",{attrs:{id:"rows"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#rows"}},[e._v("#")]),e._v(" Rows")]),e._v(" "),s("p",[e._v("Each row in the table has an associated row key that is an arbitrary string of up to 64 kilobytes in size (although most keys are significantly smaller):")]),e._v(" "),s("ul",[s("li",[e._v("Each row is uniquely identified by the ‘row key.’")]),e._v(" "),s("li",[e._v("Each ‘row key’ is internally represented as a string.")]),e._v(" "),s("li",[e._v("Every read or write of data under a single row is atomic. This also means that atomicity across rows is not guaranteed, e.g., when updating two rows, one might succeed, and the other might fail.")]),e._v(" "),s("li",[e._v("Each table’s data is only indexed by row key, column key, and timestamp. There are no secondary indices.")])]),e._v(" "),s("p",[e._v("A "),s("strong",[e._v("column")]),e._v(" is a key-value pair where the key is represented as ‘column key’\nand the value as ‘column value.’")]),e._v(" "),s("h3",{attrs:{id:"column-families"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#column-families"}},[e._v("#")]),e._v(" Column families")]),e._v(" "),s("p",[e._v("Column keys are grouped into sets called column families. All data stored in\na column family is usually of the same type. The number of distinct column\nfamilies in a table should be small (in the hundreds at maximum), and families should rarely change during operation. Access control as well as\nboth disk and memory accounting are performed at the column-family level.")]),e._v(" "),s("p",[e._v("The following figure shows a single row from a table. The row key is 294 ,\nand there are two column families: "),s("em",[e._v("personal_info")]),e._v(" and "),s("em",[e._v("work_info")]),e._v(" , with\nthree columns under the "),s("em",[e._v("personal_info")]),e._v(" column family.")]),e._v(" "),s("p",[s("img",{attrs:{src:t(717),alt:"img"}})]),e._v(" "),s("ul",[s("li",[e._v("Column family format: "),s("em",[e._v("family:optional qualifier")])]),e._v(" "),s("li",[e._v("All rows have the same set of column families.")]),e._v(" "),s("li",[e._v("BigTable can retrieve data from the same column family efficiently.")]),e._v(" "),s("li",[e._v("Short Column family names are better as names are included in the data transfer.")])]),e._v(" "),s("h3",{attrs:{id:"columns"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#columns"}},[e._v("#")]),e._v(" Columns")]),e._v(" "),s("ul",[s("li",[e._v("Columns are units within a column family.")]),e._v(" "),s("li",[e._v("A BigTable may have an unbounded number of columns.")]),e._v(" "),s("li",[e._v("New columns can be added on the fly")]),e._v(" "),s("li",[e._v("Short column names are better as names are passed in each data transfer, e.g., "),s("em",[e._v("ColumnFamily:ColumnName")]),e._v(" => "),s("em",[e._v("Work:Dept")])]),e._v(" "),s("li",[e._v("As mentioned above, BigTable is quite suitable for sparse data. This is because empty columns are not stored.")])]),e._v(" "),s("h3",{attrs:{id:"timestamps"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#timestamps"}},[e._v("#")]),e._v(" Timestamps")]),e._v(" "),s("p",[e._v("Each column cell can contain multiple versions of the content. For example,\nas we saw in the earlier example, we may have several timestamped\nversions of an employee’s email. A 64-bit timestamp identifies each version\nthat either represents real time or a custom value assigned by the client.\nWhile reading, if no timestamp is specified, BigTable returns the most recent\nversion. If the client specifies a timestamp, the latest version that is earlier\nthan the specified timestamp is returned.")]),e._v(" "),s("p",[e._v("BigTable supports two per-column-family settings to garbage-collect cell\nversions automatically. The client can specify that only the last ‘n’ versions of\na cell be kept, or that only new-enough versions be kept (e.g., only keep\nvalues that were written in the previous seven days).")]),e._v(" "),s("h2",{attrs:{id:"system-apis"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#system-apis"}},[e._v("#")]),e._v(" System APIs")]),e._v(" "),s("p",[e._v("BigTable provides APIs for two types of operations:")]),e._v(" "),s("ul",[s("li",[e._v("Metadata operations")]),e._v(" "),s("li",[e._v("Data operations")])]),e._v(" "),s("h3",{attrs:{id:"metadata-operations"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#metadata-operations"}},[e._v("#")]),e._v(" Metadata operations")]),e._v(" "),s("p",[e._v("BigTable provides APIs for creating and deleting tables and column families.\nIt also provides functions for changing cluster, table, and column family\nmetadata, such as access control rights.")]),e._v(" "),s("h3",{attrs:{id:"data-operations"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#data-operations"}},[e._v("#")]),e._v(" Data operations")]),e._v(" "),s("p",[e._v("Clients can insert, modify, or delete values in BigTable. Clients can also\nlookup values from individual rows or iterate over a subset of the data in a\ntable.")]),e._v(" "),s("ul",[s("li",[e._v("BigTable supports single-row transactions, which can be used to perform atomic read-modify-write sequences on data stored under a single row key.")]),e._v(" "),s("li",[e._v("Bigtable does not support transactions across row keys, but provides a client interface for batch writing across row keys.")]),e._v(" "),s("li",[e._v("BigTable allows cells to be used as integer counters.")]),e._v(" "),s("li",[e._v("A set of wrappers allow a BigTable to be used both as an input source and as an output target for "),s("a",{attrs:{href:"https://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("MapReduce"),s("OutboundLink")],1),e._v(" jobs.")]),e._v(" "),s("li",[e._v("Clients can also write scripts in Sawzall (a language developed at Google) to instruct server-side data processing (transform, filter, aggregate) prior to the network fetch.")])]),e._v(" "),s("p",[e._v("Here are APIs for write operations:")]),e._v(" "),s("ul",[s("li",[e._v("Set() : write cells in a row")]),e._v(" "),s("li",[e._v("DeleteCells() : delete cells in a row")]),e._v(" "),s("li",[e._v("DeleteRow() : delete all cells in a row")])]),e._v(" "),s("p",[e._v("A read or scan operation can read arbitrary cells in a BigTable:")]),e._v(" "),s("ul",[s("li",[e._v("Each row read operation is atomic.")]),e._v(" "),s("li",[e._v("Can ask for data from just one row, all rows, etc.")]),e._v(" "),s("li",[e._v("Can restrict returned rows to a particular range.")]),e._v(" "),s("li",[e._v("Can ask for all columns, just certain columns families, or specific columns.")])]),e._v(" "),s("h2",{attrs:{id:"partitioning-and-high-level-architecture"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#partitioning-and-high-level-architecture"}},[e._v("#")]),e._v(" Partitioning and High-level Architecture")]),e._v(" "),s("h3",{attrs:{id:"table-partitioning"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#table-partitioning"}},[e._v("#")]),e._v(" Table partitioning")]),e._v(" "),s("p",[e._v("A single instance of a BigTable implementation is known as a cluster. Each cluster can store a number of tables where each table is split into multiple\n"),s("strong",[e._v("Tablets")]),e._v(", each around 100–200 MB in size.")]),e._v(" "),s("p",[s("img",{attrs:{src:t(718),alt:"img"}})]),e._v(" "),s("ul",[s("li",[e._v("A Tablet holds a contiguous range of rows.")]),e._v(" "),s("li",[e._v("The table is broken into Tablets at row boundaries.")]),e._v(" "),s("li",[e._v("Initially, each table consists of only one Tablet. As the table grows, multiple Tablets are created. By default, a table is split at around 100 to 200 MB.")]),e._v(" "),s("li",[e._v("Tablets are the unit of distribution and load balancing (more about this later).")]),e._v(" "),s("li",[e._v("Since the table is sorted by row, reads of short ranges of rows are always efficient, that is to say, communicating with a small number of Tablets.")]),e._v(" "),s("li",[e._v("This also means that selecting a row key with a high degree of locality is very important.")]),e._v(" "),s("li",[e._v("Each Tablet is assigned to a Tablet server (discussed later), which\nmanages all read/write requests of that Tablet.")])]),e._v(" "),s("h3",{attrs:{id:"high-level-architecture"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#high-level-architecture"}},[e._v("#")]),e._v(" High-level architecture")]),e._v(" "),s("p",[e._v("The architecture of a BigTable cluster consists of three major components:")]),e._v(" "),s("ol",[s("li",[s("strong",[e._v("Client Library")]),e._v(": A library component that is linked into every client. The client talks to BigTable through this library.")]),e._v(" "),s("li",[s("strong",[e._v("One master server")]),e._v(": Responsible for performing metadata operations and assigning Tablets to Tablet servers and managing them.")]),e._v(" "),s("li",[s("strong",[e._v("Many Tablet servers")]),e._v(": Each Tablet server serves read and write of the data to the Tablets it is assigned.")])]),e._v(" "),s("p",[e._v("BigTable is built on top of several other pieces from Google infrastructure:")]),e._v(" "),s("ol",[s("li",[s("strong",[e._v("GFS")]),e._v(": BigTable uses the Google File System to store its data and log files.")]),e._v(" "),s("li",[s("strong",[e._v("SSTable")]),e._v(": Google’s SSTable (Sorted String Table) file format is used to store BigTable data. SSTable provides a persistent, ordered, and\nimmutable map from keys to values. SSTable is designed in such a way that any data access requires, at most, a single\ndisk access.")]),e._v(" "),s("li",[s("strong",[e._v("Chubby")]),e._v(": BigTable uses a highly available and persistent distributed lock service called Chubby to handle synchronization issues and store configuration information.")]),e._v(" "),s("li",[s("strong",[e._v("Cluster Scheduling System")]),e._v(": Google has a cluster management system\nthat schedules, monitors, and manages the Bigtable’s cluster.")])]),e._v(" "),s("p",[s("img",{attrs:{src:t(719),alt:"high lv"}}),s("br"),e._v(" "),s("em",[e._v("High-level architecture of BigTable")])]),e._v(" "),s("h2",{attrs:{id:"sstable"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#sstable"}},[e._v("#")]),e._v(" SSTable")]),e._v(" "),s("h3",{attrs:{id:"how-are-tablets-stored-in-gfs"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#how-are-tablets-stored-in-gfs"}},[e._v("#")]),e._v(" How are Tablets stored in GFS?")]),e._v(" "),s("p",[e._v("BigTable uses Google File System (GFS), a persistent distributed file storage\nsystem to store data as files. The file format used by BigTable to store its files\nis called SSTable:")]),e._v(" "),s("ul",[s("li",[s("p",[e._v("SSTables are persisted, ordered maps of keys to values, where both keys and values are arbitrary byte strings.")])]),e._v(" "),s("li",[s("p",[e._v("Each Tablet is stored in GFS as a sequence of files called SSTables.")])]),e._v(" "),s("li",[s("p",[e._v("An SSTable consists of a sequence of data blocks (typically 64KB in size).\n"),s("img",{attrs:{src:t(720),alt:"img"}}),s("br"),e._v(" "),s("em",[e._v("SSTable contains multiple blocks")])])]),e._v(" "),s("li",[s("p",[e._v("A block index is used to locate blocks; the index is loaded into memory when the SSTable is opened.\n"),s("img",{attrs:{src:t(721),alt:"img"}})])]),e._v(" "),s("li",[s("p",[e._v("A lookup can be performed with a single disk seek. We first find the appropriate block by performing a binary search in the in-memory index, and then reading the appropriate block from the disk.")])]),e._v(" "),s("li",[s("p",[e._v("To read data from an SSTable, it can either be copied from disk to memory as a whole or just the index. The former approach avoids subsequent disk seeks for lookups, while the latter requires a single disk seek for each lookup.")])]),e._v(" "),s("li",[s("p",[e._v("SSTables provide two operations:")]),e._v(" "),s("ul",[s("li",[e._v("Get the value associated with a given key")]),e._v(" "),s("li",[e._v("Iterate over a set of values in a given key range")])])]),e._v(" "),s("li",[s("p",[e._v("Each SSTable is immutable (read-only) once written to GFS. If new data is added, a new SSTable is created. Once an old SSTable is no longer needed, it is set out for garbage collection. SSTable immutability is at the core of BigTable’s data checkpointing and recovery routines. SSTable’s immutability provides following advantages:")]),e._v(" "),s("ul",[s("li",[e._v("No synchronization is needed during read operations.")]),e._v(" "),s("li",[e._v("This also makes it easier to split Tablets.")]),e._v(" "),s("li",[e._v("Garbage collector handles the permanent removal of deleted or stale data.")])])])]),e._v(" "),s("h3",{attrs:{id:"table-vs-tablet-vs-sstable"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#table-vs-tablet-vs-sstable"}},[e._v("#")]),e._v(" Table vs. Tablet vs. SSTable")]),e._v(" "),s("p",[e._v("Here is how we can define the relationship between Table, Tablet and SStable:")]),e._v(" "),s("ul",[s("li",[e._v("Multiple Tablets make up a table.")]),e._v(" "),s("li",[e._v("SSTables can be shared by multiple Tablets.")]),e._v(" "),s("li",[e._v("Tablets do not overlap, SSTables can overlap.")])]),e._v(" "),s("p",[s("img",{attrs:{src:t(722),alt:"img"}}),s("br"),e._v(" "),s("em",[e._v("Tablet vs SSTable")])]),e._v(" "),s("ul",[s("li",[e._v("To improve write performance, BigTable uses an in-memory, mutable sorted buffer called "),s("strong",[e._v("MemTable")]),e._v(" to store recent updates. As more writes\nare performed, MemTable size increases, and when it reaches a threshold, the MemTable is frozen, a new MemTable is created, and the frozen MemTable is converted to an SSTable and written to GFS.")]),e._v(" "),s("li",[e._v("Each data update is also written to a commit-log which is also stored in\nGFS. This log contains redo records used for recovery if a Tablet server\nfails before committing a MemTable to SSTable.")]),e._v(" "),s("li",[e._v("While reading, the data can be in MemTables or SSTables. Since both\nthese tables are sorted, it is easy to find the most recent data.")])]),e._v(" "),s("p",[s("img",{attrs:{src:t(723),alt:"img"}}),e._v(" "),s("em",[e._v("Read and write workow")])]),e._v(" "),s("h2",{attrs:{id:"gfs-and-chubby"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#gfs-and-chubby"}},[e._v("#")]),e._v(" GFS and Chubby")]),e._v(" "),s("h3",{attrs:{id:"gfs"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#gfs"}},[e._v("#")]),e._v(" GFS")]),e._v(" "),s("p",[e._v("GFS is a scalable distributed file system developed by Google for its large data-intensive applications such as BigTable.")]),e._v(" "),s("p",[s("img",{attrs:{src:t(724),alt:"img"}}),s("br"),e._v(" "),s("em",[e._v("High-level architecture of GFS")])]),e._v(" "),s("ul",[s("li",[e._v("GFS files are broken into fixed-size blocks, called Chunks.")]),e._v(" "),s("li",[e._v("Chunks are stored on data servers called ChunkServers.")]),e._v(" "),s("li",[e._v("GFS master manages the metadata.")]),e._v(" "),s("li",[e._v("SSTables are divided into fixed-size, blocks and these blocks are stored on ChunkServers.")]),e._v(" "),s("li",[e._v("Each chunk in GFS is replicated across multiple ChunkServers for reliability.")]),e._v(" "),s("li",[e._v("Clients interact with the GFS master for metadata, but all data transfers happen directly between the client and ChunkServers.")])]),e._v(" "),s("h3",{attrs:{id:"chubby"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#chubby"}},[e._v("#")]),e._v(" Chubby")]),e._v(" "),s("p",[e._v("Chubby is a highly available and persistent distributed locking service that allows a multi-thousand node Bigtable cluster to stay coordinated.")]),e._v(" "),s("p",[s("img",{attrs:{src:t(725),alt:"img"}}),s("br"),e._v(" "),s("em",[e._v("High-level architecture of Chubby")])]),e._v(" "),s("ul",[s("li",[e._v("Chubby usually runs with five active replicas, one of which is elected as the master to serve requests. To remain alive, a majority of Chubby replicas must be running.")]),e._v(" "),s("li",[e._v("BigTable depends on Chubby so much that if Chubby is unavailable for an extended period of time, BigTable will also become unavailable.")]),e._v(" "),s("li",[e._v("Chubby uses the Paxos algorithm to keep its replicas consistent in the face of failure.")]),e._v(" "),s("li",[e._v("Chubby provides a namespace consisting of files and directories. Each file or directory can be used as a lock.")]),e._v(" "),s("li",[e._v("Read and write access to a Chubby file is atomic.")]),e._v(" "),s("li",[e._v("Each Chubby client maintains a session with a Chubby service. A client’s session expires if it is unable to renew its session lease within the lease expiration time. When a client’s session expires, it loses any locks and open handles. Chubby clients can also register callbacks on Chubby files and directories for notification of changes or session expiration.")]),e._v(" "),s("li",[e._v("In BigTable, Chubby is used to:\n"),s("ul",[s("li",[e._v("Ensure there is only one active master. The master maintains a session lease with Chubby and periodically renews it to retain the status of the master.")]),e._v(" "),s("li",[e._v("Store the bootstrap location of BigTable data (discussed later)")]),e._v(" "),s("li",[e._v("Discover new Tablet servers as well as the failure of existing ones")]),e._v(" "),s("li",[e._v("Store BigTable schema information (the column family information for each table)")]),e._v(" "),s("li",[e._v("Store Access Control Lists (ACLs)")])])])]),e._v(" "),s("h2",{attrs:{id:"bigtable-components"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#bigtable-components"}},[e._v("#")]),e._v(" Bigtable Components")]),e._v(" "),s("p",[e._v("As described previously, a BigTable cluster consists of three major components:")]),e._v(" "),s("ol",[s("li",[e._v("A library component that is linked into every client")]),e._v(" "),s("li",[e._v("One master server")]),e._v(" "),s("li",[e._v("Many Tablet servers")])]),e._v(" "),s("p",[s("img",{attrs:{src:t(726),alt:"img"}}),s("br"),e._v(" "),s("em",[e._v("BigTable architecture")])]),e._v(" "),s("h3",{attrs:{id:"bigtable-master-server"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#bigtable-master-server"}},[e._v("#")]),e._v(" BigTable master server")]),e._v(" "),s("p",[e._v("There is only one master server in a BigTable cluster, and it is responsible for:")]),e._v(" "),s("ul",[s("li",[e._v("Assigning Tablets to Tablet servers and ensuring effective load balancing")]),e._v(" "),s("li",[e._v("Monitoring the status of Tablet servers and managing the joining or failure of Tablet server")]),e._v(" "),s("li",[e._v("Garbage collection of the underlying files stored in GFS")]),e._v(" "),s("li",[e._v("Handling metadata operations such as table and column family creations")])]),e._v(" "),s("p",[e._v("Bigtable master is not involved in the core task of mapping tablets onto the\nunderlying files in GFS (Tablet servers handle this). This means that Bigtable\nclients do not have to communicate with the master at all. This design\ndecision significantly reduces the load on the master and the possibility of\nthe master becoming a bottleneck.")]),e._v(" "),s("h3",{attrs:{id:"tablet-servers"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#tablet-servers"}},[e._v("#")]),e._v(" Tablet servers")]),e._v(" "),s("ul",[s("li",[e._v("Each Tablet server is assigned ownership of a number of Tablets (typically 10–1,000 Tablets per server) by the master.")]),e._v(" "),s("li",[e._v("Each Tablet server serves read and write requests of the data of the Tablets it is assigned. The client communicates directly with the Tablet servers for reads/writes.")]),e._v(" "),s("li",[e._v("Tablet servers can be added or removed dynamically from a cluster to accommodate changes in the workloads.")]),e._v(" "),s("li",[e._v("Tablet creation, deletion, or merging is initiated by the master server, while Tablet partition is handled by Tablet servers who notify the master.")])]),e._v(" "),s("h2",{attrs:{id:"working-with-tablets"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#working-with-tablets"}},[e._v("#")]),e._v(" Working with Tablets")]),e._v(" "),s("h3",{attrs:{id:"locating-tablets"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#locating-tablets"}},[e._v("#")]),e._v(" Locating Tablets")]),e._v(" "),s("p",[e._v("Since Tablets move around from server to server (due to load balancing,\nTablet server failures, etc.), given a row, how do we find the correct Tablet\nserver? To answer this, we need to find the Tablet whose row range covers\nthe target row. BigTable maintains a 3-level hierarchy, analogous to that of a\nB+ tree, to store Tablet location information.")]),e._v(" "),s("p",[e._v("BigTable creates a special table, called "),s("strong",[e._v("Metadata")]),e._v(" table, to store Tablet\nlocations. This Metadata table contains one row per Tablet that tells us which\nTablet server is serving this Tablet. Each row in the METADATA table stores a\nTablet’s location under a row key that is an encoding of the Tablet’s table\nidentifier and its end row.")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("METADATA:   Key: table id + end row\n           Data: tablet server location\n")])])]),s("p",[e._v("BigTable stores the information about the Metadata table in two parts:")]),e._v(" "),s("ol",[s("li",[s("strong",[e._v("Meta-1 Tablet")]),e._v(" has one row for each data Tablet (or non-meta Tablet). Since Meta-1 Tablet can be big, it is split into multiple metadata Tablets\nand distributed to multiple Tablet servers.")]),e._v(" "),s("li",[s("strong",[e._v("Meta-0 Tablet")]),e._v(" has one row for each Meta-1 Tablet. Meta-0 table never gets split. BigTable stores the location of the Meta-0 Tablet in a Chubby file.")])]),e._v(" "),s("p",[s("img",{attrs:{src:t(727),alt:"img"}}),s("br"),e._v(" "),s("em",[e._v("Metadata tablets")])]),e._v(" "),s("p",[e._v("A BigTable client seeking the location of a Tablet starts the search by looking\nup a particular file in Chubby that is known to hold the location of the Meta0 Tablet. This Meta-0 Tablet contains information about other metadata\nTablets, which in turn contain the location of the actual data Tablets. With\nthis scheme, the depth of the tree is limited to three. For efficiency, the client\nlibrary caches Tablet locations and also prefetch metadata associated with\nother Tablets whenever it reads the METADATA table.")]),e._v(" "),s("p",[s("img",{attrs:{src:t(728),alt:"img"}})]),e._v(" "),s("h3",{attrs:{id:"assigning-tablets"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#assigning-tablets"}},[e._v("#")]),e._v(" Assigning Tablets")]),e._v(" "),s("p",[e._v("A Tablet is assigned to only one Tablet server at any time. The master keeps\ntrack of the set of live Tablet servers and the mapping of Tablets to Tablet\nservers. The master also keeps track of any unassigned Tablets and assigns\nthem to Tablet servers with sufficient room.")]),e._v(" "),s("p",[e._v("When a Tablet server starts, it creates and acquires an exclusive lock on a\nuniquely named file in Chubby’s “servers” directory. This mechanism is used\nto tell the master that the Tablet server is alive. When the master is restarted\nby the Cluster Management System, the following things happen:")]),e._v(" "),s("ol",[s("li",[e._v("The master grabs a unique master lock in Chubby to prevent multiple\nmaster instantiations.")]),e._v(" "),s("li",[e._v("The master scans the Chubby’s “servers” directory to find the live Tablet\nservers.")]),e._v(" "),s("li",[e._v("The master communicates with every live Tablet server to discover\nwhat Tablets are assigned to each server.")]),e._v(" "),s("li",[e._v("The master scans the METADATA table to learn the full set of Tablets.\nWhenever this scan encounters a Tablet that is not already assigned, the\nmaster adds the Tablet to the set of unassigned Tablets. Similarly, the\nmaster builds a set of unassigned Tablet servers, which are eligible for\nTablet assignment. The master uses this information to assign the\nunassigned Tablets to appropriate Tablet servers.")])]),e._v(" "),s("h3",{attrs:{id:"monitoring-tablet-servers"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#monitoring-tablet-servers"}},[e._v("#")]),e._v(" Monitoring Tablet servers")]),e._v(" "),s("p",[e._v("As stated above, BigTable maintains a ‘Servers’ directory in Chubby, which\ncontains one file for each live Tablet server. Whenever a new Tablet server\ncomes online, it creates a new file in this directory to signal its availability\nand obtains an exclusive lock on this file. As long as a Tablet server retains\nthe lock on its Chubby file, it is considered alive.")]),e._v(" "),s("p",[e._v("BigTable’s master keeps monitoring the ‘Servers’ directory, and whenever it\nsees a new file in this directory, it knows that a new Tablet server has\nbecome available and is ready to be assigned Tablets. In addition to that, the\nmaster regularly checks the status of the lock. If the lock is lost, the master\nassumes that there is a problem either with the Tablet server or the Chubby.\nIn such a case, the master tries to acquire the lock, and if it succeeds, it\nconcludes that Chubby is working fine, and the Tablet server is having\nproblems. The master, in this case, deletes the file and reassigns the tablets\nof the failing Tablet server. The deletion of the file works as a signal for the\nfailing Tablet server to terminate itself and stop serving the Tablets.")]),e._v(" "),s("p",[e._v("Whenever a Table server loses its lock on the file it has created in the\n“servers” directory, it stops serving its Tablets. It tries to acquire the lock\nagain, and if it succeeds, it considers it a temporary network problem and\nstarts serving the Tablets again. If the file gets deleted, then the Tablet server\nterminates itself to start afresh.")]),e._v(" "),s("h3",{attrs:{id:"load-balancing-tablet-servers"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#load-balancing-tablet-servers"}},[e._v("#")]),e._v(" Load-balancing Tablet servers")]),e._v(" "),s("p",[e._v("As described above, the master is responsible for assigning Tablets to Tablet\nservers. The master keeps track of all available Tablet servers and maintains\nthe list of Tablets that the cluster is supposed to serve. In addition to that, the\nmaster periodically asks Tablet servers about their current load. All this\ninformation gives the master a global view of the cluster and helps assign\nand load-balance Tablets.")]),e._v(" "),s("h2",{attrs:{id:"the-life-of-read-write-operations"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#the-life-of-read-write-operations"}},[e._v("#")]),e._v(" The Life of Read & Write Operations")]),e._v(" "),s("h3",{attrs:{id:"write-request"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#write-request"}},[e._v("#")]),e._v(" Write request")]),e._v(" "),s("p",[e._v("Upon receiving a write request, a Tablet server performs the following set of steps:")]),e._v(" "),s("ol",[s("li",[e._v("Checks that the request is well-formed.")]),e._v(" "),s("li",[e._v("Checks that the sender is authorized to perform the mutation. This\nauthorization is performed based on the Access Control Lists (ACLs) that\nare stored in a chubby file.")]),e._v(" "),s("li",[e._v("If the above two conditions are met, the mutation is written to the\ncommit-log in GFS that stores redo records.")]),e._v(" "),s("li",[e._v("Once the mutation is committed to the commit-log, its contents are\nstored in memory in a sorted buffer called MemTable.")]),e._v(" "),s("li",[e._v("After inserting the data into the MemTable, acknowledgment is sent to\nthe client that the data has been successfully written.")]),e._v(" "),s("li",[e._v("Periodically, MemTables are flushed to SSTables, and SSTables are\nmerged during compaction (discussed later).")])]),e._v(" "),s("p",[s("img",{attrs:{src:t(729),alt:"img"}}),e._v(" "),s("em",[e._v("The anatomy of a write request")])]),e._v(" "),s("h3",{attrs:{id:"read-request"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#read-request"}},[e._v("#")]),e._v(" Read request")]),e._v(" "),s("p",[e._v("Upon receiving a read request, a Tablet server performs the following set of\nsteps:")]),e._v(" "),s("ol",[s("li",[e._v("Checks that the request is well-formed and the sender is authorized")]),e._v(" "),s("li",[e._v("Returns the rows if they are available in the Cache (discussed later)")]),e._v(" "),s("li",[e._v("Reads MemTable first to find the required rows")]),e._v(" "),s("li",[e._v("Reads SSTable indexes that are loaded in memory to find SSTables that\nwill have the required data, then reads the rows from those SSTables")]),e._v(" "),s("li",[e._v("Merge rows read from MemTable and SSTables to find the required\nversion of the data. Since the SSTables and the MemTable are sorted, the\nmerged view can be formed efficiently.")])]),e._v(" "),s("p",[s("img",{attrs:{src:t(730),alt:"img"}})]),e._v(" "),s("h2",{attrs:{id:"fault-tolerance"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#fault-tolerance"}},[e._v("#")]),e._v(" Fault Tolerance")]),e._v(" "),s("h3",{attrs:{id:"fault-tolerance-in-chubby-and-gfs"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#fault-tolerance-in-chubby-and-gfs"}},[e._v("#")]),e._v(" Fault tolerance in Chubby and GFS")]),e._v(" "),s("p",[e._v("BigTable uses two independent systems Chubby and GFS. Both of these systems adopt a replication strategy for fault tolerance\nand higher availability. For example, a Chubby cell usually consists of five servers, where one server becomes the master and the remaining four work\nas replicas. In case the master fails, one of the replicas is elected to become the leader; thus, minimizing Chubby’s downtime. Similarly, GFS stores\nmultiple copies of data on different ChunkServers.")]),e._v(" "),s("h3",{attrs:{id:"fault-tolerance-for-tablet-server"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#fault-tolerance-for-tablet-server"}},[e._v("#")]),e._v(" Fault tolerance for Tablet server")]),e._v(" "),s("p",[e._v("BigTable’s master is responsible for monitoring the Tablet servers. The\nmaster does this by periodically checking the status of the Chubby lock\nagainst each Tablet server. When the master finds out that a Tablet server\nhas gone dead, it reassigns the tablets of the failing Tablet server.")]),e._v(" "),s("h3",{attrs:{id:"fault-tolerance-for-the-master"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#fault-tolerance-for-the-master"}},[e._v("#")]),e._v(" Fault tolerance for the Master")]),e._v(" "),s("p",[e._v("The master acquires a lock in a Chubby file and maintains a lease. If, at any\ntime, the master’s lease expires, it kills itself. When Google’s Cluster\nManagement System finds out that there is no active master, it starts one up.\nThe new master has to acquire the lock on the Chubby file before acting as\nthe master.")]),e._v(" "),s("h2",{attrs:{id:"compaction"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#compaction"}},[e._v("#")]),e._v(" Compaction")]),e._v(" "),s("p",[e._v("Mutilations in BigTable take up extra space till compaction happens.\nBigTable manages compaction behind the scenes. Here is the list of\ncompactions:")]),e._v(" "),s("p",[s("img",{attrs:{src:t(731),alt:"img"}}),e._v(" "),s("em",[e._v("Major, minor, and merging compaction in BigTable")])]),e._v(" "),s("ol",[s("li",[s("strong",[e._v("Minor Compaction")]),e._v(": As write operations are performed, the MemTable grows in size. When the MemTable reaches a certain threshold, it is frozen, and a new MemTable is created. The frozen MemTable is converted to an SSTable and written to GFS. This process is called minor compaction. Each minor compaction creates a new SSTable and has the following two benefits:\n"),s("ul",[s("li",[e._v("It reduces the memory usage of the Tablet server, as it flushes the MemTable to GFS. Once a MemTable is written to GFS, corresponding entries in the commit-log are also removed.")]),e._v(" "),s("li",[e._v("It reduces the amount of data that has to be read from the commit log during recovery if this server dies.")])])]),e._v(" "),s("li",[s("strong",[e._v("Merging Compaction")]),e._v(" — Minor compaction keeps increasing the count of SSTables. This means that read operations might need to merge\nupdates from an arbitrary number of SSTables. To reduce the number of\nSSTables, a merging compaction is performed which reads the contents\nof a few SSTables and the MemTable and writes out a new SSTable. The\ninput SSTables and MemTable can be discarded as soon as the\ncompaction has finished.")]),e._v(" "),s("li",[s("strong",[e._v("Major Compaction")]),e._v(" — In Major compaction, all the SSTables are written\ninto a single SSTable. SSTables created as a result of major compaction\ndo not contain any deletion information or deleted data, whereas\nSSTables created from non-major compactions may contain deleted\nentries. Major compaction allows BigTable to reclaim resources used by\ndeleted data and ensures that deleted data disappears from the system\nquickly, which is important for services storing sensitive data.")])]),e._v(" "),s("h2",{attrs:{id:"bigtable-refinements"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#bigtable-refinements"}},[e._v("#")]),e._v(" BigTable Refinements")]),e._v(" "),s("h3",{attrs:{id:"locality-groups"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#locality-groups"}},[e._v("#")]),e._v(" Locality groups")]),e._v(" "),s("p",[e._v("Clients can club together multiple column families into a locality group.\nBigTable generates separate SSTables for each locality group. This has two\nbenefits:")]),e._v(" "),s("ul",[s("li",[e._v("Grouping columns that are frequently accessed together in a locality\ngroup enhances the read performance.")]),e._v(" "),s("li",[e._v("Clients can explicitly declare any locality group to be in memory for\nfaster access. This way, smaller locality groups that are frequently\naccessed can be kept in memory.")]),e._v(" "),s("li",[e._v("Scans over one locality group are O(bytes_in_locality_group) and not\nO(bytes_in_table).")])]),e._v(" "),s("p",[s("img",{attrs:{src:t(732),alt:"img"}}),e._v(" "),s("em",[e._v("Grouping together columns to form locality groups")])]),e._v(" "),s("h3",{attrs:{id:"compression"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#compression"}},[e._v("#")]),e._v(" Compression")]),e._v(" "),s("p",[e._v("Clients can choose to compress the SSTable for a locality group to save space.\nBigTable allows its clients to choose compression techniques based on their\napplication requirements. The compression ratio gets even better when\nmultiple versions of the same data are stored. Compression is applied to each\nSSTable block separately.")]),e._v(" "),s("h3",{attrs:{id:"caching"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#caching"}},[e._v("#")]),e._v(" Caching")]),e._v(" "),s("p",[e._v("To improve read performance, Tablet servers employ two levels of caching:")]),e._v(" "),s("ul",[s("li",[s("strong",[e._v("Scan Cache")]),e._v(" — It caches (key, value) pairs returned by the SSTable and is\nuseful for applications that read the same data multiple times.")]),e._v(" "),s("li",[s("strong",[e._v("Block Cache")]),e._v(" — It caches SSTable blocks read from GFS and is useful for\nthe applications that tend to read the data which is close to the data they\nrecently read (e.g., sequential or random reads of different columns in\nthe same locality group within a frequently accessed row)")])]),e._v(" "),s("h3",{attrs:{id:"bloom-filters"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#bloom-filters"}},[e._v("#")]),e._v(" Bloom filters")]),e._v(" "),s("p",[e._v("Any read operation has to read from all SSTables that make up a Tablet. If\nthese SSTables are not in memory, the read operation may end up doing\nmany disk accesses. To reduce the number of disk accesses BigTable uses\nBloom Filters.")]),e._v(" "),s("p",[e._v("Bloom Filters are created for SSTables (particularly for the locality groups).\nThey help to reduce the number of disk accesses by predicting if an SSTable\nmay contain data corresponding to a particular (row, column) pair. Bloom\nfilters take a small amount of memory but can improve the read\nperformance drastically")]),e._v(" "),s("h3",{attrs:{id:"unified-commit-log"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#unified-commit-log"}},[e._v("#")]),e._v(" Unified commit Log")]),e._v(" "),s("p",[e._v("Instead of maintaining separate commit log files for each Tablet, BigTable\nmaintains one log file for a Tablet server. This gives better write\nperformance. Since each write has to go to the commit log, writing to a large\nnumber of log files would be slow as it could cause a large number of disk\nseeks.")]),e._v(" "),s("p",[e._v("One disadvantage of having a single log file is that it complicates the Tablet\nrecovery process. When a Tablet server dies, the Tablets that it served will be\nmoved to other Tablet servers. To recover the state for a Tablet, the new\nTablet server needs to reapply the mutations for that Tablet from the commit\nlog written by the original Tablet server. However, the mutations for these Tablets were co-mingled in the same physical log file. One approach would\nbe for each new Tablet server to read this full commit log file and apply just\nthe entries needed for the Tablets it needs to recover. However, under such a\nscheme, if 100 machines were each assigned a single Tablet from a failed\nTablet server, then the log file would be read 100 times. BigTable avoids\nduplicating log reads by first sorting the commit log entries in order of the\nkeys "),s("code",[e._v("<table, row name, log sequence number>")]),e._v(". In the sorted output, all\nmutations for a particular Tablet are contiguous and can therefore be read\nefficiently")]),e._v(" "),s("p",[e._v("To further improve the performance, each Tablet server maintains two log\nwriting threads — each writing to its own and separate log file. Only one of\nthe threads is active at a time. If one of the threads is performing poorly (say,\ndue to network congestion), the writing switches to the other thread. Log\nentries have sequence numbers to allow the recovery process.")]),e._v(" "),s("h3",{attrs:{id:"speeding-up-tablet-recovery"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#speeding-up-tablet-recovery"}},[e._v("#")]),e._v(" Speeding up Tablet recovery")]),e._v(" "),s("p",[e._v("As we saw above, one of the complicated and time-consuming tasks while\nloading Tablets is to ensure that the Tablet server loads all entries from the\ncommit log. When the master moves a Tablet from one Tablet server to\nanother, the source Tablet server performs compactions to ensure that the\ndestination Tablet server does not have to read the commit log. This is done\nin three steps:")]),e._v(" "),s("ul",[s("li",[e._v("In the first step, the source server performs a minor compaction. This\ncompaction reduces the amount of data in the commit log.")]),e._v(" "),s("li",[e._v("After this, the source Tablet server stops serving the Tablet.")]),e._v(" "),s("li",[e._v("Finally, the source server performs another (usually very fast) minor\ncompaction to apply any new log entries that have arrived while the\nfirst minor compaction was being performed. After this second minor compaction is complete, the Tablet can be loaded on another Tablet\nserver without requiring any recovery of log entries.")])]),e._v(" "),s("h2",{attrs:{id:"bigtable-characteristics"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#bigtable-characteristics"}},[e._v("#")]),e._v(" BigTable Characteristics")]),e._v(" "),s("h3",{attrs:{id:"bigtable-performance"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#bigtable-performance"}},[e._v("#")]),e._v(" BigTable performance")]),e._v(" "),s("p",[e._v("Here are a few reasons behind BigTable’s performance and popularity:")]),e._v(" "),s("ul",[s("li",[s("strong",[e._v("Distributed multi-level map")]),e._v(": BigTable can run on a large number of\nmachines.")]),e._v(" "),s("li",[s("strong",[e._v("Scalable")]),e._v(" means that BigTable can be easily scaled horizontally by\nadding more nodes to the cluster without any performance impact. No\nmanual intervention or rebalancing is required. BigTable achieves\nlinear scalability and proven fault tolerance on commodity hardware.")]),e._v(" "),s("li",[s("strong",[e._v("Fault-tolerant and reliable")]),e._v(": Since data is replicated to multiple nodes,\nfault tolerance is pretty high.")]),e._v(" "),s("li",[s("strong",[e._v("Durable")]),e._v(": BigTable stores data permanently.")]),e._v(" "),s("li",[s("strong",[e._v("Centralized")]),e._v(": BigTable adopts a single-master approach to maintain data\nconsistency and a centralized view of the state of the system.")]),e._v(" "),s("li",[s("strong",[e._v("Separation between control and data")]),e._v(": BigTable maintains a strict\nseparation between control and data flow. Clients talk to the Master for all metadata operations, whereas all data access happens directly\nbetween the Clients and the Tablet servers.")])]),e._v(" "),s("h3",{attrs:{id:"dynamo-vs-bigtable"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#dynamo-vs-bigtable"}},[e._v("#")]),e._v(" Dynamo vs. BigTable")]),e._v(" "),s("table",[s("thead",[s("tr",[s("th",[e._v(".")]),e._v(" "),s("th",[e._v("Dynamo")]),e._v(" "),s("th",[e._v("BigTable")])])]),e._v(" "),s("tbody",[s("tr",[s("td",[e._v("Architecture")]),e._v(" "),s("td",[s("strong",[e._v("Decentralized")]),e._v(" "),s("br"),e._v(" Every node has same set of responsibilities")]),e._v(" "),s("td",[s("strong",[e._v("Centralized")]),e._v(" "),s("br"),e._v(" Master handles metadata, tablet servers handle read/write")])]),e._v(" "),s("tr",[s("td",[e._v("Data Model")]),e._v(" "),s("td",[e._v("Key-value")]),e._v(" "),s("td",[e._v("Multidimensional sorted map.")])]),e._v(" "),s("tr",[s("td",[e._v("Security")]),e._v(" "),s("td",[e._v("X")]),e._v(" "),s("td",[e._v("Access rights at column family level")])]),e._v(" "),s("tr",[s("td",[e._v("Partitioning")]),e._v(" "),s("td",[s("strong",[e._v("Consistent Hashing")]),e._v(" "),s("br"),e._v("  Each node is assigned to a random position on the ring")]),e._v(" "),s("td",[s("strong",[e._v("Tablets")]),e._v(" "),s("br"),e._v(" Each table is broken into a contiguous range of rows called tablets.")])]),e._v(" "),s("tr",[s("td",[e._v("Replication")]),e._v(" "),s("td",[s("strong",[e._v("Sloppy Quorum")]),e._v(" "),s("br"),e._v("  Each data item is replicated to 'N' number of nodes.")]),e._v(" "),s("td",[s("strong",[e._v("GFS Chunk replication")]),e._v(" "),s("br"),e._v("  Data is stored in GFS. Files in GFS are broken into chunks, and these chunks are replicated to different servers.")])]),e._v(" "),s("tr",[s("td",[e._v("CAP")]),e._v(" "),s("td",[e._v("AP")]),e._v(" "),s("td",[e._v("CP")])]),e._v(" "),s("tr",[s("td",[e._v("Operations")]),e._v(" "),s("td",[e._v("By key")]),e._v(" "),s("td",[e._v("By key range")])]),e._v(" "),s("tr",[s("td",[e._v("Storage")]),e._v(" "),s("td",[e._v("Plug-in")]),e._v(" "),s("td",[e._v("SSTables in GFS")])]),e._v(" "),s("tr",[s("td",[e._v("Memberships and failure detection")]),e._v(" "),s("td",[e._v("Gossip based protocol")]),e._v(" "),s("td",[e._v("Handshakes initiated by the master")])])])]),e._v(" "),s("h2",{attrs:{id:"summary"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#summary"}},[e._v("#")]),e._v(" Summary")]),e._v(" "),s("ul",[s("li",[e._v("BigTable is Google's "),s("strong",[e._v("distributed storage system")]),e._v(" designed to manage large amounts of structured data with high availability, low latency, scalability, and  fault-tolerance goals.")]),e._v(" "),s("li",[e._v("BigTable is a "),s("strong",[e._v("sparse")]),e._v(", "),s("strong",[e._v("distributed")]),e._v(", persistent, "),s("strong",[e._v("multidimensional sorted map")]),e._v(".")]),e._v(" "),s("li",[e._v('The map is indexed by a unique key made up of a row key, a column key, and a timestamp (a 64-bit integer, "real time" in millisecond).')]),e._v(" "),s("li",[e._v("Each row key is an arbitrary string of up to 64 kilobytes in size, although most keys are significantly smaller.")]),e._v(" "),s("li",[e._v("Unlike a traditional relational database table, BigTable is a "),s("strong",[e._v("wide-column datastore")]),e._v(" with an unbounded number of columns.")]),e._v(" "),s("li",[e._v("Columns are grouped into "),s("strong",[e._v("column families")]),e._v(". Each column family stores similar types of data under a 'family:qualifier' column key.")]),e._v(" "),s("li",[e._v("The row key and the column (family:qualifier) key uniquely identify a data cell. Within each cell, the data contents are further indexed by timestamps providing multiple versions of the data in time.")]),e._v(" "),s("li",[e._v("Every read or write of data under a single row is atomic. Atomicity across rows is not guaranteed.")]),e._v(" "),s("li",[e._v("BigTable provides APIs for metadata operations like creating and deleting tables and column families. BigTable clients can use data operation APIs for writing or deleting values, lookup values from individual rows, or iterate over a subset of the data in a table.")]),e._v(" "),s("li",[e._v("A table is split into smaller ranges of rows called "),s("strong",[e._v("Tablets")]),e._v(". A Tablet holds a contiguous range of rows.")]),e._v(" "),s("li",[e._v("Tablets are the unit of distribution and load balancing.")]),e._v(" "),s("li",[e._v("BigTable architecture consists of "),s("strong",[e._v("one master server")]),e._v(" and "),s("strong",[e._v("multiple Tablet servers.")])]),e._v(" "),s("li",[e._v("Master is responsible for assigning Tablets to Tablet servers, as well as monitoring and balancing Tablet servers' load.")]),e._v(" "),s("li",[e._v("Each Tablet server serves read and write requests of the data to the Tablets it is assigned.")]),e._v(" "),s("li",[e._v("BigTable clients communicate directly with the Tablet servers to read/write data.")]),e._v(" "),s("li",[e._v("Each Tablet server stores the data in immutable STable files which are stored in "),s("strong",[e._v("Google File System (GFS).")])]),e._v(" "),s("li",[e._v("New committed updates are first stored in a memory-based "),s("strong",[e._v("MemTable")]),e._v(".")]),e._v(" "),s("li",[e._v("BigTable performs all read operations against a combined view of SSTables and MemTable.")]),e._v(" "),s("li",[e._v("Periodically, the MemTable is flushed into an SSTable, allowing for efficient memory utilization.")]),e._v(" "),s("li",[e._v("To enhance read performance, BigTable makes use of caching and "),s("strong",[e._v("Bloom filters.")])]),e._v(" "),s("li",[e._v("BigTable relies heavily on distributed locking service "),s("strong",[e._v("Chubby")]),e._v(" for master server selection and monitoring.")])])])}),[],!1,null,null,null);a.default=i.exports},715:function(e,a,t){e.exports=t.p+"assets/img/2d-layout.57523f8c.png"},716:function(e,a,t){e.exports=t.p+"assets/img/4d.e3e7bb63.png"},717:function(e,a,t){e.exports=t.p+"assets/img/column-fam.7512ae0c.png"},718:function(e,a,t){e.exports=t.p+"assets/img/tablets.1f756679.png"},719:function(e,a,t){e.exports=t.p+"assets/img/hla.6e5df112.png"},720:function(e,a,t){e.exports=t.p+"assets/img/sstable.0ae9f4c6.png"},721:function(e,a,t){e.exports=t.p+"assets/img/reading-sstable.b2326a4a.png"},722:function(e,a,t){e.exports=t.p+"assets/img/tablet-vs-sstable.6e0e0ee5.png"},723:function(e,a,t){e.exports=t.p+"assets/img/read-and-write-wf.aeaa275e.png"},724:function(e,a,t){e.exports=t.p+"assets/img/arch-gfs.37301f30.png"},725:function(e,a,t){e.exports=t.p+"assets/img/arch-chubby.811b1187.png"},726:function(e,a,t){e.exports=t.p+"assets/img/arch-bigtable.dd7625a3.png"},727:function(e,a,t){e.exports=t.p+"assets/img/metadata-tablets.50c280e3.png"},728:function(e,a,t){e.exports=t.p+"assets/img/control-and-dataflow.b16e3539.png"},729:function(e,a,t){e.exports=t.p+"assets/img/write.9e52fb79.png"},730:function(e,a,t){e.exports=t.p+"assets/img/read.d4a233f0.png"},731:function(e,a,t){e.exports=t.p+"assets/img/compaction.6c532643.png"},732:function(e,a,t){e.exports=t.p+"assets/img/groupping.a05b97dd.png"}}]);